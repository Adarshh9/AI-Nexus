{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/dataset/datasets_data_df.pickle' ,'rb') as file:\n",
    "    df = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>sha</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>disabled</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>cardData</th>\n",
       "      <th>siblings</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>paperswithcode_id</th>\n",
       "      <th>citation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>664a1c1f4fa4afb446afa8f7</td>\n",
       "      <td>openbmb/RLAIF-V-Dataset</td>\n",
       "      <td>openbmb</td>\n",
       "      <td>d2726fcfdb37fba679e7ccdf31e23f09e869b0f0</td>\n",
       "      <td>2024-05-28T04:25:05.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[task_categories:visual-question-answering, si...</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RLAIF...</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>{'license': 'cc-by-nc-4.0', 'task_categories':...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2024-05-19T15:34:55.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>655b26e86a7098bc6e6f99e6</td>\n",
       "      <td>Lin-Chen/ShareGPT4V</td>\n",
       "      <td>Lin-Chen</td>\n",
       "      <td>731e581f7dad9ac5e6458395ce1ba731975a78f6</td>\n",
       "      <td>2024-05-27T07:32:48.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[task_categories:visual-question-answering, ta...</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT4V 1.2M Datase...</td>\n",
       "      <td>5901</td>\n",
       "      <td>218</td>\n",
       "      <td>{'license': 'cc-by-nc-4.0', 'task_categories':...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-11-20T09:29:12.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>643dda8f317127fb1e30b27b</td>\n",
       "      <td>liuhaotian/LLaVA-Instruct-150K</td>\n",
       "      <td>liuhaotian</td>\n",
       "      <td>9d451dc7629cfe0469f6ae4432b765cd603d5fcb</td>\n",
       "      <td>2024-01-03T01:59:20.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[task_categories:visual-question-answering, ta...</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLaVA Visual Instruct ...</td>\n",
       "      <td>186</td>\n",
       "      <td>364</td>\n",
       "      <td>{'license': 'cc-by-4.0', 'task_categories': ['...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-04-17T23:47:27.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6564d741cfdc8b6433bfba49</td>\n",
       "      <td>MMMU/MMMU</td>\n",
       "      <td>MMMU</td>\n",
       "      <td>d77f80e9578e1c8f8dfcdacf57eec983f9cd93ad</td>\n",
       "      <td>2024-05-30T09:32:35.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[task_categories:question-answering, task_cate...</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-...</td>\n",
       "      <td>184369</td>\n",
       "      <td>143</td>\n",
       "      <td>{'language': ['en'], 'license': 'apache-2.0', ...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-11-27T17:52:01.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6590008ac04427eb3871a8a1</td>\n",
       "      <td>openbmb/RLHF-V-Dataset</td>\n",
       "      <td>openbmb</td>\n",
       "      <td>1d8e9804b59e9da64ad7b1e17d505869ab9b2ad3</td>\n",
       "      <td>2024-05-28T04:31:38.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[task_categories:text-generation, task_categor...</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RLHF-...</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>{'license': 'cc-by-nc-4.0', 'task_categories':...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-12-30T11:35:38.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                              id      author  \\\n",
       "0  664a1c1f4fa4afb446afa8f7         openbmb/RLAIF-V-Dataset     openbmb   \n",
       "1  655b26e86a7098bc6e6f99e6             Lin-Chen/ShareGPT4V    Lin-Chen   \n",
       "2  643dda8f317127fb1e30b27b  liuhaotian/LLaVA-Instruct-150K  liuhaotian   \n",
       "3  6564d741cfdc8b6433bfba49                       MMMU/MMMU        MMMU   \n",
       "4  6590008ac04427eb3871a8a1          openbmb/RLHF-V-Dataset     openbmb   \n",
       "\n",
       "                                        sha              lastModified  \\\n",
       "0  d2726fcfdb37fba679e7ccdf31e23f09e869b0f0  2024-05-28T04:25:05.000Z   \n",
       "1  731e581f7dad9ac5e6458395ce1ba731975a78f6  2024-05-27T07:32:48.000Z   \n",
       "2  9d451dc7629cfe0469f6ae4432b765cd603d5fcb  2024-01-03T01:59:20.000Z   \n",
       "3  d77f80e9578e1c8f8dfcdacf57eec983f9cd93ad  2024-05-30T09:32:35.000Z   \n",
       "4  1d8e9804b59e9da64ad7b1e17d505869ab9b2ad3  2024-05-28T04:31:38.000Z   \n",
       "\n",
       "   private  gated  disabled  \\\n",
       "0    False  False     False   \n",
       "1    False  False     False   \n",
       "2    False  False     False   \n",
       "3    False  False     False   \n",
       "4    False  False     False   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [task_categories:visual-question-answering, si...   \n",
       "1  [task_categories:visual-question-answering, ta...   \n",
       "2  [task_categories:visual-question-answering, ta...   \n",
       "3  [task_categories:question-answering, task_cate...   \n",
       "4  [task_categories:text-generation, task_categor...   \n",
       "\n",
       "                                         description  downloads  likes  \\\n",
       "0  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RLAIF...         75     60   \n",
       "1  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT4V 1.2M Datase...       5901    218   \n",
       "2  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLaVA Visual Instruct ...        186    364   \n",
       "3  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-...     184369    143   \n",
       "4  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RLHF-...          1     27   \n",
       "\n",
       "                                            cardData  \\\n",
       "0  {'license': 'cc-by-nc-4.0', 'task_categories':...   \n",
       "1  {'license': 'cc-by-nc-4.0', 'task_categories':...   \n",
       "2  {'license': 'cc-by-4.0', 'task_categories': ['...   \n",
       "3  {'language': ['en'], 'license': 'apache-2.0', ...   \n",
       "4  {'license': 'cc-by-nc-4.0', 'task_categories':...   \n",
       "\n",
       "                                            siblings  \\\n",
       "0  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "1  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "2  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "3  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "4  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "\n",
       "                  createdAt paperswithcode_id citation  \n",
       "0  2024-05-19T15:34:55.000Z               NaN      NaN  \n",
       "1  2023-11-20T09:29:12.000Z               NaN      NaN  \n",
       "2  2023-04-17T23:47:27.000Z               NaN      NaN  \n",
       "3  2023-11-27T17:52:01.000Z               NaN      NaN  \n",
       "4  2023-12-30T11:35:38.000Z               NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _id   id   author   tags   description   downloads   likes   createdAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_categories:multiple-choice',\n",
       " 'task_categories:question-answering',\n",
       " 'task_categories:visual-question-answering',\n",
       " 'size_categories:1K<n<10K',\n",
       " 'language:en',\n",
       " 'croissant',\n",
       " 'arxiv:2403.14624',\n",
       " 'region:us']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_task_categories(tags):\n",
    "    return [tag[16:] for tag in tags if 'task_categories' in tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df['tags'].apply(filter_task_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>sha</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>disabled</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>cardData</th>\n",
       "      <th>siblings</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>paperswithcode_id</th>\n",
       "      <th>citation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>622527838dc6b0b64f5e9094</td>\n",
       "      <td>gustavecortal/fr_covid_news</td>\n",
       "      <td>gustavecortal</td>\n",
       "      <td>5e8f91d26c84fea6bb72e4172fff39ec1e6a0cc2</td>\n",
       "      <td>2024-02-23T13:38:53.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[text2text-generation, text-generation, tabula...</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COVID...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'annotations_creators': ['machine-generated']...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2022-03-06T21:28:35.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>621ffdd236468d709f181fc5</td>\n",
       "      <td>nakhun/thaisum</td>\n",
       "      <td>nakhun</td>\n",
       "      <td>616357f471a24974284b7066056d5b17ac9bc7d5</td>\n",
       "      <td>2024-01-18T11:17:07.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[summarization, text-generation, fill-mask]</td>\n",
       "      <td>ThaiSum is a large-scale corpus for Thai text ...</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>{'annotations_creators': ['no-annotation'], 'l...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2022-03-02T23:29:22.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@mastersthesis{chumpolsathien_2020,\\n    title...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>64b9b9dc84ddd52599c13626</td>\n",
       "      <td>d0rj/dolphin-ru</td>\n",
       "      <td>d0rj</td>\n",
       "      <td>1f179039cc6a64b7e8ccaca0793bbbe0bf880c1d</td>\n",
       "      <td>2023-07-26T14:54:29.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[text-classification, token-classification, ta...</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDolphin-ru 🐬\\n\\t\\n\\nTh...</td>\n",
       "      <td>101</td>\n",
       "      <td>6</td>\n",
       "      <td>{'language_creators': ['translated'], 'languag...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-07-20T22:49:00.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>6633acd37430b79b6dc0f9d6</td>\n",
       "      <td>sentence-transformers/msmarco-co-condenser-mar...</td>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>84ed2d35626f617d890bd493b4d6db69a741e0e2</td>\n",
       "      <td>2024-05-15T14:24:09.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[feature-extraction, sentence-similarity]</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMS MARCO with hard neg...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>{'language': ['en'], 'multilinguality': ['mono...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2024-05-02T15:10:11.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>637c8ae7caabb38c460567b1</td>\n",
       "      <td>DTU54DL/demo-common-whisper</td>\n",
       "      <td>DTU54DL</td>\n",
       "      <td>4907bc207705a1da6e08dcd60ee01832a3c012ac</td>\n",
       "      <td>2022-11-22T08:43:39.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[token-classification]</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Data...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'annotations_creators': ['expert-generated'],...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2022-11-22T08:40:07.000Z</td>\n",
       "      <td>acronym-identification</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id  \\\n",
       "4141  622527838dc6b0b64f5e9094   \n",
       "4104  621ffdd236468d709f181fc5   \n",
       "4430  64b9b9dc84ddd52599c13626   \n",
       "5688  6633acd37430b79b6dc0f9d6   \n",
       "2841  637c8ae7caabb38c460567b1   \n",
       "\n",
       "                                                     id  \\\n",
       "4141                        gustavecortal/fr_covid_news   \n",
       "4104                                     nakhun/thaisum   \n",
       "4430                                    d0rj/dolphin-ru   \n",
       "5688  sentence-transformers/msmarco-co-condenser-mar...   \n",
       "2841                        DTU54DL/demo-common-whisper   \n",
       "\n",
       "                     author                                       sha  \\\n",
       "4141          gustavecortal  5e8f91d26c84fea6bb72e4172fff39ec1e6a0cc2   \n",
       "4104                 nakhun  616357f471a24974284b7066056d5b17ac9bc7d5   \n",
       "4430                   d0rj  1f179039cc6a64b7e8ccaca0793bbbe0bf880c1d   \n",
       "5688  sentence-transformers  84ed2d35626f617d890bd493b4d6db69a741e0e2   \n",
       "2841                DTU54DL  4907bc207705a1da6e08dcd60ee01832a3c012ac   \n",
       "\n",
       "                  lastModified  private  gated  disabled  \\\n",
       "4141  2024-02-23T13:38:53.000Z    False  False     False   \n",
       "4104  2024-01-18T11:17:07.000Z    False  False     False   \n",
       "4430  2023-07-26T14:54:29.000Z    False  False     False   \n",
       "5688  2024-05-15T14:24:09.000Z    False  False     False   \n",
       "2841  2022-11-22T08:43:39.000Z    False  False     False   \n",
       "\n",
       "                                                   tags  \\\n",
       "4141  [text2text-generation, text-generation, tabula...   \n",
       "4104        [summarization, text-generation, fill-mask]   \n",
       "4430  [text-classification, token-classification, ta...   \n",
       "5688          [feature-extraction, sentence-similarity]   \n",
       "2841                             [token-classification]   \n",
       "\n",
       "                                            description  downloads  likes  \\\n",
       "4141  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for COVID...          5      1   \n",
       "4104  ThaiSum is a large-scale corpus for Thai text ...         14     10   \n",
       "4430  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDolphin-ru 🐬\\n\\t\\n\\nTh...        101      6   \n",
       "5688  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMS MARCO with hard neg...          5      0   \n",
       "2841  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for [Data...          0      0   \n",
       "\n",
       "                                               cardData  \\\n",
       "4141  {'annotations_creators': ['machine-generated']...   \n",
       "4104  {'annotations_creators': ['no-annotation'], 'l...   \n",
       "4430  {'language_creators': ['translated'], 'languag...   \n",
       "5688  {'language': ['en'], 'multilinguality': ['mono...   \n",
       "2841  {'annotations_creators': ['expert-generated'],...   \n",
       "\n",
       "                                               siblings  \\\n",
       "4141  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "4104  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "4430  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "5688  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "2841  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "\n",
       "                     createdAt       paperswithcode_id  \\\n",
       "4141  2022-03-06T21:28:35.000Z                     NaN   \n",
       "4104  2022-03-02T23:29:22.000Z                     NaN   \n",
       "4430  2023-07-20T22:49:00.000Z                     NaN   \n",
       "5688  2024-05-02T15:10:11.000Z                     NaN   \n",
       "2841  2022-11-22T08:40:07.000Z  acronym-identification   \n",
       "\n",
       "                                               citation  \n",
       "4141                                                NaN  \n",
       "4104  @mastersthesis{chumpolsathien_2020,\\n    title...  \n",
       "4430                                                NaN  \n",
       "5688                                                NaN  \n",
       "2841                                                NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7329, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Total Values</th>\n",
       "      <th>Percentage Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <td>_id</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>author</td>\n",
       "      <td>233</td>\n",
       "      <td>7329</td>\n",
       "      <td>3.179151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sha</th>\n",
       "      <td>sha</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lastModified</th>\n",
       "      <td>lastModified</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private</th>\n",
       "      <td>private</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gated</th>\n",
       "      <td>gated</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disabled</th>\n",
       "      <td>disabled</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>tags</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>description</td>\n",
       "      <td>461</td>\n",
       "      <td>7329</td>\n",
       "      <td>6.290081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>downloads</th>\n",
       "      <td>downloads</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>likes</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardData</th>\n",
       "      <td>cardData</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siblings</th>\n",
       "      <td>siblings</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>createdAt</th>\n",
       "      <td>createdAt</td>\n",
       "      <td>0</td>\n",
       "      <td>7329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paperswithcode_id</th>\n",
       "      <td>paperswithcode_id</td>\n",
       "      <td>6556</td>\n",
       "      <td>7329</td>\n",
       "      <td>89.452859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citation</th>\n",
       "      <td>citation</td>\n",
       "      <td>5652</td>\n",
       "      <td>7329</td>\n",
       "      <td>77.118297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Column  Missing Values  Total Values  \\\n",
       "_id                              _id               0          7329   \n",
       "id                                id               0          7329   \n",
       "author                        author             233          7329   \n",
       "sha                              sha               0          7329   \n",
       "lastModified            lastModified               0          7329   \n",
       "private                      private               0          7329   \n",
       "gated                          gated               0          7329   \n",
       "disabled                    disabled               0          7329   \n",
       "tags                            tags               0          7329   \n",
       "description              description             461          7329   \n",
       "downloads                  downloads               0          7329   \n",
       "likes                          likes               0          7329   \n",
       "cardData                    cardData               0          7329   \n",
       "siblings                    siblings               0          7329   \n",
       "createdAt                  createdAt               0          7329   \n",
       "paperswithcode_id  paperswithcode_id            6556          7329   \n",
       "citation                    citation            5652          7329   \n",
       "\n",
       "                   Percentage Missing  \n",
       "_id                          0.000000  \n",
       "id                           0.000000  \n",
       "author                       3.179151  \n",
       "sha                          0.000000  \n",
       "lastModified                 0.000000  \n",
       "private                      0.000000  \n",
       "gated                        0.000000  \n",
       "disabled                     0.000000  \n",
       "tags                         0.000000  \n",
       "description                  6.290081  \n",
       "downloads                    0.000000  \n",
       "likes                        0.000000  \n",
       "cardData                     0.000000  \n",
       "siblings                     0.000000  \n",
       "createdAt                    0.000000  \n",
       "paperswithcode_id           89.452859  \n",
       "citation                    77.118297  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing Values': df.isna().sum(),\n",
    "    'Total Values': len(df),\n",
    "    'Percentage Missing': (df.isna().sum() / len(df)) * 100\n",
    "})\n",
    "\n",
    "missing_values_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['paperswithcode_id' ,'citation'] ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Total Values</th>\n",
       "      <th>Percentage Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <td>_id</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>author</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sha</th>\n",
       "      <td>sha</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lastModified</th>\n",
       "      <td>lastModified</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private</th>\n",
       "      <td>private</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gated</th>\n",
       "      <td>gated</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disabled</th>\n",
       "      <td>disabled</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>tags</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>description</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>downloads</th>\n",
       "      <td>downloads</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>likes</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardData</th>\n",
       "      <td>cardData</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siblings</th>\n",
       "      <td>siblings</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>createdAt</th>\n",
       "      <td>createdAt</td>\n",
       "      <td>0</td>\n",
       "      <td>6635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Column  Missing Values  Total Values  Percentage Missing\n",
       "_id                    _id               0          6635                 0.0\n",
       "id                      id               0          6635                 0.0\n",
       "author              author               0          6635                 0.0\n",
       "sha                    sha               0          6635                 0.0\n",
       "lastModified  lastModified               0          6635                 0.0\n",
       "private            private               0          6635                 0.0\n",
       "gated                gated               0          6635                 0.0\n",
       "disabled          disabled               0          6635                 0.0\n",
       "tags                  tags               0          6635                 0.0\n",
       "description    description               0          6635                 0.0\n",
       "downloads        downloads               0          6635                 0.0\n",
       "likes                likes               0          6635                 0.0\n",
       "cardData          cardData               0          6635                 0.0\n",
       "siblings          siblings               0          6635                 0.0\n",
       "createdAt        createdAt               0          6635                 0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing Values': df.isna().sum(),\n",
    "    'Total Values': len(df),\n",
    "    'Percentage Missing': (df.isna().sum() / len(df)) * 100\n",
    "})\n",
    "\n",
    "missing_values_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "694"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7329 - 6635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the DataFrame\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6635, 15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepvk'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'][28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(len(df)):\n",
    "    if 'Dataset Card' in df['description'][i]:\n",
    "        x.append(1)\n",
    "    else:\n",
    "        x.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6635, 6635)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x) ,df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI)\\n\\t\\n\\n🌐 Homepage | 🤗 Dataset | 🤗 Paper | 📖 arXiv | GitHub\\n\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t🔔News\\n\\t\\n\\n\\n🛠️[2024-05-30]: Fixed duplicate option issues in Materials dataset items (validation_Materials_25; test_Materials_17, 242) and content error in validation_Materials_25.\\n🛠️[2024-04-30]: Fixed missing \"-\" or \"^\" signs in Math dataset items (dev_Math_2, validation_Math_11, 12, 16; test_Math_8, 23, 43, 113… See the full description on the dataset page: https://huggingface.co/datasets/MMMU/MMMU.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>sha</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>disabled</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>cardData</th>\n",
       "      <th>siblings</th>\n",
       "      <th>createdAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>664a1c1f4fa4afb446afa8f7</td>\n",
       "      <td>openbmb/RLAIF-V-Dataset</td>\n",
       "      <td>openbmb</td>\n",
       "      <td>d2726fcfdb37fba679e7ccdf31e23f09e869b0f0</td>\n",
       "      <td>2024-05-28T04:25:05.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[visual-question-answering]</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RLAIF...</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>{'license': 'cc-by-nc-4.0', 'task_categories':...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2024-05-19T15:34:55.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>655b26e86a7098bc6e6f99e6</td>\n",
       "      <td>Lin-Chen/ShareGPT4V</td>\n",
       "      <td>Lin-Chen</td>\n",
       "      <td>731e581f7dad9ac5e6458395ce1ba731975a78f6</td>\n",
       "      <td>2024-05-27T07:32:48.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[visual-question-answering, question-answering]</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT4V 1.2M Datase...</td>\n",
       "      <td>5901</td>\n",
       "      <td>218</td>\n",
       "      <td>{'license': 'cc-by-nc-4.0', 'task_categories':...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-11-20T09:29:12.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>643dda8f317127fb1e30b27b</td>\n",
       "      <td>liuhaotian/LLaVA-Instruct-150K</td>\n",
       "      <td>liuhaotian</td>\n",
       "      <td>9d451dc7629cfe0469f6ae4432b765cd603d5fcb</td>\n",
       "      <td>2024-01-03T01:59:20.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[visual-question-answering, question-answering]</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLaVA Visual Instruct ...</td>\n",
       "      <td>186</td>\n",
       "      <td>364</td>\n",
       "      <td>{'license': 'cc-by-4.0', 'task_categories': ['...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-04-17T23:47:27.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6564d741cfdc8b6433bfba49</td>\n",
       "      <td>MMMU/MMMU</td>\n",
       "      <td>MMMU</td>\n",
       "      <td>d77f80e9578e1c8f8dfcdacf57eec983f9cd93ad</td>\n",
       "      <td>2024-05-30T09:32:35.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[question-answering, visual-question-answering...</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-...</td>\n",
       "      <td>184369</td>\n",
       "      <td>143</td>\n",
       "      <td>{'language': ['en'], 'license': 'apache-2.0', ...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-11-27T17:52:01.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6590008ac04427eb3871a8a1</td>\n",
       "      <td>openbmb/RLHF-V-Dataset</td>\n",
       "      <td>openbmb</td>\n",
       "      <td>1d8e9804b59e9da64ad7b1e17d505869ab9b2ad3</td>\n",
       "      <td>2024-05-28T04:31:38.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[text-generation, visual-question-answering]</td>\n",
       "      <td>\\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RLHF-...</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>{'license': 'cc-by-nc-4.0', 'task_categories':...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-12-30T11:35:38.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                              id      author  \\\n",
       "0  664a1c1f4fa4afb446afa8f7         openbmb/RLAIF-V-Dataset     openbmb   \n",
       "1  655b26e86a7098bc6e6f99e6             Lin-Chen/ShareGPT4V    Lin-Chen   \n",
       "2  643dda8f317127fb1e30b27b  liuhaotian/LLaVA-Instruct-150K  liuhaotian   \n",
       "3  6564d741cfdc8b6433bfba49                       MMMU/MMMU        MMMU   \n",
       "4  6590008ac04427eb3871a8a1          openbmb/RLHF-V-Dataset     openbmb   \n",
       "\n",
       "                                        sha              lastModified  \\\n",
       "0  d2726fcfdb37fba679e7ccdf31e23f09e869b0f0  2024-05-28T04:25:05.000Z   \n",
       "1  731e581f7dad9ac5e6458395ce1ba731975a78f6  2024-05-27T07:32:48.000Z   \n",
       "2  9d451dc7629cfe0469f6ae4432b765cd603d5fcb  2024-01-03T01:59:20.000Z   \n",
       "3  d77f80e9578e1c8f8dfcdacf57eec983f9cd93ad  2024-05-30T09:32:35.000Z   \n",
       "4  1d8e9804b59e9da64ad7b1e17d505869ab9b2ad3  2024-05-28T04:31:38.000Z   \n",
       "\n",
       "   private  gated  disabled  \\\n",
       "0    False  False     False   \n",
       "1    False  False     False   \n",
       "2    False  False     False   \n",
       "3    False  False     False   \n",
       "4    False  False     False   \n",
       "\n",
       "                                                tags  \\\n",
       "0                        [visual-question-answering]   \n",
       "1    [visual-question-answering, question-answering]   \n",
       "2    [visual-question-answering, question-answering]   \n",
       "3  [question-answering, visual-question-answering...   \n",
       "4       [text-generation, visual-question-answering]   \n",
       "\n",
       "                                         description  downloads  likes  \\\n",
       "0  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RLAIF...         75     60   \n",
       "1  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tShareGPT4V 1.2M Datase...       5901    218   \n",
       "2  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tLLaVA Visual Instruct ...        186    364   \n",
       "3  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tMMMU (A Massive Multi-...     184369    143   \n",
       "4  \\n\\t\\n\\t\\t\\n\\t\\n\\t\\n\\t\\tDataset Card for RLHF-...          1     27   \n",
       "\n",
       "                                            cardData  \\\n",
       "0  {'license': 'cc-by-nc-4.0', 'task_categories':...   \n",
       "1  {'license': 'cc-by-nc-4.0', 'task_categories':...   \n",
       "2  {'license': 'cc-by-4.0', 'task_categories': ['...   \n",
       "3  {'language': ['en'], 'license': 'apache-2.0', ...   \n",
       "4  {'license': 'cc-by-nc-4.0', 'task_categories':...   \n",
       "\n",
       "                                            siblings                 createdAt  \n",
       "0  [{'rfilename': '.gitattributes'}, {'rfilename'...  2024-05-19T15:34:55.000Z  \n",
       "1  [{'rfilename': '.gitattributes'}, {'rfilename'...  2023-11-20T09:29:12.000Z  \n",
       "2  [{'rfilename': '.gitattributes'}, {'rfilename'...  2023-04-17T23:47:27.000Z  \n",
       "3  [{'rfilename': '.gitattributes'}, {'rfilename'...  2023-11-27T17:52:01.000Z  \n",
       "4  [{'rfilename': '.gitattributes'}, {'rfilename'...  2023-12-30T11:35:38.000Z  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in /home/adarsh/.local/lib/python3.10/site-packages (2.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in /home/adarsh/.local/lib/python3.10/site-packages (from emoji) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "def clean_text(text):\n",
    "    # Remove newlines and tabs\n",
    "    text = text.replace('\\n', ' ').replace('\\t', ' ')\n",
    "    # Remove 'Dataset Card'\n",
    "    text = text.replace('Dataset Card', ' ')\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    # Remove emojis\n",
    "    text = emoji.replace_emoji(text, replace=' ')\n",
    "    # Remove special characters, keeping only alphanumeric and space\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openbmb/RLHF-V-Dataset'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for rlhf v dataset project page paper github updates 2024 05 28 our rlaif v paper is accesible at arxiv now 2024 05 20 we release a new feedback dataset rlaif v dataset which is a large scale diverse task multimodal feedback dataset constructed using open source models you can download the corresponding dataset and models 7b 12b now 2024 04 11 our data is used in minicpm v 2 0 an end side multimodal large language see the full description on the dataset page'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moondream2 coyo 700m 5m subset captions a 5 million image text pair subset of coyo 700m dataset captioned with moondream2 rev 2024 05 08 captioning question is write a long caption for this image given the alt text alt text sampling conditions randomly sampled from 5 million images from coyo 700m images that fit to the following filters filters width 256 height 256 aesthetic score laion v2 5 2 see the full description on the dataset page\n",
      "\n",
      "open llava next 1m dataset details dataset type 1m sft data for re producing llava next series we augmented the sharegpt4v mix665k dataset with additional data we have made every effort to align our training data with that of llava next however we were unable to access the tens of thousands of real user interaction data that llava next collected as a result we used 200k allava instruct vflan 4v data as a substitute additionally since textvqa see the full description on the dataset page\n",
      "\n",
      "creation guide dataset summary learn to explain multimodal reasoning via thought chains for science question answering supported tasks and leaderboards multi modal multiple choice languages english dataset structure data instances explore more samples here image image question which of these states is farthest north choices west virginia louisiana arizona see the full description on the dataset page\n",
      "\n",
      "for mathvista dataset description paper information dataset examples leaderboard dataset usage data downloading data format data visualization data source automatic evaluation license citation dataset description mathvista is a consolidated mathematical reasoning benchmark within visual contexts it consists of three newly created datasets iqtest functionqa and paperqa which address the missing visual domains and are tailored to evaluate see the full description on the dataset page\n",
      "\n",
      "measuring multimodal mathematical reasoning with math vision dataset homepage arxiv paper huggingface dataset github data usage from datasets import load dataset dataset load dataset mathllms mathvision print dataset introduction recent advancements in large multimodal models lmms have shown promising results in mathematical reasoning within visual contexts with models approaching human level performance on existing benchmarks see the full description on the dataset page\n",
      "\n",
      "for mathverse dataset description paper information dataset examples leaderboard citation dataset description the capabilities of multi modal large language models mllms in visual math problem solving remain insufficiently evaluated and understood we investigate current benchmarks to incorporate excessive visual content within textual questions which potentially assist mllms in deducing answers without truly interpreting the input diagrams see the full description on the dataset page\n",
      "\n",
      "mmstar are we on the right way for evaluating large vision language models homepage dataset paper arxiv github dataset details as shown in the figure below existing benchmarks lack consideration of the vision dependency of evaluation samples and potential data leakage from llms and lvlms training data therefore we introduce mmstar an elite vision indispensible multi modal benchmark aiming to ensure each curated sample see the full description on the dataset page\n",
      "\n",
      "llava instruct ru dataset similar to llava instruct but in russian we follow the original pipeline to generate data and collect instruction with conversation and complex reasoning types for more details see original paper each row has 4 fields type conversation or complex reasoning conversations a list of dictionaries with utterances each utterance contains from and value keys id image identifier in coco not unique image path to the image in coco dataset each see the full description on the dataset page\n",
      "\n",
      "this dataset is composed by 1k examples of english visual instruction data from llava 1k examples of english visual instruction data from openbmb you can organize content in the dataset info json in llama factory like this llava 1k en hf hub url buaadreamer llava en zh 2k subset en formatting sharegpt columns messages messages images images tags role tag role content tag content see the full description on the dataset page\n",
      "\n",
      "m4u evaluating multilingual understanding and reasoning for large multimodal models code for the paper m4u evaluating multilingual understanding and reasoning for large multimodal models webpage paper huggingface dataset leaderboard news 2024 05 23 our paper dataset and code are public aviailable about m4u multilingual multimodal reasoning is a core component to achieve human level intelligence however most of see the full description on the dataset page\n",
      "\n",
      "img2latex 1 latex ko 1 1 im2latex 230k llava llava kollava\n",
      "\n",
      "textvqa requires models to read and reason about text in images to answer questions about them specifically models need to incorporate a new modality of text present in the images and reason over it to answer textvqa questions textvqa dataset contains 45 336 questions over 28 408 images from the openimages dataset\n",
      "\n",
      "for pathvqa dataset description pathvqa is a dataset of question answer pairs on pathology images the dataset is intended to be used for training and testing medical visual question answering vqa systems the dataset includes both open ended questions and binary yes no questions the dataset is built from two publicly available pathology textbooks textbook of pathology and basic pathology and a publicly available digital library see the full description on the dataset page\n",
      "\n",
      "dataoptim dataoptim is a data repository designed to offer an optimized solution for utilizing training data in multimodal large language models mllms efficiently github datasets currently the visual instruction tuning data contain 20 public datasets more datasets are coming in the future category dataset images samples split image captioning coco 82783 414113 train image captioning flickr30k see the full description on the dataset page\n",
      "\n",
      "kollava v1 5 visual instruct 581k llava v1 5 instruction following data feat deepl kollava repo\n",
      "\n",
      "image2structure latex dataset description we introduce image2structure a dataset to evaluate the capabilities of multimodel models to learn the structure of a document this subdataset focuses on latex code the model is given an image of the expected output with the prompt prease provide the latex code used to generate this image only generate the code relevant to what you see your code will be surrounded by all the imports necessary as well as the begin see the full description on the dataset page\n",
      "\n",
      "bunny v1 0 technical report bunny v1 0 3b code demo bunny is a family of lightweight multimodal models bunny v1 0 data is the training dataset for bunny v1 0 series including bunny v1 0 3b pretrain we use a high quality coreset with less duplicates and more informative samples of laion 2b built by this work we randomly sample 2 million image text pairs from the coreset and convert them to training format the pretraining data and see the full description on the dataset page\n",
      "\n",
      "visual question answering dataset based on localized narratives please cite their paper if you use this dataset in your research\n",
      "\n",
      "realworldqa dataset this is the benchmark dataset released by xai along with the grok 1 5 vision announcement this benchmark is designed to evaluate basic real world spatial understanding capabilities of multimodal models while many of the examples in the current benchmark are relatively easy for humans they often pose a challenge for frontier models this release of the realworldqa consists of 765 images with a question and easily verifiable answer for each image the see the full description on the dataset page\n",
      "\n",
      "gqa ru this is translated version of original gqa dataset and stored in format supported for lmms eval pipeline for this dataset we translate the original one with gpt 4 turbo filter out unsuccessful translations i e where the model protection was triggered manually validate most common errors citation inproceedings hudson2019gqa title gqa a new dataset for real world visual reasoning and compositional question answering author hudson drew a see the full description on the dataset page\n",
      "\n",
      "shot2story a new benchmark for comprehensive understanding of multi shot videos for video data downloading please have a look at this issue we are excited to release a new video text benchmark for multi shot video understanding this release contains a 134k version of our dataset it includes detailed long summaries human annotated gptv generated for 134k videos and shot captions human annotated for 188k video shots annotation format our 134k see the full description on the dataset page\n",
      "\n",
      "for tablevqa bench more information needed\n",
      "\n",
      "this chinese dataset was translated from llava med using qwen1 5 14b chat and contains 60k medical visual instruction data points you can organize content in the dataset info json in llama factory like this llava med zh 60k hf hub url buaadreamer llava med zh instruct 60k formatting sharegpt columns messages messages images images tags role tag role content tag content user tag user assistant tag see the full description on the dataset page\n",
      "\n",
      "mmbench ru this is translated version of original mmbench dataset and stored in format supported for lmms eval pipeline for this dataset we translate the original one with gpt 4o filter out unsuccessful translations i e where the model protection was triggered manually validate most common errors citation article mmbench author yuan liu haodong duan yuanhan zhang bo li songyang zhang wangbo zhao yike yuan jiaqi wang conghui he ziwei liu see the full description on the dataset page\n",
      "\n",
      "seed bench h card benchmark details benchmark type seed bench h is a large scale benchmark to evaluate multimodal large language models mllms it consists of 28k multiple choice questions with precise human annotations spanning 34 dimensions including the evaluation of both text and image generation benchmark date seed bench h was collected in april 2024 paper or resources for more information license see the full description on the dataset page\n",
      "\n",
      "for compguesswhat dataset summary compguesswhat is an instance of a multi task framework for evaluating the quality of learned neural representations in particular concerning attribute grounding use this dataset if you want to use the set of games whose reference scene is an image in visualgenome visit the website for more details supported tasks and leaderboards more information needed see the full description on the dataset page\n",
      "\n",
      "visual genome enable to model objects and relationships between objects they collect dense annotations of objects attributes and relationships within each image specifically the dataset contains over 108k images where each image has an average of 35 objects 26 attributes and 21 pairwise relationships between objects\n",
      "\n",
      "the tumblr gif tgif dataset contains 100k animated gifs and 120k sentences describing visual content of the animated gifs the animated gifs have been collected from tumblr from randomly selected posts published between may and june of 2015 we provide the urls of animated gifs in this release the sentences are collected via crowdsourcing with a carefully designed annotationinterface that ensures high quality dataset we provide one sentence per animated gif for the training and validation splits and three sentences per gif for the test split the dataset shall be used to evaluate animated gif video description techniques\n",
      "\n",
      "the tumblr gif tgif dataset contains 100k animated gifs and 120k sentences describing visual content of the animated gifs the animated gifs have been collected from tumblr from randomly selected posts published between may and june of 2015 we provide the urls of animated gifs in this release the sentences are collected via crowdsourcing with a carefully designed annotationinterface that ensures high quality dataset we provide one sentence per animated gif for the training and validation splits and three sentences per gif for the test split the dataset shall be used to evaluate animated gif video description techniques\n",
      "\n",
      "update oct 2023 add v2 with recent sota model swinv2 classifier for both soft hard label visual caption cosine score v2 with person label 0 2 0 3 and 0 4 introduction modern image captaining relies heavily on extracting knowledge from images such as objects to capture the concept of static story in the image in this paper we propose a textual visual context dataset for captioning where the publicly available dataset coco caption lin et al 2014 has see the full description on the dataset page\n",
      "\n",
      "clevr math is a dataset for compositional language visual and mathematical reasoning clevr math poses questions about mathematical operations on visual scenes using subtraction and addition such as remove all large red cylinders how many objects are left there are also adversarial e g remove all blue cubes how many cylinders are left and multihop questions e g remove all blue cubes remove all small purple spheres how many objects are left\n",
      "\n",
      "for new yorker caption contest benchmarks dataset summary see capcon dev for more data from do androids laugh at electric sheep humor understanding benchmarks from the new yorker caption contest inproceedings hessel2023androids title do androids laugh at electric sheep humor understanding benchmarks from the new yorker caption contest author hessel jack and marasovi c ana and hwang jena d and lee lillian see the full description on the dataset page\n",
      "\n",
      "the youtube transcriptions dataset contains technical tutorials currently from james briggs daniel bourke and ai coffee break transcribed using openai s whisper large each row represents roughly a sentence length chunk of text alongside the video url and timestamp note that each item in the dataset contains just a short chunk of text for most use cases you will likely need to merge multiple rows to create more substantial chunks of text if you need to do that this code snippet will see the full description on the dataset page\n",
      "\n",
      "for wsdmcup2023 question image and answer what do you use to hit the ball what do people use for cutting what do we use to support the immune system and get vitamin c dataset summary the wsdmcup2023 dataset consists of images associated with textual questions one entry instance in our dataset is a question image pair labeled with the ground truth coordinates of a bounding box containing the visual answer to the given see the full description on the dataset page\n",
      "\n",
      "for plotqa dataset summary plotqa is a vqa dataset with 28 9 million question answer pairs grounded over 224 377 plots on data from real world sources and questions based on crowd sourced question templates dataset structure data fields list and describe the fields present in the dataset mention their data type and whether they are used as input or output in any of the tasks the dataset currently supports if the data see the full description on the dataset page\n",
      "\n",
      "\n",
      "\n",
      "for bilbaoqa dataset summary this dataset was collected for a proyect for a master degree in computation and intelligent system from university of deusto it was done by students and recolected from webpages famous in the basque country deia and getimages the questions and answers were created using a set of models that are able to generate this information from a description of a text supported tasks and leaderboards the dataset see the full description on the dataset page\n",
      "\n",
      "for bilbaoqa2 dataset summary this dataset was collected for a proyect for a master degree in computation and intelligent system from university of deusto it was done by students and recolected from webpages famous in the basque country deia and getimages the questions and answers were created using a set of models that are able to generate this information from a description of a text supported tasks and leaderboards the dataset see the full description on the dataset page\n",
      "\n",
      "for scienceqa dataset summary scienceqa is collected from elementary and high school science curricula and contains 21 208 multimodal multiple choice science questions out of the questions in scienceqa 10 332 48 7 have an image context 10 220 48 2 have a text context and 6 532 30 8 have both most questions are annotated with grounded lectures 83 9 and detailed explanations 90 5 the lecture and explanation provide general see the full description on the dataset page\n",
      "\n",
      "for vqa rad dataset description vqa rad is a dataset of question answer pairs on radiology images the dataset is intended to be used for training and testing medical visual question answering vqa systems the dataset includes both open ended questions and binary yes no questions the dataset is built from medpix which is a free open access online database of medical images the question answer pairs were manually generated by a team of see the full description on the dataset page\n",
      "\n",
      "evjvqa multilingual visual question answering abstract visual question answering vqa is a challenging task of natural language processing nlp and computer vision cv attracting significant attention from researchers english is a resource rich language that has witnessed various developments in datasets and models for visual question answering visual question answering in other languages also would be developed for resources and models in addition there see the full description on the dataset page\n",
      "\n",
      "llava visual instruct cc3m 595k pretrain llava cc3m 595k visual instruction dataset ko conceptual captions caption deepl license cc 3m\n",
      "\n",
      "diaccept this is a multimodal dialog dataset for the task of sending an image in an acceptable and relevant situation dataset was annotated using toloka platform how dataset was created we randomly trimmed human chit chat dialogs annotated them to accept the image sent at the end of the dialog generated appropriate captions using vicuna and matched the captions to the appropriate images using clip\n",
      "\n",
      "vqav2 in vietnamese this is google translated version of vqav2 in vietnamese the process of building vietnamese version as follows in en folder download v2 openended mscoco train2014 questions json and v2 mscoco train2014 annotations json from vqav2 remove key answers of key annotations from v2 mscoco train2014 annotations json i shall use key multiple choice answer of key annotations only let call the new file v2 openended mscoco train2014 answers json by using set data see the full description on the dataset page\n",
      "\n",
      "textvqa in vietnamese this is google translated version of textvqa in vietnamese the process of building vietnamese version as follows in en folder download textvqa 0 5 1 train json textvqa 0 5 1 val json by using set data structure generate txt files of unique text train answer list txt train question list txt val answer list txt val question list txt in vi folder by translating 4 en txt files generate train answer list jsonl train question list jsonl see the full description on the dataset page\n",
      "\n",
      "ok vqa in multilang this is google translated versions of ok vqa in many languages each language version stays in each folder the process of building vietnamese version as follows in en folder from ok vqa obtain all json files mscoco train2014 annotations json mscoco val2014 annotations json openended mscoco train2014 questions json openended mscoco val2014 questions json by using set data structure generate txt files of unique text train answer list txt see the full description on the dataset page\n",
      "\n",
      "aasdfsdf\n",
      "\n",
      "llavar data enhanced visual instruction data with text rich images more info at llavar project page github repo and paper training data based on the laion dataset we collect 422k pretraining data based on ocr results for finetuning data we collect 16k high quality instruction following data by interacting with langauge only gpt 4 note that we also release a larger and more diverse finetuning dataset below 20k which contains the 16k we used for the see the full description on the dataset page\n",
      "\n",
      "seed bench card benchmark details benchmark type seed bench is a large scale benchmark to evaluate multimodal large language models mllms it consists of 19k multiple choice questions with accurate human annotations which covers 12 evaluation dimensions including the comprehension of both the image and video modality benchmark date seed bench was collected in july 2023 paper or resources for more information license see the full description on the dataset page\n",
      "\n",
      "for dataset name dataset summary the yttb vqa dataset is a collection of 400 youtube thumbnail question answer pairs to evaluate the visual perception abilities of in text images it covers 11 categories including technology sports entertainment food news history music nature cars and education supported tasks and leaderboards this dataset supports many tasks including visual question answering image captioning etc see the full description on the dataset page\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(df['description'][i+5]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>sha</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>disabled</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>cardData</th>\n",
       "      <th>siblings</th>\n",
       "      <th>createdAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6310</th>\n",
       "      <td>62c86ea24fd4a24e1522a17a</td>\n",
       "      <td>MicPie/unpredictable_cluster18</td>\n",
       "      <td>MicPie</td>\n",
       "      <td>4f8c12a5c28317fceef20e232b0935db46653a70</td>\n",
       "      <td>2022-08-04T19:55:58.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[multiple-choice, question-answering, zero-sho...</td>\n",
       "      <td>the unpredictable dataset consists of web tabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'annotations_creators': ['no-annotation'], 'l...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2022-07-08T17:51:30.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>6559cd74ab0644b531890a31</td>\n",
       "      <td>DBQ/Saint.Laurent.Product.prices.Hong.Kong</td>\n",
       "      <td>DBQ</td>\n",
       "      <td>4e1f793d0e660fee3e65f1c28be502dcddebb283</td>\n",
       "      <td>2023-11-19T08:55:21.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[text-classification, image-classification, fe...</td>\n",
       "      <td>saint laurent web scraped data about the websi...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>{'annotations_creators': ['other'], 'language_...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-11-19T08:55:16.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>63438435f4f36a39f635bf5d</td>\n",
       "      <td>Bioskop/autotrain-data-beccacp</td>\n",
       "      <td>Bioskop</td>\n",
       "      <td>3a206d464eacf0492d232e1a2d80ecfebdd6dc0c</td>\n",
       "      <td>2022-10-10T02:51:18.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[image-classification]</td>\n",
       "      <td>autotrain dataset for project beccacp dataset ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'task_categories': ['image-classification']}</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2022-10-10T02:32:21.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>63b14c67000cd823283954a5</td>\n",
       "      <td>Norod78/microsoft-fluentui-emoji-512-whitebg</td>\n",
       "      <td>Norod78</td>\n",
       "      <td>2f760f5a232b842b788e58adfb533dbf205a8b31</td>\n",
       "      <td>2023-07-16T12:12:01.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[unconditional-image-generation, text-to-image]</td>\n",
       "      <td>for microsoft fluentui emoji 512 whitebg svg a...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>{'language': 'en', 'license': 'mit', 'size_cat...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-01-01T09:03:35.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>65df0d6dbae1dba8d89efb82</td>\n",
       "      <td>projecte-aina/MentorES</td>\n",
       "      <td>projecte-aina</td>\n",
       "      <td>7d67ce045c80f3c4bb85ea5c04a0159e14889ac8</td>\n",
       "      <td>2024-05-30T08:11:48.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[question-answering, summarization, text-gener...</td>\n",
       "      <td>dataset summary mentor es is an open source da...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>{'license': 'cc-by-4.0', 'task_categories': ['...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2024-02-28T10:39:41.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id                                            id  \\\n",
       "6310  62c86ea24fd4a24e1522a17a                MicPie/unpredictable_cluster18   \n",
       "2035  6559cd74ab0644b531890a31    DBQ/Saint.Laurent.Product.prices.Hong.Kong   \n",
       "246   63438435f4f36a39f635bf5d                Bioskop/autotrain-data-beccacp   \n",
       "1816  63b14c67000cd823283954a5  Norod78/microsoft-fluentui-emoji-512-whitebg   \n",
       "3048  65df0d6dbae1dba8d89efb82                        projecte-aina/MentorES   \n",
       "\n",
       "             author                                       sha  \\\n",
       "6310         MicPie  4f8c12a5c28317fceef20e232b0935db46653a70   \n",
       "2035            DBQ  4e1f793d0e660fee3e65f1c28be502dcddebb283   \n",
       "246         Bioskop  3a206d464eacf0492d232e1a2d80ecfebdd6dc0c   \n",
       "1816        Norod78  2f760f5a232b842b788e58adfb533dbf205a8b31   \n",
       "3048  projecte-aina  7d67ce045c80f3c4bb85ea5c04a0159e14889ac8   \n",
       "\n",
       "                  lastModified  private  gated  disabled  \\\n",
       "6310  2022-08-04T19:55:58.000Z    False  False     False   \n",
       "2035  2023-11-19T08:55:21.000Z    False  False     False   \n",
       "246   2022-10-10T02:51:18.000Z    False  False     False   \n",
       "1816  2023-07-16T12:12:01.000Z    False  False     False   \n",
       "3048  2024-05-30T08:11:48.000Z    False  False     False   \n",
       "\n",
       "                                                   tags  \\\n",
       "6310  [multiple-choice, question-answering, zero-sho...   \n",
       "2035  [text-classification, image-classification, fe...   \n",
       "246                              [image-classification]   \n",
       "1816    [unconditional-image-generation, text-to-image]   \n",
       "3048  [question-answering, summarization, text-gener...   \n",
       "\n",
       "                                            description  downloads  likes  \\\n",
       "6310  the unpredictable dataset consists of web tabl...          0      0   \n",
       "2035  saint laurent web scraped data about the websi...          7      0   \n",
       "246   autotrain dataset for project beccacp dataset ...          0      0   \n",
       "1816  for microsoft fluentui emoji 512 whitebg svg a...         18      5   \n",
       "3048  dataset summary mentor es is an open source da...          0      2   \n",
       "\n",
       "                                               cardData  \\\n",
       "6310  {'annotations_creators': ['no-annotation'], 'l...   \n",
       "2035  {'annotations_creators': ['other'], 'language_...   \n",
       "246       {'task_categories': ['image-classification']}   \n",
       "1816  {'language': 'en', 'license': 'mit', 'size_cat...   \n",
       "3048  {'license': 'cc-by-4.0', 'task_categories': ['...   \n",
       "\n",
       "                                               siblings  \\\n",
       "6310  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "2035  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "246   [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "1816  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "3048  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
       "\n",
       "                     createdAt  \n",
       "6310  2022-07-08T17:51:30.000Z  \n",
       "2035  2023-11-19T08:55:16.000Z  \n",
       "246   2022-10-10T02:32:21.000Z  \n",
       "1816  2023-01-01T09:03:35.000Z  \n",
       "3048  2024-02-28T10:39:41.000Z  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(lambda x : x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>sha</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>disabled</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>cardData</th>\n",
       "      <th>siblings</th>\n",
       "      <th>createdAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>664a1c1f4fa4afb446afa8f7</td>\n",
       "      <td>openbmb/RLAIF-V-Dataset</td>\n",
       "      <td>openbmb</td>\n",
       "      <td>d2726fcfdb37fba679e7ccdf31e23f09e869b0f0</td>\n",
       "      <td>2024-05-28T04:25:05.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[visual-question-answering]</td>\n",
       "      <td>[for, rlaif, v, dataset, github, paper, news, ...</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>{'license': 'cc-by-nc-4.0', 'task_categories':...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2024-05-19T15:34:55.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>655b26e86a7098bc6e6f99e6</td>\n",
       "      <td>Lin-Chen/ShareGPT4V</td>\n",
       "      <td>Lin-Chen</td>\n",
       "      <td>731e581f7dad9ac5e6458395ce1ba731975a78f6</td>\n",
       "      <td>2024-05-27T07:32:48.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[visual-question-answering, question-answering]</td>\n",
       "      <td>[sharegpt4v, 1, 2m, dataset, details, dataset,...</td>\n",
       "      <td>5901</td>\n",
       "      <td>218</td>\n",
       "      <td>{'license': 'cc-by-nc-4.0', 'task_categories':...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-11-20T09:29:12.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>643dda8f317127fb1e30b27b</td>\n",
       "      <td>liuhaotian/LLaVA-Instruct-150K</td>\n",
       "      <td>liuhaotian</td>\n",
       "      <td>9d451dc7629cfe0469f6ae4432b765cd603d5fcb</td>\n",
       "      <td>2024-01-03T01:59:20.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[visual-question-answering, question-answering]</td>\n",
       "      <td>[llava, visual, instruct, 150k, dataset, detai...</td>\n",
       "      <td>186</td>\n",
       "      <td>364</td>\n",
       "      <td>{'license': 'cc-by-4.0', 'task_categories': ['...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-04-17T23:47:27.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6564d741cfdc8b6433bfba49</td>\n",
       "      <td>MMMU/MMMU</td>\n",
       "      <td>MMMU</td>\n",
       "      <td>d77f80e9578e1c8f8dfcdacf57eec983f9cd93ad</td>\n",
       "      <td>2024-05-30T09:32:35.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[question-answering, visual-question-answering...</td>\n",
       "      <td>[mmmu, a, massive, multi, discipline, multimod...</td>\n",
       "      <td>184369</td>\n",
       "      <td>143</td>\n",
       "      <td>{'language': ['en'], 'license': 'apache-2.0', ...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-11-27T17:52:01.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6590008ac04427eb3871a8a1</td>\n",
       "      <td>openbmb/RLHF-V-Dataset</td>\n",
       "      <td>openbmb</td>\n",
       "      <td>1d8e9804b59e9da64ad7b1e17d505869ab9b2ad3</td>\n",
       "      <td>2024-05-28T04:31:38.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[text-generation, visual-question-answering]</td>\n",
       "      <td>[for, rlhf, v, dataset, project, page, paper, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>{'license': 'cc-by-nc-4.0', 'task_categories':...</td>\n",
       "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
       "      <td>2023-12-30T11:35:38.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                              id      author  \\\n",
       "0  664a1c1f4fa4afb446afa8f7         openbmb/RLAIF-V-Dataset     openbmb   \n",
       "1  655b26e86a7098bc6e6f99e6             Lin-Chen/ShareGPT4V    Lin-Chen   \n",
       "2  643dda8f317127fb1e30b27b  liuhaotian/LLaVA-Instruct-150K  liuhaotian   \n",
       "3  6564d741cfdc8b6433bfba49                       MMMU/MMMU        MMMU   \n",
       "4  6590008ac04427eb3871a8a1          openbmb/RLHF-V-Dataset     openbmb   \n",
       "\n",
       "                                        sha              lastModified  \\\n",
       "0  d2726fcfdb37fba679e7ccdf31e23f09e869b0f0  2024-05-28T04:25:05.000Z   \n",
       "1  731e581f7dad9ac5e6458395ce1ba731975a78f6  2024-05-27T07:32:48.000Z   \n",
       "2  9d451dc7629cfe0469f6ae4432b765cd603d5fcb  2024-01-03T01:59:20.000Z   \n",
       "3  d77f80e9578e1c8f8dfcdacf57eec983f9cd93ad  2024-05-30T09:32:35.000Z   \n",
       "4  1d8e9804b59e9da64ad7b1e17d505869ab9b2ad3  2024-05-28T04:31:38.000Z   \n",
       "\n",
       "   private  gated  disabled  \\\n",
       "0    False  False     False   \n",
       "1    False  False     False   \n",
       "2    False  False     False   \n",
       "3    False  False     False   \n",
       "4    False  False     False   \n",
       "\n",
       "                                                tags  \\\n",
       "0                        [visual-question-answering]   \n",
       "1    [visual-question-answering, question-answering]   \n",
       "2    [visual-question-answering, question-answering]   \n",
       "3  [question-answering, visual-question-answering...   \n",
       "4       [text-generation, visual-question-answering]   \n",
       "\n",
       "                                         description  downloads  likes  \\\n",
       "0  [for, rlaif, v, dataset, github, paper, news, ...         75     60   \n",
       "1  [sharegpt4v, 1, 2m, dataset, details, dataset,...       5901    218   \n",
       "2  [llava, visual, instruct, 150k, dataset, detai...        186    364   \n",
       "3  [mmmu, a, massive, multi, discipline, multimod...     184369    143   \n",
       "4  [for, rlhf, v, dataset, project, page, paper, ...          1     27   \n",
       "\n",
       "                                            cardData  \\\n",
       "0  {'license': 'cc-by-nc-4.0', 'task_categories':...   \n",
       "1  {'license': 'cc-by-nc-4.0', 'task_categories':...   \n",
       "2  {'license': 'cc-by-4.0', 'task_categories': ['...   \n",
       "3  {'language': ['en'], 'license': 'apache-2.0', ...   \n",
       "4  {'license': 'cc-by-nc-4.0', 'task_categories':...   \n",
       "\n",
       "                                            siblings                 createdAt  \n",
       "0  [{'rfilename': '.gitattributes'}, {'rfilename'...  2024-05-19T15:34:55.000Z  \n",
       "1  [{'rfilename': '.gitattributes'}, {'rfilename'...  2023-11-20T09:29:12.000Z  \n",
       "2  [{'rfilename': '.gitattributes'}, {'rfilename'...  2023-04-17T23:47:27.000Z  \n",
       "3  [{'rfilename': '.gitattributes'}, {'rfilename'...  2023-11-27T17:52:01.000Z  \n",
       "4  [{'rfilename': '.gitattributes'}, {'rfilename'...  2023-12-30T11:35:38.000Z  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       for rlaif v dataset github paper news 2024 05 ...\n",
       "1       sharegpt4v 1 2m dataset details dataset type s...\n",
       "2       llava visual instruct 150k dataset details dat...\n",
       "3       mmmu a massive multi discipline multimodal und...\n",
       "4       for rlhf v dataset project page paper github u...\n",
       "                              ...                        \n",
       "6630    maniskill pickcube demonstrations contains the...\n",
       "6631    maniskill stackcube demonstrations contains de...\n",
       "6632    maniskill peginsertionside demonstrations cont...\n",
       "6633    maniskill plugcharger demonstrations contains ...\n",
       "6634    maniskill pushcube demonstrations contains dem...\n",
       "Name: text, Length: 6635, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['createdAt'] = df['createdAt'].apply(lambda x : x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>createdAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>664a1c1f4fa4afb446afa8f7</td>\n",
       "      <td>openbmb/RLAIF-V-Dataset</td>\n",
       "      <td>openbmb</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>for rlaif v dataset github paper news 2024 05 ...</td>\n",
       "      <td>2024-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>655b26e86a7098bc6e6f99e6</td>\n",
       "      <td>Lin-Chen/ShareGPT4V</td>\n",
       "      <td>Lin-Chen</td>\n",
       "      <td>5901</td>\n",
       "      <td>218</td>\n",
       "      <td>sharegpt4v 1 2m dataset details dataset type s...</td>\n",
       "      <td>2023-11-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>643dda8f317127fb1e30b27b</td>\n",
       "      <td>liuhaotian/LLaVA-Instruct-150K</td>\n",
       "      <td>liuhaotian</td>\n",
       "      <td>186</td>\n",
       "      <td>364</td>\n",
       "      <td>llava visual instruct 150k dataset details dat...</td>\n",
       "      <td>2023-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6564d741cfdc8b6433bfba49</td>\n",
       "      <td>MMMU/MMMU</td>\n",
       "      <td>MMMU</td>\n",
       "      <td>184369</td>\n",
       "      <td>143</td>\n",
       "      <td>mmmu a massive multi discipline multimodal und...</td>\n",
       "      <td>2023-11-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6590008ac04427eb3871a8a1</td>\n",
       "      <td>openbmb/RLHF-V-Dataset</td>\n",
       "      <td>openbmb</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>for rlhf v dataset project page paper github u...</td>\n",
       "      <td>2023-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                              id      author  \\\n",
       "0  664a1c1f4fa4afb446afa8f7         openbmb/RLAIF-V-Dataset     openbmb   \n",
       "1  655b26e86a7098bc6e6f99e6             Lin-Chen/ShareGPT4V    Lin-Chen   \n",
       "2  643dda8f317127fb1e30b27b  liuhaotian/LLaVA-Instruct-150K  liuhaotian   \n",
       "3  6564d741cfdc8b6433bfba49                       MMMU/MMMU        MMMU   \n",
       "4  6590008ac04427eb3871a8a1          openbmb/RLHF-V-Dataset     openbmb   \n",
       "\n",
       "   downloads  likes                                               text  \\\n",
       "0         75     60  for rlaif v dataset github paper news 2024 05 ...   \n",
       "1       5901    218  sharegpt4v 1 2m dataset details dataset type s...   \n",
       "2        186    364  llava visual instruct 150k dataset details dat...   \n",
       "3     184369    143  mmmu a massive multi discipline multimodal und...   \n",
       "4          1     27  for rlhf v dataset project page paper github u...   \n",
       "\n",
       "    createdAt  \n",
       "0  2024-05-19  \n",
       "1  2023-11-20  \n",
       "2  2023-04-17  \n",
       "3  2023-11-27  \n",
       "4  2023-12-30  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[['_id' ,'id' ,'author' ,'downloads' ,'likes' ,'text' ,'createdAt']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(obj):\n",
    "    y = []\n",
    "    for i in obj.split():\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14019/4000824553.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['text'] = df2['text'].apply(stem)\n"
     ]
    }
   ],
   "source": [
    "df2['text'] = df2['text'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       for rlaif v dataset github paper news 2024 05 ...\n",
       "1       sharegpt4v 1 2m dataset detail dataset type sh...\n",
       "2       llava visual instruct 150k dataset detail data...\n",
       "3       mmmu a massiv multi disciplin multimod underst...\n",
       "4       for rlhf v dataset project page paper github u...\n",
       "                              ...                        \n",
       "6630    maniskil pickcub demonstr contain the follow d...\n",
       "6631    maniskil stackcub demonstr contain demonstr so...\n",
       "6632    maniskil peginsertionsid demonstr contain demo...\n",
       "6633    maniskil plugcharg demonstr contain demonstr s...\n",
       "6634    maniskil pushcub demonstr contain demonstr sou...\n",
       "Name: text, Length: 6635, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for missingkey note thi contain old data befor 10 04 24 the upload ha move to here dataset summari missingkey is a raw dataset archiv of the misskey io network support task and leaderboard thi dataset is primarili intend for unsupervis train of text gener model howev it may be use for other purpos text classif text gener languag primarili japanes howev there see the full descript on the dataset page'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['text'][1111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14019/3441183336.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['text'] = df2['text'].str.replace(r'\\d+', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "df2['text'] = df2['text'].str.replace(r'\\d+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autotrain dataset for project satellit imag classif dataset descritpion thi dataset ha been automat process by autotrain for project satellit imag classif languag the bcp  code for the dataset s languag is unk dataset structur data instanc a sampl from thi dataset look as follow imag x cmyk pil imag target  imag x cmyk see the full descript on the dataset page'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['text'][234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>createdAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>64a2aee6a2cde43b6d9a1687</td>\n",
       "      <td>pengxiang01/test</td>\n",
       "      <td>pengxiang01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aasdfsdf</td>\n",
       "      <td>2023-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>64c8612ef7f4ccb5ea35aa08</td>\n",
       "      <td>PetraAI/PetraAI</td>\n",
       "      <td>PetraAI</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>petra overview petra is a multilingu dataset f...</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>65148fdca8849e84282d6647</td>\n",
       "      <td>Illia56/Military-Aircraft-Detection</td>\n",
       "      <td>Illia56</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>dataset for object detect of militari aircraft...</td>\n",
       "      <td>2023-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>62a07b9c9bb481870211b0eb</td>\n",
       "      <td>AhmedSSabir/Textual-Image-Caption-Dataset</td>\n",
       "      <td>AhmedSSabir</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>updat oct  add v with recent sota model swinv ...</td>\n",
       "      <td>2022-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>62dc62a478a44abeb6eba809</td>\n",
       "      <td>biglam/nls_chapbook_illustrations</td>\n",
       "      <td>biglam</td>\n",
       "      <td>242</td>\n",
       "      <td>8</td>\n",
       "      <td>for nation librari of scotland chapbook illust...</td>\n",
       "      <td>2022-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6630</th>\n",
       "      <td>66565ad534f77bc3965d2fac</td>\n",
       "      <td>haosulab/ManiSkill_PickCube</td>\n",
       "      <td>haosulab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>maniskil pickcub demonstr contain the follow d...</td>\n",
       "      <td>2024-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6631</th>\n",
       "      <td>66565c6e2cac66c3d73e5a23</td>\n",
       "      <td>haosulab/ManiSkill_StackCube</td>\n",
       "      <td>haosulab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>maniskil stackcub demonstr contain demonstr so...</td>\n",
       "      <td>2024-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6632</th>\n",
       "      <td>66565cacca7f02c3d4581bec</td>\n",
       "      <td>haosulab/ManiSkill_PegInsertionSide</td>\n",
       "      <td>haosulab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>maniskil peginsertionsid demonstr contain demo...</td>\n",
       "      <td>2024-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>66565ccc6df2f5f482e57606</td>\n",
       "      <td>haosulab/ManiSkill_PlugCharger</td>\n",
       "      <td>haosulab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>maniskil plugcharg demonstr contain demonstr s...</td>\n",
       "      <td>2024-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>66565d297c0be58143be2822</td>\n",
       "      <td>haosulab/ManiSkill_PushCube</td>\n",
       "      <td>haosulab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>maniskil pushcub demonstr contain demonstr sou...</td>\n",
       "      <td>2024-05-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1910 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id                                         id  \\\n",
       "159   64a2aee6a2cde43b6d9a1687                           pengxiang01/test   \n",
       "160   64c8612ef7f4ccb5ea35aa08                            PetraAI/PetraAI   \n",
       "182   65148fdca8849e84282d6647        Illia56/Military-Aircraft-Detection   \n",
       "206   62a07b9c9bb481870211b0eb  AhmedSSabir/Textual-Image-Caption-Dataset   \n",
       "425   62dc62a478a44abeb6eba809          biglam/nls_chapbook_illustrations   \n",
       "...                        ...                                        ...   \n",
       "6630  66565ad534f77bc3965d2fac                haosulab/ManiSkill_PickCube   \n",
       "6631  66565c6e2cac66c3d73e5a23               haosulab/ManiSkill_StackCube   \n",
       "6632  66565cacca7f02c3d4581bec        haosulab/ManiSkill_PegInsertionSide   \n",
       "6633  66565ccc6df2f5f482e57606             haosulab/ManiSkill_PlugCharger   \n",
       "6634  66565d297c0be58143be2822                haosulab/ManiSkill_PushCube   \n",
       "\n",
       "           author  downloads  likes  \\\n",
       "159   pengxiang01          0      0   \n",
       "160       PetraAI          7     16   \n",
       "182       Illia56         21     25   \n",
       "206   AhmedSSabir          8      6   \n",
       "425        biglam        242      8   \n",
       "...           ...        ...    ...   \n",
       "6630     haosulab          0      0   \n",
       "6631     haosulab          0      0   \n",
       "6632     haosulab          0      0   \n",
       "6633     haosulab          0      0   \n",
       "6634     haosulab          0      0   \n",
       "\n",
       "                                                   text   createdAt  \n",
       "159                                            aasdfsdf  2023-07-03  \n",
       "160   petra overview petra is a multilingu dataset f...  2023-08-01  \n",
       "182   dataset for object detect of militari aircraft...  2023-09-27  \n",
       "206   updat oct  add v with recent sota model swinv ...  2022-06-08  \n",
       "425   for nation librari of scotland chapbook illust...  2022-07-23  \n",
       "...                                                 ...         ...  \n",
       "6630  maniskil pickcub demonstr contain the follow d...  2024-05-28  \n",
       "6631  maniskil stackcub demonstr contain demonstr so...  2024-05-28  \n",
       "6632  maniskil peginsertionsid demonstr contain demo...  2024-05-28  \n",
       "6633  maniskil plugcharg demonstr contain demonstr s...  2024-05-28  \n",
       "6634  maniskil pushcub demonstr contain demonstr sou...  2024-05-28  \n",
       "\n",
       "[1910 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_rows = df2[df2.duplicated()]\n",
    "duplicated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14019/3008726784.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the DataFrame\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4725, 7)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=10000 , stop_words=\"english\")\n",
    "\n",
    "vectors = cv.fit_transform(df2[\"text\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4725, 10000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n",
      "aaac\n",
      "aaai\n",
      "aac\n",
      "aad\n",
      "aai\n",
      "aak\n",
      "aal\n",
      "aalto\n",
      "aapo\n",
      "aaron\n",
      "aas\n",
      "aasa\n",
      "aasdfsdf\n",
      "aasl\n",
      "aau\n",
      "aayushi\n",
      "aaz\n",
      "ab\n",
      "aba\n",
      "abacha\n",
      "abad\n",
      "abalon\n",
      "abastract\n",
      "abbrevi\n",
      "abc\n",
      "abdhul\n",
      "abdi\n",
      "abdomen\n",
      "abdomenatla\n",
      "abdomin\n",
      "abduct\n",
      "aberdeen\n",
      "aberdeenshir\n",
      "abi\n",
      "abid\n",
      "abil\n",
      "abkhaz\n",
      "abl\n",
      "ablat\n",
      "abnorm\n",
      "abo\n",
      "aboard\n",
      "aborevsky\n",
      "abov\n",
      "abraham\n",
      "abridg\n",
      "absa\n",
      "absenc\n",
      "absent\n",
      "absinth\n",
      "absmaxscal\n",
      "abstract\n",
      "abstractivo\n",
      "abt\n",
      "abu\n",
      "abund\n",
      "abus\n",
      "abx\n",
      "ac\n",
      "academ\n",
      "academi\n",
      "academia\n",
      "acaden\n",
      "acapella\n",
      "acc\n",
      "acceden\n",
      "acceler\n",
      "accent\n",
      "accept\n",
      "acces\n",
      "access\n",
      "accessibilit\n",
      "accessori\n",
      "accessticket\n",
      "accid\n",
      "accommod\n",
      "accompani\n",
      "accomplish\n",
      "accord\n",
      "accordingli\n",
      "account\n",
      "accumul\n",
      "accur\n",
      "accuraci\n",
      "acdc\n",
      "ace\n",
      "acehnes\n",
      "acf\n",
      "achiev\n",
      "acid\n",
      "acknowledg\n",
      "acknowledgemetn\n",
      "acl\n",
      "aclu\n",
      "acm\n",
      "acn\n",
      "acoust\n",
      "acquir\n",
      "acquisit\n",
      "acr\n",
      "acronym\n",
      "acrosom\n",
      "act\n",
      "action\n",
      "activ\n",
      "actividad\n",
      "actor\n",
      "actoress\n",
      "actress\n",
      "actu\n",
      "actual\n",
      "actuat\n",
      "acu\n",
      "acut\n",
      "ad\n",
      "ada\n",
      "adan\n",
      "adapt\n",
      "adavann\n",
      "add\n",
      "addit\n",
      "additon\n",
      "addones\n",
      "address\n",
      "addsent\n",
      "ade\n",
      "adek\n",
      "adel\n",
      "adelani\n",
      "adenoma\n",
      "adequ\n",
      "adequaci\n",
      "adgen\n",
      "adher\n",
      "adida\n",
      "adigabook\n",
      "adithya\n",
      "aditya\n",
      "adject\n",
      "adjonct\n",
      "adjud\n",
      "adjust\n",
      "administr\n",
      "admm\n",
      "ado\n",
      "adob\n",
      "adopt\n",
      "adroit\n",
      "adult\n",
      "adv\n",
      "advanc\n",
      "advantag\n",
      "advbench\n",
      "advent\n",
      "adventur\n",
      "adver\n",
      "adversari\n",
      "adversarialqa\n",
      "advertis\n",
      "advic\n",
      "advis\n",
      "advisor\n",
      "advoc\n",
      "adz\n",
      "aenea\n",
      "aer\n",
      "aerial\n",
      "aerodactyl\n",
      "aeronaut\n",
      "aeropath\n",
      "aeslc\n",
      "aesthet\n",
      "aey\n",
      "af\n",
      "affect\n",
      "affili\n",
      "affin\n",
      "affirm\n",
      "affluenc\n",
      "affluent\n",
      "afghan\n",
      "afghanwir\n",
      "aflit\n",
      "africa\n",
      "african\n",
      "africlirmatrix\n",
      "afrikaan\n",
      "afriqa\n",
      "afrisenti\n",
      "afrispeech\n",
      "afrixnli\n",
      "afro\n",
      "afrobeat\n",
      "afrolm\n",
      "aftenblad\n",
      "aftenposten\n",
      "afterward\n",
      "ag\n",
      "agarw\n",
      "agd\n",
      "age\n",
      "agenc\n",
      "agenda\n",
      "agent\n",
      "agentsearch\n",
      "agerri\n",
      "agg\n",
      "agglutin\n",
      "aggrav\n",
      "aggreg\n",
      "aggres\n",
      "aggress\n",
      "aghent\n",
      "agi\n",
      "agm\n",
      "agn\n",
      "agnew\n",
      "agnor\n",
      "agnost\n",
      "ago\n",
      "agorax\n",
      "agr\n",
      "agre\n",
      "agreeabl\n",
      "agreement\n",
      "agreg\n",
      "agricultor\n",
      "agricultur\n",
      "agrochat\n",
      "agrosegnet\n",
      "agt\n",
      "agu\n",
      "agua\n",
      "agustin\n",
      "agustsson\n",
      "agustssonntir\n",
      "aharoni\n",
      "ahbot\n",
      "ahead\n",
      "ahm\n",
      "ahmad\n",
      "ahog\n",
      "ahref\n",
      "ai\n",
      "aia\n",
      "aiatmongodb\n",
      "aibooru\n",
      "aic\n",
      "aichi\n",
      "aid\n",
      "aiec\n",
      "aifeg\n",
      "aigiz\n",
      "aihub\n",
      "aihubbuild\n",
      "aihubshel\n",
      "aii\n",
      "aiim\n",
      "aiinli\n",
      "aik\n",
      "aikin\n",
      "ailab\n",
      "aim\n",
      "aina\n",
      "aino\n",
      "aiprivaci\n",
      "air\n",
      "airbalt\n",
      "airbend\n",
      "airbnb\n",
      "aircraft\n",
      "airdialogu\n",
      "airl\n",
      "airport\n",
      "airsweep\n",
      "airway\n",
      "ais\n",
      "aiseg\n",
      "aishel\n",
      "aishwarya\n",
      "aisuko\n",
      "aitor\n",
      "aizu\n",
      "aj\n",
      "ajgt\n",
      "ajout\n",
      "ajwa\n",
      "aka\n",
      "akash\n",
      "ake\n",
      "akhmetgareevasummari\n",
      "akhtar\n",
      "akifumi\n",
      "akira\n",
      "al\n",
      "alabi\n",
      "alakazam\n",
      "alan\n",
      "alarab\n",
      "alarm\n",
      "albanian\n",
      "albeit\n",
      "albertina\n",
      "alberto\n",
      "albiero\n",
      "album\n",
      "alcar\n",
      "aldab\n",
      "aldin\n",
      "aldo\n",
      "aleksandra\n",
      "alert\n",
      "alex\n",
      "alexand\n",
      "alexandr\n",
      "alexandra\n",
      "alexandria\n",
      "alexi\n",
      "alexsu\n",
      "alfafood\n",
      "alfr\n",
      "alfredo\n",
      "alg\n",
      "algebra\n",
      "algerian\n",
      "algorithm\n",
      "alhajar\n",
      "ali\n",
      "alia\n",
      "alic\n",
      "alien\n",
      "align\n",
      "alik\n",
      "alison\n",
      "aljazeeraenglish\n",
      "allan\n",
      "allava\n",
      "alleg\n",
      "allegedli\n",
      "allegro\n",
      "allenai\n",
      "aller\n",
      "allergi\n",
      "allevi\n",
      "allison\n",
      "allnli\n",
      "alloc\n",
      "allocin\n",
      "allophon\n",
      "allow\n",
      "allyson\n",
      "alma\n",
      "almanac\n",
      "almanach\n",
      "almannar\n",
      "almendra\n",
      "alon\n",
      "alongsid\n",
      "alongwith\n",
      "alopecia\n",
      "alp\n",
      "alpaca\n",
      "alpacaev\n",
      "alpacar\n",
      "alpagasu\n",
      "alpak\n",
      "alphabet\n",
      "alphacod\n",
      "alq\n",
      "alreadi\n",
      "alrogritm\n",
      "alt\n",
      "alta\n",
      "alter\n",
      "altern\n",
      "althamm\n",
      "althingi\n",
      "alti\n",
      "altitud\n",
      "altlex\n",
      "altman\n",
      "altmetr\n",
      "alu\n",
      "aluminium\n",
      "alv\n",
      "alva\n",
      "alway\n",
      "amalgam\n",
      "amali\n",
      "amanpreet\n",
      "amara\n",
      "amaz\n",
      "amazon\n",
      "amber\n",
      "ambientcg\n",
      "ambignq\n",
      "ambigqa\n",
      "ambigu\n",
      "amc\n",
      "amd\n",
      "amdo\n",
      "ame\n",
      "amelot\n",
      "amend\n",
      "america\n",
      "american\n",
      "americasnli\n",
      "amf\n",
      "amff\n",
      "amh\n",
      "amhar\n",
      "ami\n",
      "amid\n",
      "amidst\n",
      "amino\n",
      "amirkabir\n",
      "amitava\n",
      "amiya\n",
      "amk\n",
      "amm\n",
      "ammount\n",
      "amn\n",
      "amo\n",
      "amod\n",
      "amp\n",
      "ampharo\n",
      "amplifi\n",
      "amr\n",
      "amsterdam\n",
      "amt\n",
      "amttl\n",
      "amu\n",
      "amultimod\n",
      "amur\n",
      "amx\n",
      "ana\n",
      "anaemia\n",
      "anakin\n",
      "analiza\n",
      "analog\n",
      "analogu\n",
      "analys\n",
      "analysi\n",
      "analyst\n",
      "analyt\n",
      "analyz\n",
      "anaphora\n",
      "anatom\n",
      "anc\n",
      "ancestor\n",
      "anchor\n",
      "ancien\n",
      "ancient\n",
      "ancora\n",
      "andersen\n",
      "andi\n",
      "andra\n",
      "andrea\n",
      "andrei\n",
      "andrej\n",
      "andressa\n",
      "andrew\n",
      "andrey\n",
      "androgenet\n",
      "android\n",
      "anecdot\n",
      "anecho\n",
      "angel\n",
      "angela\n",
      "angelika\n",
      "angelina\n",
      "anger\n",
      "angl\n",
      "angri\n",
      "angrytweet\n",
      "angu\n",
      "anguag\n",
      "angular\n",
      "anh\n",
      "ani\n",
      "anidet\n",
      "aniemor\n",
      "anim\n",
      "anima\n",
      "animeheadsv\n",
      "animelov\n",
      "anisha\n",
      "anispeech\n",
      "anlaysi\n",
      "anli\n",
      "ann\n",
      "anneal\n",
      "annex\n",
      "annot\n",
      "annota\n",
      "annotatedaddit\n",
      "annotationinterfac\n",
      "announc\n",
      "annoy\n",
      "annual\n",
      "annuiti\n",
      "anomali\n",
      "anonym\n",
      "anonymis\n",
      "anot\n",
      "anoth\n",
      "anr\n",
      "ans\n",
      "ansel\n",
      "ansi\n",
      "answer\n",
      "answersumm\n",
      "ant\n",
      "antaranew\n",
      "anteced\n",
      "antenna\n",
      "anterior\n",
      "antholog\n",
      "anthrop\n",
      "anthropolog\n",
      "anti\n",
      "antibodi\n",
      "antil\n",
      "antin\n",
      "antinuclear\n",
      "antiqu\n",
      "antiqua\n",
      "antisemit\n",
      "antlr\n",
      "antofagasta\n",
      "antoni\n",
      "antonio\n",
      "anv\n",
      "anxieti\n",
      "anymor\n",
      "anyon\n",
      "anyth\n",
      "anza\n",
      "anzey\n",
      "ao\n",
      "aoi\n",
      "aoj\n",
      "aom\n",
      "aon\n",
      "aorta\n",
      "aortic\n",
      "ap\n",
      "apa\n",
      "apach\n",
      "apart\n",
      "apb\n",
      "ape\n",
      "apek\n",
      "aperfei\n",
      "apertium\n",
      "apertur\n",
      "apex\n",
      "api\n",
      "apki\n",
      "apn\n",
      "apologis\n",
      "aposemat\n",
      "apoyo\n",
      "app\n",
      "appar\n",
      "apparel\n",
      "appear\n",
      "append\n",
      "appendix\n",
      "appetit\n",
      "appjobb\n",
      "appl\n",
      "applescript\n",
      "appli\n",
      "applianc\n",
      "applic\n",
      "appreci\n",
      "approach\n",
      "appropri\n",
      "approv\n",
      "approx\n",
      "approxim\n",
      "apr\n",
      "aprend\n",
      "april\n",
      "aprox\n",
      "aproxim\n",
      "aptitud\n",
      "apu\n",
      "apw\n",
      "apz\n",
      "aqol\n",
      "aqsoldb\n",
      "aqu\n",
      "aqua\n",
      "aquaint\n",
      "aquamus\n",
      "aquarium\n",
      "aquat\n",
      "aqueou\n",
      "aquir\n",
      "ar\n",
      "ara\n",
      "arab\n",
      "arabia\n",
      "arama\n",
      "araphras\n",
      "arasl\n",
      "arb\n",
      "arbeit\n",
      "arbejdet\n",
      "arbitrari\n",
      "arc\n",
      "arcd\n",
      "arcen\n",
      "archeri\n",
      "archetto\n",
      "architect\n",
      "architectur\n",
      "archiv\n",
      "archiveprefix\n",
      "archivo\n",
      "archonti\n",
      "arctic\n",
      "area\n",
      "aremuadeolajr\n",
      "aren\n",
      "arena\n",
      "arg\n",
      "argentina\n",
      "argilla\n",
      "argmin\n",
      "argtclass\n",
      "argu\n",
      "arguana\n",
      "argument\n",
      "argvalu\n",
      "argyl\n",
      "arhythmia\n",
      "arhytmia\n",
      "ari\n",
      "ariana\n",
      "arisu\n",
      "arithmet\n",
      "ariz\n",
      "arizona\n",
      "ark\n",
      "arknight\n",
      "arl\n",
      "arlequin\n",
      "arm\n",
      "armabe\n",
      "armand\n",
      "armenian\n",
      "armi\n",
      "arn\n",
      "arnold\n",
      "aroonmanakun\n",
      "arp\n",
      "arrang\n",
      "array\n",
      "arrestreview\n",
      "arrhythmia\n",
      "arsarcasm\n",
      "arsentd\n",
      "arsha\n",
      "arsl\n",
      "art\n",
      "artbook\n",
      "artefact\n",
      "artelingo\n",
      "artemi\n",
      "arteri\n",
      "artetx\n",
      "artetxeeuscrawl\n",
      "arthograph\n",
      "articl\n",
      "articlebodi\n",
      "articul\n",
      "articuno\n",
      "artifact\n",
      "artifactai\n",
      "artifici\n",
      "artigo\n",
      "artisan\n",
      "artisanat\n",
      "artist\n",
      "artopicd\n",
      "artstudio\n",
      "artstyl\n",
      "artwork\n",
      "arxiv\n",
      "arzama\n",
      "asant\n",
      "asap\n",
      "asbesto\n",
      "asc\n",
      "ascend\n",
      "ascertain\n",
      "ascii\n",
      "asclepiu\n",
      "asd\n",
      "asean\n",
      "asesoramiento\n",
      "ashaninka\n",
      "ashish\n",
      "asia\n",
      "asian\n",
      "asiat\n",
      "asid\n",
      "asif\n",
      "asil\n",
      "asirra\n",
      "asistent\n",
      "ask\n",
      "askel\n",
      "askubuntu\n",
      "asm\n",
      "asma\n",
      "asnq\n",
      "aso\n",
      "asosoft\n",
      "asp\n",
      "aspect\n",
      "aspectemo\n",
      "aspirin\n",
      "aspr\n",
      "asr\n",
      "asru\n",
      "ass\n",
      "assames\n",
      "assassin\n",
      "assembl\n",
      "assess\n",
      "asset\n",
      "assign\n",
      "assin\n",
      "assist\n",
      "assit\n",
      "associ\n",
      "assort\n",
      "assum\n",
      "assur\n",
      "assyrian\n",
      "ast\n",
      "astd\n",
      "asterix\n",
      "astesia\n",
      "astrolog\n",
      "astronom\n",
      "astronomi\n",
      "astrophys\n",
      "asturian\n",
      "astyp\n",
      "asu\n",
      "asuna\n",
      "asvspoof\n",
      "asymmetr\n",
      "asymmetri\n",
      "ata\n",
      "ataset\n",
      "atasoglu\n",
      "atb\n",
      "atc\n",
      "atcc\n",
      "atco\n",
      "atcod\n",
      "atcosim\n",
      "atd\n",
      "ate\n",
      "atec\n",
      "atent\n",
      "atg\n",
      "athanasopoulo\n",
      "athena\n",
      "athlet\n",
      "ati\n",
      "atilla\n",
      "atku\n",
      "atla\n",
      "atlant\n",
      "atlu\n",
      "atol\n",
      "atom\n",
      "atop\n",
      "atr\n",
      "atrial\n",
      "att\n",
      "attach\n",
      "attack\n",
      "attain\n",
      "attempt\n",
      "attend\n",
      "attent\n",
      "attest\n",
      "atticu\n",
      "attir\n",
      "attitud\n",
      "attr\n",
      "attract\n",
      "attribut\n",
      "atyp\n",
      "auc\n",
      "aucasian\n",
      "auction\n",
      "audi\n",
      "audienc\n",
      "audio\n",
      "audiobook\n",
      "audiocap\n",
      "audiofil\n",
      "audiomagazin\n",
      "audiometr\n",
      "audiomnist\n",
      "audioset\n",
      "audiovisu\n",
      "audit\n",
      "auditori\n",
      "auditorium\n",
      "aug\n",
      "augment\n",
      "augraphi\n",
      "august\n",
      "auli\n",
      "aung\n",
      "auratu\n",
      "aurora\n",
      "australia\n",
      "australian\n",
      "austria\n",
      "austrian\n",
      "autextif\n",
      "auth\n",
      "authent\n",
      "author\n",
      "authoris\n",
      "authorit\n",
      "authorship\n",
      "auto\n",
      "autoantibodi\n",
      "autobiographi\n",
      "autocomplet\n",
      "autodan\n",
      "autogener\n",
      "autoimmun\n",
      "autoincr\n",
      "autom\n",
      "automag\n",
      "automat\n",
      "automathtext\n",
      "automaticament\n",
      "automatiqu\n",
      "automobil\n",
      "automot\n",
      "autonlp\n",
      "autonom\n",
      "autor\n",
      "autotoken\n",
      "autotrain\n",
      "autr\n",
      "auv\n",
      "auxiliari\n",
      "auxquel\n",
      "av\n",
      "ava\n",
      "avaiabl\n",
      "avaibl\n",
      "avail\n",
      "availab\n",
      "availbl\n",
      "aval\n",
      "avali\n",
      "avalia\n",
      "avanzada\n",
      "avast\n",
      "avatar\n",
      "ave\n",
      "avenir\n",
      "avenu\n",
      "averag\n",
      "avg\n",
      "aviail\n",
      "avialab\n",
      "avian\n",
      "aviat\n",
      "avif\n",
      "avis\n",
      "aviskorpu\n",
      "avoid\n",
      "aw\n",
      "awal\n",
      "awar\n",
      "award\n",
      "awb\n",
      "awesom\n",
      "awkward\n",
      "awlaki\n",
      "ax\n",
      "axe\n",
      "axial\n",
      "axolotl\n",
      "axon\n",
      "aya\n",
      "ayacucho\n",
      "ayaka\n",
      "aye\n",
      "ayer\n",
      "aymara\n",
      "ayoub\n",
      "ayoubi\n",
      "ayr\n",
      "az\n",
      "azerbaijan\n",
      "azerbaijani\n",
      "azoulay\n",
      "azur\n",
      "azusa\n",
      "ba\n",
      "baa\n",
      "baat\n",
      "babbag\n",
      "babel\n",
      "babelbox\n",
      "babelnet\n",
      "babelscap\n",
      "babenko\n",
      "babi\n",
      "babylon\n",
      "backbon\n",
      "background\n",
      "backslash\n",
      "backtransl\n",
      "backup\n",
      "backward\n",
      "bacteria\n",
      "bactrain\n",
      "bactrian\n",
      "bad\n",
      "badano\n",
      "baden\n",
      "badg\n",
      "badger\n",
      "badminton\n",
      "bae\n",
      "baek\n",
      "bag\n",
      "bagpip\n",
      "bahasa\n",
      "bai\n",
      "baicoig\n",
      "bain\n",
      "baiter\n",
      "bake\n",
      "bakeoff\n",
      "baker\n",
      "balan\n",
      "balanc\n",
      "balconi\n",
      "bald\n",
      "baldwin\n",
      "balear\n",
      "balenciaga\n",
      "balines\n",
      "ball\n",
      "balloon\n",
      "bam\n",
      "bambara\n",
      "ban\n",
      "banana\n",
      "banc\n",
      "band\n",
      "bandad\n",
      "bandmarch\n",
      "bandwidth\n",
      "banek\n",
      "bang\n",
      "bangla\n",
      "bangor\n",
      "bangumi\n",
      "bangumibas\n",
      "banjares\n",
      "bank\n",
      "baobab\n",
      "baolin\n",
      "baptist\n",
      "baptista\n",
      "bar\n",
      "barakat\n",
      "barbara\n",
      "barcelona\n",
      "barcod\n",
      "bare\n",
      "bargain\n",
      "baria\n",
      "bark\n",
      "baroqu\n",
      "barr\n",
      "barrel\n",
      "barricad\n",
      "barrier\n",
      "bart\n",
      "barton\n",
      "basaa\n",
      "basart\n",
      "base\n",
      "basebal\n",
      "baselin\n",
      "basetim\n",
      "bash\n",
      "bashkir\n",
      "basi\n",
      "basic\n",
      "basketbal\n",
      "basqu\n",
      "basqueparl\n",
      "bastarda\n",
      "batak\n",
      "batch\n",
      "batter\n",
      "batteri\n",
      "batterydataextractor\n",
      "battl\n",
      "battlefield\n",
      "batuhan\n",
      "batzner\n",
      "bayelemabaga\n",
      "baykara\n",
      "bbaw\n",
      "bbc\n",
      "bbj\n",
      "bbox\n",
      "bboyunv\n",
      "bbq\n",
      "bccd\n",
      "bcgm\n",
      "bcp\n",
      "bdb\n",
      "bdl\n",
      "bea\n",
      "bead\n",
      "beagl\n",
      "beam\n",
      "bean\n",
      "bear\n",
      "beard\n",
      "beatl\n",
      "beatmap\n",
      "beatriz\n",
      "beaumont\n",
      "beauti\n",
      "becam\n",
      "becaus\n",
      "beccacp\n",
      "bechmark\n",
      "becom\n",
      "bed\n",
      "bedford\n",
      "bedroom\n",
      "bee\n",
      "beed\n",
      "beedn\n",
      "beeswax\n",
      "befor\n",
      "began\n",
      "begin\n",
      "beginn\n",
      "behanc\n",
      "behav\n",
      "behavior\n",
      "behaviour\n",
      "behoimi\n",
      "beij\n",
      "beir\n",
      "bel\n",
      "belaru\n",
      "belarusian\n",
      "belebel\n",
      "belgian\n",
      "belief\n",
      "believ\n",
      "belirli\n",
      "bell\n",
      "bellevil\n",
      "belli\n",
      "bello\n",
      "bellsprout\n",
      "belog\n",
      "belong\n",
      "belorussian\n",
      "belov\n",
      "belt\n",
      "beltrachini\n",
      "ben\n",
      "bench\n",
      "benchamrk\n",
      "benchfilt\n",
      "benchlmm\n",
      "benchmark\n",
      "benchmarkdata\n",
      "bencod\n",
      "bend\n",
      "benefici\n",
      "benefit\n",
      "bengali\n",
      "benign\n",
      "benin\n",
      "beninmadrid\n",
      "benjamin\n",
      "beno\n",
      "benson\n",
      "benteau\n",
      "benthic\n",
      "beomi\n",
      "beproj\n",
      "berbahasa\n",
      "beret\n",
      "bergen\n",
      "bergmann\n",
      "bergskollegium\n",
      "berkeley\n",
      "berkman\n",
      "berlin\n",
      "berlinski\n",
      "bernama\n",
      "bernsohn\n",
      "berri\n",
      "bert\n",
      "bertcat\n",
      "bertdot\n",
      "berti\n",
      "bertin\n",
      "bertlarg\n",
      "bertsum\n",
      "bertvits\n",
      "besid\n",
      "best\n",
      "besultan\n",
      "bet\n",
      "beta\n",
      "bethecloud\n",
      "better\n",
      "bezzam\n",
      "bfloat\n",
      "bgglue\n",
      "bhagwat\n",
      "bharatanatyam\n",
      "bharathi\n",
      "bhasha\n",
      "bhatur\n",
      "bhojpuri\n",
      "bhosal\n",
      "bi\n",
      "bia\n",
      "bianet\n",
      "bias\n",
      "bibl\n",
      "biblenlp\n",
      "biblett\n",
      "biblic\n",
      "biblica\n",
      "bibliograph\n",
      "bibliotik\n",
      "bibtex\n",
      "bicub\n",
      "bicycl\n",
      "bidaf\n",
      "bidirect\n",
      "bien\n",
      "bienestar\n",
      "big\n",
      "bigbench\n",
      "bigbird\n",
      "bigclonebench\n",
      "bigcod\n",
      "bigger\n",
      "biggest\n",
      "biglam\n",
      "bigpat\n",
      "bike\n",
      "bilbao\n",
      "bilbaoqa\n",
      "bilgil\n",
      "bilingu\n",
      "billion\n",
      "bilstm\n",
      "bimod\n",
      "bin\n",
      "binanc\n",
      "binar\n",
      "binari\n",
      "bind\n",
      "bing\n",
      "bingcoronavirusqueryset\n",
      "bingen\n",
      "binggpt\n",
      "bingsu\n",
      "binqiang\n",
      "binyu\n",
      "bio\n",
      "bioacoust\n",
      "bioasq\n",
      "bioclip\n",
      "biocr\n",
      "biodataom\n",
      "biodegrad\n",
      "biographi\n",
      "bioinformat\n",
      "bioleaflet\n",
      "biolog\n",
      "biologist\n",
      "biomed\n",
      "biomedicin\n",
      "biometr\n",
      "bionlp\n",
      "biopsi\n",
      "bioss\n",
      "biotech\n",
      "biovdb\n",
      "biq\n",
      "biqqueri\n",
      "bir\n",
      "birb\n",
      "birch\n",
      "bird\n",
      "birdl\n",
      "birdset\n",
      "birth\n",
      "birthdat\n",
      "birthplac\n",
      "biryani\n",
      "bisni\n",
      "bison\n",
      "bit\n",
      "bitcoin\n",
      "bite\n",
      "bites\n",
      "bitext\n",
      "bittensor\n",
      "biyang\n",
      "bj\n",
      "bl\n",
      "black\n",
      "blackhead\n",
      "blad\n",
      "bladder\n",
      "blaha\n",
      "blank\n",
      "blast\n",
      "blaze\n",
      "blbook\n",
      "bleking\n",
      "blemishin\n",
      "blender\n",
      "blicker\n",
      "blimp\n",
      "blind\n",
      "blip\n",
      "blizzard\n",
      "blob\n",
      "block\n",
      "blog\n",
      "blogger\n",
      "blogpost\n",
      "blogspot\n",
      "blond\n",
      "blood\n",
      "bloom\n",
      "bloomberg\n",
      "bloomvqa\n",
      "blue\n",
      "blunt\n",
      "blur\n",
      "blurb\n",
      "blurri\n",
      "blush\n",
      "bm\n",
      "bmc\n",
      "bnc\n",
      "bne\n",
      "bnl\n",
      "bo\n",
      "boar\n",
      "board\n",
      "boast\n",
      "bob\n",
      "bodi\n",
      "bogota\n",
      "bohemia\n",
      "bojanowski\n",
      "bojar\n",
      "bok\n",
      "bokeh\n",
      "bokm\n",
      "bold\n",
      "bollywood\n",
      "bolorsoft\n",
      "bombtow\n",
      "bon\n",
      "bonapart\n",
      "bond\n",
      "bone\n",
      "bongard\n",
      "book\n",
      "bookcorpu\n",
      "bookcorpus\n",
      "bookcorpusopen\n",
      "bookmark\n",
      "books\n",
      "bookstor\n",
      "booksum\n",
      "booktitl\n",
      "bool\n",
      "boolean\n",
      "boolq\n",
      "boom\n",
      "boost\n",
      "boostcamp\n",
      "bootstrap\n",
      "bop\n",
      "border\n",
      "borderless\n",
      "borderlin\n",
      "bore\n",
      "boredom\n",
      "borger\n",
      "bori\n",
      "born\n",
      "bornholmsk\n",
      "borodin\n",
      "bosnian\n",
      "boson\n",
      "bosqu\n",
      "boston\n",
      "bot\n",
      "botan\n",
      "botox\n",
      "bottega\n",
      "bottl\n",
      "bottleneck\n",
      "boubekri\n",
      "boudoir\n",
      "bought\n",
      "bounc\n",
      "bound\n",
      "boundari\n",
      "bourdoi\n",
      "bourgogn\n",
      "bourk\n",
      "boutiqu\n",
      "bow\n",
      "bowel\n",
      "bowman\n",
      "box\n",
      "boxian\n",
      "boy\n",
      "boyan\n",
      "bp\n",
      "bppt\n",
      "bprateek\n",
      "bq\n",
      "br\n",
      "braid\n",
      "brain\n",
      "brainstorm\n",
      "bramvanroy\n",
      "branch\n",
      "brand\n",
      "brandenburg\n",
      "brasil\n",
      "brat\n",
      "brats\n",
      "braunschweig\n",
      "brazil\n",
      "brazilian\n",
      "bread\n",
      "breadth\n",
      "break\n",
      "breakdown\n",
      "breakthrough\n",
      "breast\n",
      "breath\n",
      "breed\n",
      "breton\n",
      "brezhoneg\n",
      "brian\n",
      "bribri\n",
      "brick\n",
      "bridg\n",
      "brief\n",
      "briefli\n",
      "brigg\n",
      "bright\n",
      "brightman\n",
      "brill\n",
      "brindar\n",
      "bring\n",
      "brisban\n",
      "britannica\n",
      "british\n",
      "britt\n",
      "brittl\n",
      "bro\n",
      "broad\n",
      "broadband\n",
      "broadcast\n",
      "broader\n",
      "broadsheet\n",
      "brogaard\n",
      "broke\n",
      "broken\n",
      "broodwarmap\n",
      "brought\n",
      "broughttoyoubyinfor\n",
      "brouwer\n",
      "brown\n",
      "browser\n",
      "bruna\n",
      "bruno\n",
      "brush\n",
      "brute\n",
      "brwac\n",
      "bsard\n",
      "bsc\n",
      "bsd\n",
      "bsmock\n",
      "bt\n",
      "btc\n",
      "btgenbot\n",
      "btih\n",
      "bu\n",
      "buaadream\n",
      "bubbl\n",
      "buch\n",
      "bucket\n",
      "buckey\n",
      "budapest\n",
      "budget\n",
      "buego\n",
      "buffer\n",
      "buffet\n",
      "bug\n",
      "buggi\n",
      "bugines\n",
      "bugliarello\n",
      "build\n",
      "builder\n",
      "builderconfig\n",
      "built\n",
      "buis\n",
      "bulg\n",
      "bulgaria\n",
      "bulgarian\n",
      "bulk\n",
      "bulletin\n",
      "bun\n",
      "bunch\n",
      "bunker\n",
      "bunni\n",
      "buoy\n",
      "burberri\n",
      "burch\n",
      "burden\n",
      "bureau\n",
      "burgeon\n",
      "burger\n",
      "burkhardtdatabas\n",
      "burl\n",
      "burman\n",
      "burmes\n",
      "burn\n",
      "buryat\n",
      "busca\n",
      "busi\n",
      "butter\n",
      "butterfli\n",
      "button\n",
      "buy\n",
      "buyer\n",
      "bv\n",
      "bw\n",
      "bync\n",
      "byol\n",
      "bypass\n",
      "byte\n",
      "bytecod\n",
      "bytesio\n",
      "byvoid\n",
      "ca\n",
      "cabank\n",
      "cabbag\n",
      "cabbi\n",
      "cabl\n",
      "cabuar\n",
      "cach\n",
      "cacti\n",
      "cactoro\n",
      "cad\n",
      "cada\n",
      "cade\n",
      "cadi\n",
      "cafeadbebacaab\n",
      "caharia\n",
      "cai\n",
      "cair\n",
      "cake\n",
      "cal\n",
      "calc\n",
      "calcul\n",
      "calendar\n",
      "calidad\n",
      "california\n",
      "callchimp\n",
      "caller\n",
      "callhom\n",
      "callison\n",
      "calm\n",
      "calori\n",
      "caltech\n",
      "camara\n",
      "cambridg\n",
      "came\n",
      "camel\n",
      "camelyon\n",
      "camembert\n",
      "camera\n",
      "cameroon\n",
      "campaign\n",
      "campo\n",
      "campsit\n",
      "campu\n",
      "canada\n",
      "canadian\n",
      "canal\n",
      "canariaview\n",
      "canarim\n",
      "cancer\n",
      "cancion\n",
      "candi\n",
      "candid\n",
      "canker\n",
      "canni\n",
      "canon\n",
      "canonic\n",
      "canopi\n",
      "cantando\n",
      "cantemist\n",
      "canton\n",
      "cantones\n",
      "canuma\n",
      "canva\n",
      "canvas\n",
      "canziani\n",
      "cao\n",
      "caoyq\n",
      "cap\n",
      "capabl\n",
      "capac\n",
      "capcon\n",
      "cape\n",
      "capi\n",
      "capit\n",
      "capitalist\n",
      "capk\n",
      "caprion\n",
      "capsul\n",
      "captain\n",
      "captcha\n",
      "caption\n",
      "captur\n",
      "capybara\n",
      "car\n",
      "carassiu\n",
      "carcharodon\n",
      "carcinogenesi\n",
      "carcinoma\n",
      "card\n",
      "cardboard\n",
      "cardigan\n",
      "cardin\n",
      "care\n",
      "career\n",
      "careqa\n",
      "carhart\n",
      "carissa\n",
      "carl\n",
      "carlo\n",
      "carlyl\n",
      "carnegi\n",
      "carnelian\n",
      "carolina\n",
      "carpent\n",
      "carpet\n",
      "carri\n",
      "carrier\n",
      "cart\n",
      "carter\n",
      "cartoon\n",
      "carv\n",
      "carveset\n",
      "carvil\n",
      "case\n",
      "casehold\n",
      "caselaw\n",
      "cash\n",
      "cashew\n",
      "casino\n",
      "casmacat\n",
      "cassett\n",
      "cast\n",
      "castleford\n",
      "castorini\n",
      "castro\n",
      "casual\n",
      "casum\n",
      "cat\n",
      "catac\n",
      "catal\n",
      "catalan\n",
      "catalana\n",
      "catalog\n",
      "catalogu\n",
      "catalonia\n",
      "catalunya\n",
      "catalyz\n",
      "catarina\n",
      "catb\n",
      "categor\n",
      "categori\n",
      "categotiy\n",
      "cater\n",
      "catergori\n",
      "caterpi\n",
      "catmu\n",
      "caucasian\n",
      "caus\n",
      "causal\n",
      "caution\n",
      "cavalcanti\n",
      "cavanagh\n",
      "caveat\n",
      "cavendish\n",
      "caverle\n",
      "cavern\n",
      "caviti\n",
      "cawac\n",
      "cb\n",
      "cbefbaccabaedf\n",
      "cbma\n",
      "cbsa\n",
      "cc\n",
      "ccagt\n",
      "ccdv\n",
      "ccfbdci\n",
      "ccgigafida\n",
      "ccglambda\n",
      "cci\n",
      "cck\n",
      "ccks\n",
      "ccm\n",
      "ccma\n",
      "ccmatrix\n",
      "ccmusic\n",
      "ccnet\n",
      "ccpe\n",
      "ccvl\n",
      "cd\n",
      "cdeval\n",
      "cdip\n",
      "cdla\n",
      "cdn\n",
      "cdr\n",
      "cdrb\n",
      "ce\n",
      "ceasefir\n",
      "cebccbfd\n",
      "ceci\n",
      "cecilia\n",
      "cedar\n",
      "ceder\n",
      "cedr\n",
      "cefcdfeeccbebbcaeefab\n",
      "cefr\n",
      "ceia\n",
      "ceil\n",
      "cel\n",
      "celeb\n",
      "celeba\n",
      "celebi\n",
      "celebr\n",
      "celesti\n",
      "celex\n",
      "celibat\n",
      "celin\n",
      "cell\n",
      "cellist\n",
      "cellphon\n",
      "cellular\n",
      "celsiu\n",
      "cem\n",
      "cen\n",
      "censu\n",
      "center\n",
      "centr\n",
      "central\n",
      "centric\n",
      "centrifug\n",
      "centuri\n",
      "ceob\n",
      "cepstral\n",
      "cer\n",
      "cereal\n",
      "cerebra\n",
      "ceren\n",
      "cerrado\n",
      "certain\n",
      "certainli\n",
      "certif\n",
      "cervic\n",
      "ceshbp\n",
      "cetoli\n",
      "cewu\n",
      "ceylon\n",
      "cfa\n",
      "cfq\n",
      "ch\n",
      "chad\n",
      "chadic\n",
      "chaeyeon\n",
      "chahiy\n",
      "chai\n",
      "chain\n",
      "chakraborti\n",
      "chakravarthi\n",
      "challang\n",
      "challeng\n",
      "chamber\n",
      "champaign\n",
      "chanc\n",
      "chanel\n",
      "chang\n",
      "changpinyo\n",
      "changpinyomaxm\n",
      "channel\n",
      "chanussot\n",
      "chanyin\n",
      "chao\n",
      "chapati\n",
      "chapbook\n",
      "chapter\n",
      "char\n",
      "charact\n",
      "character\n",
      "characteris\n",
      "characterist\n",
      "charadesego\n",
      "charat\n",
      "charcoal\n",
      "charg\n",
      "charitaki\n",
      "charitramrutam\n",
      "charl\n",
      "charli\n",
      "charmeleon\n",
      "chart\n",
      "chat\n",
      "chatbot\n",
      "chatdoctor\n",
      "chate\n",
      "chatgpt\n",
      "chathealth\n",
      "chatm\n",
      "chatmat\n",
      "chatml\n",
      "chattopadhyay\n",
      "chaucer\n",
      "chaudhari\n",
      "chauss\n",
      "che\n",
      "cheap\n",
      "check\n",
      "checkout\n",
      "checkpoint\n",
      "cheetah\n",
      "chem\n",
      "chemdner\n",
      "chemic\n",
      "chemicalconcentr\n",
      "cheminf\n",
      "chemistri\n",
      "chemprot\n",
      "chemyshev\n",
      "chen\n",
      "cheng\n",
      "chengcan\n",
      "chenghao\n",
      "chengremot\n",
      "cherguelain\n",
      "chernousov\n",
      "cheroke\n",
      "chess\n",
      "chessbig\n",
      "chest\n",
      "chexpert\n",
      "chhattisgarhi\n",
      "chi\n",
      "chiari\n",
      "chichewa\n",
      "chicken\n",
      "chid\n",
      "chief\n",
      "child\n",
      "childr\n",
      "children\n",
      "chile\n",
      "chilean\n",
      "chin\n",
      "china\n",
      "chine\n",
      "chines\n",
      "chinesest\n",
      "chinmay\n",
      "chip\n",
      "chit\n",
      "chk\n",
      "chloe\n",
      "chn\n",
      "chocol\n",
      "choi\n",
      "choic\n",
      "chole\n",
      "cholec\n",
      "cholecsegk\n",
      "cholecystectomi\n",
      "chondrosarcoma\n",
      "choos\n",
      "chop\n",
      "chord\n",
      "choru\n",
      "chose\n",
      "chosen\n",
      "chr\n",
      "chren\n",
      "chri\n",
      "christian\n",
      "christma\n",
      "christmasclaym\n",
      "christo\n",
      "christodoulopoulo\n",
      "christoph\n",
      "chroma\n",
      "chromium\n",
      "chromosom\n",
      "chronicl\n",
      "chshona\n",
      "chu\n",
      "chuck\n",
      "chun\n",
      "chung\n",
      "chunk\n",
      "church\n",
      "churkin\n",
      "chuvash\n",
      "ci\n",
      "cia\n",
      "cic\n",
      "cidar\n",
      "ciemen\n",
      "ciempiess\n",
      "cienc\n",
      "cient\n",
      "cifak\n",
      "cifar\n",
      "cilantroperejil\n",
      "cin\n",
      "cindi\n",
      "cine\n",
      "cinnamon\n",
      "ciqual\n",
      "circa\n",
      "circadian\n",
      "circl\n",
      "circuit\n",
      "circular\n",
      "cirenia\n",
      "cistercien\n",
      "cit\n",
      "citat\n",
      "cite\n",
      "citesum\n",
      "citi\n",
      "citizen\n",
      "civil\n",
      "civilian\n",
      "civitai\n",
      "ck\n",
      "cl\n",
      "claim\n",
      "clan\n",
      "clancastl\n",
      "clane\n",
      "clap\n",
      "clarifi\n",
      "clarinpl\n",
      "clariti\n",
      "clark\n",
      "clarkboolq\n",
      "clartt\n",
      "clase\n",
      "clash\n",
      "clasificaci\n",
      "clasificacion\n",
      "clasificada\n",
      "clasifico\n",
      "class\n",
      "classe\n",
      "classev\n",
      "classi\n",
      "classic\n",
      "classif\n",
      "classifc\n",
      "classifi\n",
      "classificd\n",
      "classifiqu\n",
      "classlabel\n",
      "claud\n",
      "claus\n",
      "claymat\n",
      "clb\n",
      "clean\n",
      "cleand\n",
      "cleaner\n",
      "cleanli\n",
      "cleans\n",
      "cleanup\n",
      "cleanvid\n",
      "clear\n",
      "clearer\n",
      "clearli\n",
      "clef\n",
      "clefairi\n",
      "clen\n",
      "clevr\n",
      "clevrer\n",
      "cli\n",
      "click\n",
      "client\n",
      "clientel\n",
      "climat\n",
      "climatefev\n",
      "climatelearn\n",
      "climatex\n",
      "clincal\n",
      "clinic\n",
      "clinicaltri\n",
      "clinican\n",
      "clip\n",
      "clipprocessor\n",
      "clivu\n",
      "cll\n",
      "clm\n",
      "clmet\n",
      "cloak\n",
      "clock\n",
      "cloister\n",
      "clone\n",
      "close\n",
      "closer\n",
      "closest\n",
      "cloth\n",
      "clotho\n",
      "cloud\n",
      "cloudop\n",
      "cloudsen\n",
      "cloversearch\n",
      "cloze\n",
      "clozetest\n",
      "clr\n",
      "clubhous\n",
      "clue\n",
      "cluener\n",
      "clueweb\n",
      "cluj\n",
      "clump\n",
      "cluster\n",
      "clusterlab\n",
      "cm\n",
      "cmbert\n",
      "cmd\n",
      "cmedqav\n",
      "cmeee\n",
      "cml\n",
      "cmmlu\n",
      "cmmu\n",
      "cmn\n",
      "cmoncrawl\n",
      "cmp\n",
      "cmu\n",
      "cmyk\n",
      "cn\n",
      "cnbcindonesia\n",
      "cner\n",
      "cnewsum\n",
      "cnica\n",
      "cnn\n",
      "cnndm\n",
      "cnnindonesia\n",
      "coach\n",
      "coai\n",
      "coalit\n",
      "coars\n",
      "coastal\n",
      "coat\n",
      "cochran\n",
      "cocktail\n",
      "coco\n",
      "cocodataset\n",
      "coct\n",
      "cod\n",
      "codah\n",
      "codalab\n",
      "code\n",
      "codeact\n",
      "codeactag\n",
      "codeactinstruct\n",
      "codealpaca\n",
      "codebas\n",
      "codec\n",
      "codechef\n",
      "codecomplet\n",
      "codecontest\n",
      "codeforc\n",
      "codellama\n",
      "codenet\n",
      "codesarchnet\n",
      "codesearchnet\n",
      "codexglu\n",
      "codi\n",
      "coe\n",
      "coeffici\n",
      "coffe\n",
      "cofnodycynulliad\n",
      "cognit\n",
      "cogniz\n",
      "cogvlm\n",
      "cohan\n",
      "cohen\n",
      "coher\n",
      "cohereforai\n",
      "coi\n",
      "coig\n",
      "coil\n",
      "coin\n",
      "coincident\n",
      "cointelegraph\n",
      "col\n",
      "cola\n",
      "colab\n",
      "colabora\n",
      "colbert\n",
      "cole\n",
      "colect\n",
      "coll\n",
      "collabor\n",
      "collado\n",
      "collat\n",
      "collect\n",
      "collection\n",
      "collectiv\n",
      "collectivat\n",
      "collectivit\n",
      "collector\n",
      "colleg\n",
      "collier\n",
      "collin\n",
      "collis\n",
      "colloc\n",
      "colloqui\n",
      "colo\n",
      "coloc\n",
      "colombia\n",
      "colombian\n",
      "colon\n",
      "coloni\n",
      "colonoscopi\n",
      "color\n",
      "colorect\n",
      "coloss\n",
      "colour\n",
      "columbu\n",
      "column\n",
      "com\n",
      "combat\n",
      "combin\n",
      "combinator\n",
      "come\n",
      "comedian\n",
      "cometomyhead\n",
      "comfort\n",
      "comic\n",
      "comm\n",
      "command\n",
      "comment\n",
      "commentari\n",
      "commer\n",
      "commerc\n",
      "commerci\n",
      "commiss\n",
      "commit\n",
      "committe\n",
      "commmonsens\n",
      "commodor\n",
      "common\n",
      "commoncatalog\n",
      "commoncrawl\n",
      "commonest\n",
      "commongen\n",
      "commonli\n",
      "commonsens\n",
      "commonsenseqa\n",
      "commonvoic\n",
      "commonwealth\n",
      "commun\n",
      "como\n",
      "compa\n",
      "compact\n",
      "compani\n",
      "companion\n",
      "companyweb\n",
      "compar\n",
      "comparis\n",
      "comparison\n",
      "compass\n",
      "compat\n",
      "compel\n",
      "compendium\n",
      "compens\n",
      "compet\n",
      "competit\n",
      "compguesswhat\n",
      "compil\n",
      "complain\n",
      "complaint\n",
      "complement\n",
      "complementari\n",
      "complet\n",
      "completetask\n",
      "complex\n",
      "compli\n",
      "complianc\n",
      "complic\n",
      "compon\n",
      "compos\n",
      "composit\n",
      "composition\n",
      "compound\n",
      "compr\n",
      "comprehend\n",
      "comprehens\n",
      "compren\n",
      "compress\n",
      "compris\n",
      "compromis\n",
      "compu\n",
      "comput\n",
      "computag\n",
      "computerroom\n",
      "comqa\n",
      "comun\n",
      "comvg\n",
      "comwilliam\n",
      "conala\n",
      "concaten\n",
      "concatin\n",
      "conceiv\n",
      "concentr\n",
      "concept\n",
      "conceptnet\n",
      "conceptu\n",
      "concern\n",
      "concert\n",
      "concis\n",
      "conclud\n",
      "conclus\n",
      "concret\n",
      "concurr\n",
      "conda\n",
      "condens\n",
      "condit\n",
      "condition\n",
      "conduct\n",
      "conductor\n",
      "confer\n",
      "confid\n",
      "config\n",
      "configur\n",
      "conflict\n",
      "conform\n",
      "confus\n",
      "conghui\n",
      "congmin\n",
      "congo\n",
      "congress\n",
      "congression\n",
      "congressmen\n",
      "conifer\n",
      "conjectur\n",
      "conjunct\n",
      "conjunto\n",
      "conll\n",
      "conllpp\n",
      "conneau\n",
      "connect\n",
      "conocimiento\n",
      "conquest\n",
      "conscienti\n",
      "consecut\n",
      "consejo\n",
      "consensu\n",
      "consequ\n",
      "conserv\n",
      "conservatori\n",
      "consid\n",
      "consider\n",
      "consist\n",
      "consol\n",
      "consolid\n",
      "consomm\n",
      "conspicu\n",
      "consta\n",
      "constant\n",
      "constitu\n",
      "constitut\n",
      "constrain\n",
      "constraint\n",
      "construct\n",
      "consult\n",
      "consum\n",
      "consumm\n",
      "consumo\n",
      "consumpt\n",
      "conta\n",
      "contact\n",
      "contain\n",
      "contemporari\n",
      "contempt\n",
      "content\n",
      "contest\n",
      "context\n",
      "contextgener\n",
      "contextu\n",
      "contien\n",
      "contigu\n",
      "contina\n",
      "continu\n",
      "continuum\n",
      "conto\n",
      "contour\n",
      "contracept\n",
      "contract\n",
      "contractor\n",
      "contradict\n",
      "contrast\n",
      "contrastor\n",
      "contribut\n",
      "contributor\n",
      "contriev\n",
      "contriv\n",
      "contrived\n",
      "control\n",
      "controlnet\n",
      "conv\n",
      "conveni\n",
      "convenic\n",
      "convent\n",
      "conver\n",
      "converg\n",
      "convers\n",
      "conversions\n",
      "convert\n",
      "convertirs\n",
      "conves\n",
      "convey\n",
      "convfinqa\n",
      "convieni\n",
      "convinc\n",
      "convolut\n",
      "convquest\n",
      "conway\n",
      "cook\n",
      "coom\n",
      "cooper\n",
      "coordena\n",
      "coordin\n",
      "cop\n",
      "copa\n",
      "copal\n",
      "copenhagen\n",
      "copernicu\n",
      "copi\n",
      "copiapoa\n",
      "copilot\n",
      "copper\n",
      "copyright\n",
      "coqa\n",
      "coqaqg\n",
      "cor\n",
      "coraal\n",
      "coral\n",
      "cord\n",
      "cordial\n",
      "core\n",
      "corefer\n",
      "coreferenti\n",
      "corenlp\n",
      "coreset\n",
      "corner\n",
      "cornerston\n",
      "cornic\n",
      "coronari\n",
      "coronaviru\n",
      "coronavirus\n",
      "coropu\n",
      "corp\n",
      "corpernicu\n",
      "corpor\n",
      "corpora\n",
      "corporaci\n",
      "corpu\n",
      "correct\n",
      "correctli\n",
      "correl\n",
      "correspond\n",
      "correspondient\n",
      "corros\n",
      "corrupt\n",
      "cortex\n",
      "cosa\n",
      "cosin\n",
      "cosmet\n",
      "cosmo\n",
      "cost\n",
      "costli\n",
      "cot\n",
      "cotain\n",
      "cotcollectionmulticonfig\n",
      "cotton\n",
      "cough\n",
      "couldn\n",
      "council\n",
      "councilmen\n",
      "counsel\n",
      "counselor\n",
      "count\n",
      "counter\n",
      "counterfactu\n",
      "countermeasu\n",
      "counterpart\n",
      "counti\n",
      "countri\n",
      "country\n",
      "countrywid\n",
      "countvector\n",
      "coupl\n",
      "courier\n",
      "cours\n",
      "courson\n",
      "court\n",
      "courtesi\n",
      "coutur\n",
      "cov\n",
      "covari\n",
      "cover\n",
      "coverag\n",
      "covertyp\n",
      "covid\n",
      "covidqa\n",
      "covost\n",
      "cow\n",
      "cowhey\n",
      "coyo\n",
      "cp\n",
      "cpc\n",
      "cpg\n",
      "cpi\n",
      "cpp\n",
      "cppe\n",
      "cpu\n",
      "cqa\n",
      "cqadupstack\n",
      "cqia\n",
      "cqt\n",
      "cr\n",
      "crab\n",
      "crack\n",
      "craft\n",
      "craftsmanship\n",
      "craigslist\n",
      "craiyon\n",
      "cranfield\n",
      "cranial\n",
      "cranio\n",
      "crash\n",
      "crave\n",
      "crawl\n",
      "crawler\n",
      "crazi\n",
      "creat\n",
      "creation\n",
      "creationd\n",
      "creativ\n",
      "creativeml\n",
      "creator\n",
      "creatur\n",
      "credenti\n",
      "credit\n",
      "creditor\n",
      "crello\n",
      "crew\n",
      "crf\n",
      "cri\n",
      "criado\n",
      "crime\n",
      "crimin\n",
      "crimsonw\n",
      "criteria\n",
      "critic\n",
      "criticbench\n",
      "critiqu\n",
      "croatia\n",
      "croatian\n",
      "crocodil\n",
      "crocodilian\n",
      "croissant\n",
      "croissantllm\n",
      "crop\n",
      "cross\n",
      "crosslingu\n",
      "crossmod\n",
      "crossner\n",
      "crosssum\n",
      "crossview\n",
      "crosswalk\n",
      "crossway\n",
      "crossword\n",
      "crow\n",
      "crowd\n",
      "crowdsourc\n",
      "crowdspeech\n",
      "crowdwork\n",
      "crown\n",
      "crucial\n",
      "crumb\n",
      "crunch\n",
      "cruso\n",
      "cruxev\n",
      "cruz\n",
      "cryptic\n",
      "crypto\n",
      "cryptocen\n",
      "cryptococcu\n",
      "cryptocurr\n",
      "cryptodata\n",
      "cryptonew\n",
      "cryptonit\n",
      "crystina\n",
      "cs\n",
      "csail\n",
      "csat\n",
      "csgo\n",
      "csharp\n",
      "csj\n",
      "csl\n",
      "csqa\n",
      "csr\n",
      "css\n",
      "cst\n",
      "cstorm\n",
      "csun\n",
      "csv\n",
      "ct\n",
      "ctell\n",
      "cthead\n",
      "cti\n",
      "ctn\n",
      "ctor\n",
      "ctrl\n",
      "cu\n",
      "cuad\n",
      "cuba\n",
      "cube\n",
      "cubic\n",
      "cubism\n",
      "cucumb\n",
      "cuda\n",
      "cue\n",
      "cuenca\n",
      "cui\n",
      "culinari\n",
      "culmin\n",
      "cult\n",
      "cultiv\n",
      "cultivar\n",
      "cultur\n",
      "culturalbench\n",
      "culturalheritag\n",
      "culturalteam\n",
      "culturax\n",
      "cum\n",
      "cumul\n",
      "cun\n",
      "cunxiang\n",
      "cup\n",
      "curat\n",
      "curb\n",
      "curi\n",
      "curios\n",
      "curiosament\n",
      "curiou\n",
      "curit\n",
      "curl\n",
      "curli\n",
      "curr\n",
      "currenc\n",
      "current\n",
      "curricula\n",
      "curriculum\n",
      "curso\n",
      "custom\n",
      "customiz\n",
      "cut\n",
      "cute\n",
      "cution\n",
      "cutoff\n",
      "cutout\n",
      "cv\n",
      "cvat\n",
      "cvpr\n",
      "cvprw\n",
      "cwle\n",
      "cxcvz\n",
      "cxr\n",
      "cy\n",
      "cyber\n",
      "cyberag\n",
      "cyberbulli\n",
      "cybernet\n",
      "cybersecur\n",
      "cycl\n",
      "cyclegan\n",
      "cyclinglan\n",
      "cyclist\n",
      "cylind\n",
      "cylindr\n",
      "cylonix\n",
      "cypher\n",
      "cyril\n",
      "cystic\n",
      "cytosin\n",
      "cz\n",
      "czech\n",
      "czechtour\n",
      "czvg\n",
      "da\n",
      "dac\n",
      "dadit\n",
      "dagbladet\n",
      "dagdelen\n",
      "dahua\n",
      "daiheng\n",
      "daili\n",
      "daill\n",
      "dailydialog\n",
      "dailyhunt\n",
      "dailymail\n",
      "dair\n",
      "dairi\n",
      "daisuk\n",
      "dal\n",
      "dalam\n",
      "dale\n",
      "dali\n",
      "daliani\n",
      "daligenericiter\n",
      "dall\n",
      "dalldata\n",
      "dalle\n",
      "dalton\n",
      "damag\n",
      "damien\n",
      "dan\n",
      "danbooru\n",
      "danc\n",
      "dane\n",
      "danelljan\n",
      "danger\n",
      "daniel\n",
      "danielcerda\n",
      "danish\n",
      "danker\n",
      "danlp\n",
      "dansk\n",
      "dant\n",
      "dar\n",
      "darija\n",
      "dark\n",
      "darpa\n",
      "dart\n",
      "das\n",
      "dash\n",
      "dashboard\n",
      "dashcam\n",
      "data\n",
      "databas\n",
      "databench\n",
      "databrick\n",
      "datacard\n",
      "datacomp\n",
      "datafram\n",
      "dataoptim\n",
      "datapoint\n",
      "datas\n",
      "dataset\n",
      "datasetdict\n",
      "datasetkey\n",
      "datasheet\n",
      "datatext\n",
      "datatranslationdt\n",
      "datatset\n",
      "date\n",
      "dater\n",
      "dato\n",
      "datset\n",
      "david\n",
      "davinci\n",
      "dawn\n",
      "day\n",
      "daylight\n",
      "dayma\n",
      "dayton\n",
      "db\n",
      "dbpedia\n",
      "dbyte\n",
      "dcase\n",
      "dcda\n",
      "dcm\n",
      "ddebdc\n",
      "ddo\n",
      "ddt\n",
      "dead\n",
      "deal\n",
      "death\n",
      "debat\n",
      "debatepedia\n",
      "debatesum\n",
      "debatewis\n",
      "deblur\n",
      "dec\n",
      "decad\n",
      "decay\n",
      "decemb\n",
      "decept\n",
      "decid\n",
      "decis\n",
      "deck\n",
      "declar\n",
      "decod\n",
      "decompos\n",
      "decontamin\n",
      "decreas\n",
      "dedic\n",
      "dedup\n",
      "dedupl\n",
      "deep\n",
      "deepa\n",
      "deepb\n",
      "deeper\n",
      "deepfak\n",
      "deepgh\n",
      "deepl\n",
      "deer\n",
      "def\n",
      "default\n",
      "defect\n",
      "defin\n",
      "definit\n",
      "degre\n",
      "deia\n",
      "del\n",
      "delay\n",
      "delet\n",
      "delimit\n",
      "delin\n",
      "delova\n",
      "demand\n",
      "demarc\n",
      "demner\n",
      "demo\n",
      "democrat\n",
      "demograph\n",
      "demon\n",
      "demonstr\n",
      "den\n",
      "denisenko\n",
      "denmark\n",
      "denois\n",
      "denorm\n",
      "denot\n",
      "dens\n",
      "densiti\n",
      "depart\n",
      "depend\n",
      "depict\n",
      "deplain\n",
      "deploy\n",
      "deport\n",
      "deprec\n",
      "depress\n",
      "dept\n",
      "depth\n",
      "der\n",
      "derain\n",
      "deriv\n",
      "dermatoscop\n",
      "desc\n",
      "describ\n",
      "descript\n",
      "descriptioncod\n",
      "descriptor\n",
      "descritpion\n",
      "design\n",
      "desir\n",
      "desmond\n",
      "despit\n",
      "destin\n",
      "detach\n",
      "detaljan\n",
      "detect\n",
      "determin\n",
      "determinar\n",
      "deusto\n",
      "deutsch\n",
      "dev\n",
      "devanagari\n",
      "develop\n",
      "devic\n",
      "devop\n",
      "devtest\n",
      "dexter\n",
      "df\n",
      "dfe\n",
      "dfki\n",
      "dfp\n",
      "dgen\n",
      "dgt\n",
      "dhivehi\n",
      "dhruv\n",
      "di\n",
      "diabet\n",
      "diac\n",
      "diachron\n",
      "diacrit\n",
      "diagnos\n",
      "diagnosi\n",
      "diagnost\n",
      "diagram\n",
      "dialect\n",
      "dialog\n",
      "dialogsum\n",
      "dialogu\n",
      "dialysi\n",
      "diamond\n",
      "diaphragm\n",
      "diaporth\n",
      "dict\n",
      "dictat\n",
      "dictionari\n",
      "did\n",
      "dietitian\n",
      "differ\n",
      "differenti\n",
      "difficult\n",
      "difficulti\n",
      "diffus\n",
      "diffusiondb\n",
      "diffusionf\n",
      "difraud\n",
      "digest\n",
      "digicam\n",
      "digit\n",
      "digitis\n",
      "digitoday\n",
      "dijon\n",
      "dil\n",
      "diller\n",
      "dimens\n",
      "dimension\n",
      "dina\n",
      "dine\n",
      "dinhanhx\n",
      "dior\n",
      "dir\n",
      "direct\n",
      "directli\n",
      "directori\n",
      "directrunn\n",
      "dirichlet\n",
      "disabl\n",
      "disambigu\n",
      "disc\n",
      "discard\n",
      "discharg\n",
      "disciplin\n",
      "disclaim\n",
      "disco\n",
      "discord\n",
      "discours\n",
      "discov\n",
      "discoveri\n",
      "discrep\n",
      "discret\n",
      "discrimin\n",
      "discuss\n",
      "dise\n",
      "diseas\n",
      "disentangl\n",
      "disfl\n",
      "disfluenc\n",
      "disfluent\n",
      "disgust\n",
      "disk\n",
      "disks\n",
      "disord\n",
      "dispar\n",
      "dispatch\n",
      "display\n",
      "dispos\n",
      "disrupt\n",
      "dissert\n",
      "dissimilar\n",
      "distanc\n",
      "distant\n",
      "distil\n",
      "distilabel\n",
      "distilbert\n",
      "distinct\n",
      "distinguish\n",
      "distractor\n",
      "distribut\n",
      "district\n",
      "divemt\n",
      "diverg\n",
      "divers\n",
      "diversifi\n",
      "divid\n",
      "divis\n",
      "divk\n",
      "dk\n",
      "dna\n",
      "dng\n",
      "dobermann\n",
      "dobijaju\n",
      "doc\n",
      "docbank\n",
      "docci\n",
      "doclaynet\n",
      "docqueri\n",
      "docr\n",
      "docstr\n",
      "doctor\n",
      "document\n",
      "docvqa\n",
      "dodrio\n",
      "doe\n",
      "doesn\n",
      "dof\n",
      "dog\n",
      "dogc\n",
      "doi\n",
      "dollar\n",
      "dolli\n",
      "dolphin\n",
      "domain\n",
      "domest\n",
      "dominio\n",
      "domino\n",
      "don\n",
      "donat\n",
      "dond\n",
      "dongyeop\n",
      "donn\n",
      "donor\n",
      "donut\n",
      "doodl\n",
      "door\n",
      "dor\n",
      "dorsal\n",
      "dot\n",
      "douan\n",
      "doubl\n",
      "doubt\n",
      "dove\n",
      "download\n",
      "downsampl\n",
      "downscal\n",
      "downstream\n",
      "downward\n",
      "dpo\n",
      "dpr\n",
      "dq\n",
      "dr\n",
      "draft\n",
      "dragon\n",
      "dragonair\n",
      "dramat\n",
      "drastic\n",
      "draw\n",
      "drawn\n",
      "dream\n",
      "dreambooth\n",
      "dreameditbench\n",
      "dri\n",
      "drill\n",
      "drink\n",
      "drive\n",
      "driven\n",
      "driver\n",
      "drl\n",
      "drone\n",
      "drop\n",
      "drowze\n",
      "drum\n",
      "ds\n",
      "dsir\n",
      "dss\n",
      "dt\n",
      "dtm\n",
      "dtype\n",
      "du\n",
      "dual\n",
      "duan\n",
      "ducaei\n",
      "duckdb\n",
      "duckietown\n",
      "dumb\n",
      "dummi\n",
      "dump\n",
      "dungeon\n",
      "duorc\n",
      "duplic\n",
      "durat\n",
      "dure\n",
      "durham\n",
      "durin\n",
      "dusk\n",
      "duskfal\n",
      "dutch\n",
      "dwie\n",
      "dynam\n",
      "dystroph\n",
      "eagl\n",
      "ear\n",
      "earli\n",
      "earlier\n",
      "earn\n",
      "earth\n",
      "earthquak\n",
      "eas\n",
      "easi\n",
      "easier\n",
      "easili\n",
      "east\n",
      "eastern\n",
      "easyportrait\n",
      "eat\n",
      "ebook\n",
      "ecdc\n",
      "ecinstruct\n",
      "eclass\n",
      "eclassqueri\n",
      "eclasstrainst\n",
      "eco\n",
      "ecolinguist\n",
      "ecolog\n",
      "ecommerc\n",
      "econo\n",
      "econom\n",
      "economi\n",
      "economia\n",
      "ecoset\n",
      "ecthr\n",
      "ed\n",
      "edacc\n",
      "edg\n",
      "edinburgh\n",
      "edit\n",
      "editor\n",
      "edoardo\n",
      "edouard\n",
      "edu\n",
      "eduardo\n",
      "educ\n",
      "edug\n",
      "edunov\n",
      "edward\n",
      "ee\n",
      "effect\n",
      "effici\n",
      "effort\n",
      "ego\n",
      "egocentr\n",
      "egod\n",
      "egoexod\n",
      "egoinstructor\n",
      "egolearn\n",
      "egovideo\n",
      "egyptian\n",
      "ehealth\n",
      "ehr\n",
      "ehristoforu\n",
      "ehu\n",
      "eindhoven\n",
      "eitb\n",
      "ejemplo\n",
      "el\n",
      "electr\n",
      "electron\n",
      "element\n",
      "elementari\n",
      "eleutherai\n",
      "elev\n",
      "elhuyar\n",
      "eli\n",
      "elicit\n",
      "elif\n",
      "elimin\n",
      "elit\n",
      "elliott\n",
      "elq\n",
      "elrc\n",
      "els\n",
      "elsevi\n",
      "elucid\n",
      "elysium\n",
      "em\n",
      "ema\n",
      "email\n",
      "emanuel\n",
      "emb\n",
      "embed\n",
      "embodi\n",
      "embrac\n",
      "embrapa\n",
      "emea\n",
      "emerg\n",
      "emil\n",
      "emir\n",
      "emiss\n",
      "emnlp\n",
      "emo\n",
      "emocontext\n",
      "emodb\n",
      "emoji\n",
      "emot\n",
      "empathet\n",
      "emphas\n",
      "emphasi\n",
      "empir\n",
      "employ\n",
      "employe\n",
      "empow\n",
      "empti\n",
      "emul\n",
      "en\n",
      "enabl\n",
      "encapsul\n",
      "enchanc\n",
      "enchondroma\n",
      "encod\n",
      "encodec\n",
      "encompass\n",
      "encount\n",
      "encourag\n",
      "encycloped\n",
      "encyclopedia\n",
      "end\n",
      "endang\n",
      "endofprompt\n",
      "endoftext\n",
      "endometriosi\n",
      "endur\n",
      "enem\n",
      "energi\n",
      "eng\n",
      "engag\n",
      "engin\n",
      "england\n",
      "english\n",
      "enhanc\n",
      "eni\n",
      "enjem\n",
      "enjoy\n",
      "enrich\n",
      "enron\n",
      "ensembl\n",
      "ensur\n",
      "ent\n",
      "entail\n",
      "enterpris\n",
      "entertain\n",
      "enth\n",
      "enthusiast\n",
      "entir\n",
      "entiti\n",
      "entitl\n",
      "entr\n",
      "entranc\n",
      "entri\n",
      "envi\n",
      "environ\n",
      "environment\n",
      "enzh\n",
      "eol\n",
      "eosf\n",
      "ep\n",
      "epic\n",
      "episod\n",
      "eprint\n",
      "equal\n",
      "equip\n",
      "equirectangular\n",
      "equiti\n",
      "equival\n",
      "er\n",
      "era\n",
      "erhu\n",
      "eric\n",
      "ernest\n",
      "erquiaga\n",
      "err\n",
      "errnew\n",
      "erron\n",
      "error\n",
      "erzya\n",
      "es\n",
      "esa\n",
      "esb\n",
      "esc\n",
      "escagleu\n",
      "escal\n",
      "escap\n",
      "esci\n",
      "escorpiu\n",
      "eslo\n",
      "espa\n",
      "especi\n",
      "essay\n",
      "essenc\n",
      "essenti\n",
      "est\n",
      "esta\n",
      "establish\n",
      "estim\n",
      "estonian\n",
      "et\n",
      "etal\n",
      "etat\n",
      "etci\n",
      "ethan\n",
      "ethereum\n",
      "ethic\n",
      "ethnic\n",
      "etho\n",
      "etth\n",
      "ettm\n",
      "eu\n",
      "euconst\n",
      "eunect\n",
      "eur\n",
      "eurlex\n",
      "europ\n",
      "europarl\n",
      "european\n",
      "europeana\n",
      "eurosat\n",
      "eurovoc\n",
      "euscrawl\n",
      "eusexam\n",
      "eval\n",
      "evalu\n",
      "evaluationhub\n",
      "evan\n",
      "evenli\n",
      "event\n",
      "everi\n",
      "everyayah\n",
      "everyday\n",
      "everyon\n",
      "everyth\n",
      "evid\n",
      "evol\n",
      "evolv\n",
      "ewe\n",
      "ex\n",
      "exact\n",
      "exactli\n",
      "exam\n",
      "examin\n",
      "exampl\n",
      "excav\n",
      "excel\n",
      "excerpt\n",
      "excess\n",
      "exchang\n",
      "excit\n",
      "exclud\n",
      "exclus\n",
      "execut\n",
      "executor\n",
      "exempl\n",
      "exemplar\n",
      "exercis\n",
      "exhaust\n",
      "exhibit\n",
      "exist\n",
      "exovideo\n",
      "expand\n",
      "expans\n",
      "expect\n",
      "expens\n",
      "experi\n",
      "experienc\n",
      "experiment\n",
      "expert\n",
      "expertis\n",
      "explain\n",
      "explan\n",
      "explicit\n",
      "explicitli\n",
      "exploit\n",
      "explor\n",
      "exponenti\n",
      "export\n",
      "expos\n",
      "exposit\n",
      "express\n",
      "extend\n",
      "extens\n",
      "extent\n",
      "extern\n",
      "extra\n",
      "extract\n",
      "extractor\n",
      "extraglu\n",
      "extravas\n",
      "extrem\n",
      "extrins\n",
      "extrus\n",
      "extrusor\n",
      "exusiai\n",
      "eye\n",
      "eyebrow\n",
      "eyepatch\n",
      "eyewear\n",
      "eyjafjalla\n",
      "fa\n",
      "fabner\n",
      "facad\n",
      "face\n",
      "facebook\n",
      "facial\n",
      "facil\n",
      "facilit\n",
      "fact\n",
      "factoid\n",
      "factor\n",
      "factori\n",
      "factual\n",
      "fail\n",
      "failur\n",
      "faint\n",
      "fair\n",
      "faiss\n",
      "faith\n",
      "fake\n",
      "falcon\n",
      "fall\n",
      "fals\n",
      "falsetto\n",
      "famil\n",
      "famili\n",
      "familiar\n",
      "famou\n",
      "fan\n",
      "fancap\n",
      "fandom\n",
      "fang\n",
      "fangyu\n",
      "fanpag\n",
      "faq\n",
      "far\n",
      "farcry\n",
      "farfetch\n",
      "farfield\n",
      "faroes\n",
      "farsi\n",
      "fashion\n",
      "fashionfail\n",
      "fashionpedia\n",
      "fast\n",
      "faster\n",
      "fastgan\n",
      "fasttext\n",
      "fate\n",
      "fault\n",
      "favori\n",
      "favour\n",
      "fawk\n",
      "faycal\n",
      "fazeka\n",
      "fbin\n",
      "fear\n",
      "feasibl\n",
      "feat\n",
      "feater\n",
      "feather\n",
      "featur\n",
      "feb\n",
      "februari\n",
      "fed\n",
      "feder\n",
      "fedor\n",
      "feed\n",
      "feedback\n",
      "feel\n",
      "feelin\n",
      "feet\n",
      "feetfoot\n",
      "fei\n",
      "feliu\n",
      "felix\n",
      "femal\n",
      "female\n",
      "femin\n",
      "fen\n",
      "fendi\n",
      "feng\n",
      "fengshenbang\n",
      "fertil\n",
      "fession\n",
      "festcat\n",
      "fetch\n",
      "fetv\n",
      "fever\n",
      "fewer\n",
      "feynman\n",
      "fft\n",
      "fhdd\n",
      "fi\n",
      "fiammetta\n",
      "fiction\n",
      "fictiti\n",
      "fidel\n",
      "field\n",
      "fierc\n",
      "fiftyon\n",
      "fig\n",
      "fight\n",
      "fighter\n",
      "figur\n",
      "fila\n",
      "file\n",
      "filenam\n",
      "filepath\n",
      "filighera\n",
      "filipino\n",
      "film\n",
      "filter\n",
      "fin\n",
      "final\n",
      "finalbartmodel\n",
      "financ\n",
      "financi\n",
      "fine\n",
      "finer\n",
      "finetun\n",
      "finev\n",
      "fineweb\n",
      "fingerprint\n",
      "finish\n",
      "finlex\n",
      "finna\n",
      "finnish\n",
      "finrag\n",
      "fintabnet\n",
      "fintwit\n",
      "fiqa\n",
      "firec\n",
      "firewatch\n",
      "fiscal\n",
      "fish\n",
      "fishey\n",
      "fiskmo\n",
      "fit\n",
      "fitbit\n",
      "fivek\n",
      "fix\n",
      "flac\n",
      "flag\n",
      "flair\n",
      "flamebring\n",
      "flametail\n",
      "flan\n",
      "flat\n",
      "flatten\n",
      "fleur\n",
      "flexibl\n",
      "fli\n",
      "flicker\n",
      "flickr\n",
      "flickrk\n",
      "flight\n",
      "flip\n",
      "flir\n",
      "float\n",
      "floco\n",
      "flood\n",
      "floor\n",
      "flore\n",
      "flourish\n",
      "flow\n",
      "flowchart\n",
      "flower\n",
      "fluenci\n",
      "fluent\n",
      "fluentui\n",
      "fluff\n",
      "fluoresc\n",
      "flush\n",
      "fn\n",
      "fo\n",
      "focal\n",
      "focu\n",
      "focus\n",
      "focuss\n",
      "foi\n",
      "foku\n",
      "fold\n",
      "folder\n",
      "follow\n",
      "fon\n",
      "fonction\n",
      "fondant\n",
      "fonseca\n",
      "font\n",
      "food\n",
      "foodseg\n",
      "foot\n",
      "footag\n",
      "footbal\n",
      "foothold\n",
      "footprint\n",
      "footwear\n",
      "fora\n",
      "forc\n",
      "forecast\n",
      "forefront\n",
      "foreground\n",
      "foreign\n",
      "forest\n",
      "foresti\n",
      "forev\n",
      "fork\n",
      "forklift\n",
      "form\n",
      "forma\n",
      "formal\n",
      "format\n",
      "formerli\n",
      "formul\n",
      "formula\n",
      "forum\n",
      "forward\n",
      "foster\n",
      "fouh\n",
      "foundat\n",
      "fourteen\n",
      "fourth\n",
      "fox\n",
      "fp\n",
      "fpt\n",
      "fquad\n",
      "fr\n",
      "fraction\n",
      "fractur\n",
      "fragment\n",
      "fragranc\n",
      "frame\n",
      "framework\n",
      "fran\n",
      "franc\n",
      "franka\n",
      "frase\n",
      "fraud\n",
      "freckl\n",
      "free\n",
      "freebas\n",
      "freed\n",
      "freehand\n",
      "freeli\n",
      "freesound\n",
      "french\n",
      "frenchmedmcqa\n",
      "frequenc\n",
      "frequent\n",
      "fri\n",
      "fridman\n",
      "friend\n",
      "friendli\n",
      "frodobot\n",
      "frog\n",
      "frontier\n",
      "frost\n",
      "frostleaf\n",
      "frquad\n",
      "fruit\n",
      "fs\n",
      "fsdk\n",
      "fsdkaggle\n",
      "ft\n",
      "fu\n",
      "fuel\n",
      "fuell\n",
      "fulli\n",
      "fulltext\n",
      "function\n",
      "fund\n",
      "fundament\n",
      "fungibl\n",
      "funni\n",
      "fuq\n",
      "furnitur\n",
      "furri\n",
      "furthermor\n",
      "fuse\n",
      "fushman\n",
      "fusion\n",
      "futur\n",
      "fvpl\n",
      "fylg\n",
      "ga\n",
      "gabon\n",
      "gaej\n",
      "gaepago\n",
      "gain\n",
      "galact\n",
      "galaxi\n",
      "galera\n",
      "galileo\n",
      "galleri\n",
      "gallicagram\n",
      "game\n",
      "gamephys\n",
      "gameplay\n",
      "gan\n",
      "gao\n",
      "gap\n",
      "garbag\n",
      "garcia\n",
      "garlic\n",
      "gate\n",
      "gateway\n",
      "gather\n",
      "gaug\n",
      "gave\n",
      "gavial\n",
      "gawain\n",
      "gazeta\n",
      "gazett\n",
      "gb\n",
      "gde\n",
      "ge\n",
      "gec\n",
      "geigl\n",
      "geitj\n",
      "gem\n",
      "gemini\n",
      "gemrec\n",
      "gen\n",
      "gencat\n",
      "gender\n",
      "gene\n",
      "gener\n",
      "generalist\n",
      "generaliz\n",
      "genom\n",
      "genr\n",
      "genshin\n",
      "gent\n",
      "genuin\n",
      "genwiki\n",
      "geo\n",
      "geobenchmark\n",
      "geoffrey\n",
      "geograph\n",
      "geographi\n",
      "geomagnet\n",
      "geometri\n",
      "geomorpholog\n",
      "geopolit\n",
      "geoqueri\n",
      "georg\n",
      "georgia\n",
      "geoscienc\n",
      "geosign\n",
      "geotiff\n",
      "german\n",
      "germandpr\n",
      "germani\n",
      "germanquad\n",
      "gerv\n",
      "gestur\n",
      "getimag\n",
      "ggjso\n",
      "ghomala\n",
      "ghost\n",
      "gi\n",
      "gib\n",
      "gid\n",
      "gif\n",
      "gigafida\n",
      "gigaspeech\n",
      "gigaword\n",
      "giornal\n",
      "giraff\n",
      "girl\n",
      "gisett\n",
      "git\n",
      "gitcoin\n",
      "github\n",
      "given\n",
      "gjsg\n",
      "gladiia\n",
      "glaiv\n",
      "glass\n",
      "glaze\n",
      "glc\n",
      "glenda\n",
      "gletscher\n",
      "glissando\n",
      "glm\n",
      "global\n",
      "globe\n",
      "glove\n",
      "glub\n",
      "glue\n",
      "glyph\n",
      "gmail\n",
      "gmasc\n",
      "gmbh\n",
      "gnome\n",
      "gnu\n",
      "goal\n",
      "goat\n",
      "gob\n",
      "goblin\n",
      "god\n",
      "goe\n",
      "goggl\n",
      "gohar\n",
      "goia\n",
      "golbat\n",
      "gold\n",
      "goldberg\n",
      "goldeen\n",
      "golden\n",
      "goldeney\n",
      "goldenglow\n",
      "goldfish\n",
      "golduck\n",
      "golel\n",
      "golem\n",
      "golf\n",
      "goliath\n",
      "golo\n",
      "gondii\n",
      "gone\n",
      "gong\n",
      "gonna\n",
      "gonzalez\n",
      "gooaq\n",
      "good\n",
      "goodread\n",
      "goog\n",
      "googl\n",
      "googler\n",
      "gore\n",
      "gorman\n",
      "got\n",
      "gotico\n",
      "gottschalk\n",
      "gou\n",
      "goud\n",
      "gov\n",
      "govern\n",
      "govreport\n",
      "goyal\n",
      "gp\n",
      "gpe\n",
      "gpl\n",
      "gpt\n",
      "gpteacher\n",
      "gptinst\n",
      "gptlife\n",
      "gptneox\n",
      "gptout\n",
      "gptv\n",
      "gpu\n",
      "gqa\n",
      "gr\n",
      "grade\n",
      "gradual\n",
      "graduat\n",
      "graelo\n",
      "graft\n",
      "graham\n",
      "grain\n",
      "gram\n",
      "gramat\n",
      "grammar\n",
      "grammat\n",
      "grand\n",
      "grani\n",
      "grant\n",
      "granular\n",
      "grape\n",
      "grapevista\n",
      "graph\n",
      "graphem\n",
      "graphic\n",
      "grasp\n",
      "grass\n",
      "grate\n",
      "grave\n",
      "gravel\n",
      "grayscal\n",
      "graz\n",
      "grd\n",
      "great\n",
      "greater\n",
      "greatli\n",
      "greedi\n",
      "greek\n",
      "green\n",
      "greenru\n",
      "greentext\n",
      "greenwich\n",
      "greet\n",
      "gregor\n",
      "gremlin\n",
      "gretel\n",
      "gretelai\n",
      "grevi\n",
      "grey\n",
      "greynir\n",
      "greyscal\n",
      "grid\n",
      "grimer\n",
      "grit\n",
      "gritsevskiy\n",
      "grobid\n",
      "groceri\n",
      "grocerystor\n",
      "grok\n",
      "grone\n",
      "groningen\n",
      "groov\n",
      "ground\n",
      "groundbreak\n",
      "groundcocoa\n",
      "groundtruth\n",
      "group\n",
      "grover\n",
      "grow\n",
      "growlith\n",
      "grown\n",
      "growth\n",
      "grug\n",
      "grugbot\n",
      "gsd\n",
      "gsl\n",
      "gsm\n",
      "gsmk\n",
      "gsnvb\n",
      "gt\n",
      "gtdb\n",
      "gtdh\n",
      "gtsrb\n",
      "gtzan\n",
      "gu\n",
      "guag\n",
      "guan\n",
      "guangdong\n",
      "guanin\n",
      "guarani\n",
      "guarante\n",
      "guardian\n",
      "guayasamin\n",
      "guazou\n",
      "gucci\n",
      "gudivk\n",
      "guerquin\n",
      "guerr\n",
      "guerreiro\n",
      "guess\n",
      "gufm\n",
      "gug\n",
      "gugugo\n",
      "guhathakurta\n",
      "gui\n",
      "guid\n",
      "guidanc\n",
      "guidelin\n",
      "guilherm\n",
      "guillaum\n",
      "guinizelli\n",
      "guitarsproject\n",
      "gujarati\n",
      "gulf\n",
      "gum\n",
      "gun\n",
      "gundam\n",
      "guo\n",
      "gupta\n",
      "guptha\n",
      "gurevych\n",
      "gut\n",
      "gutenb\n",
      "gutenberg\n",
      "gutendex\n",
      "gutsch\n",
      "gutur\n",
      "guturalscream\n",
      "guynem\n",
      "guzheng\n",
      "guzm\n",
      "gv\n",
      "gw\n",
      "gwara\n",
      "gyeonggi\n",
      "gynecolog\n",
      "gz\n",
      "ha\n",
      "haber\n",
      "haberman\n",
      "habit\n",
      "hackathon\n",
      "hackerearth\n",
      "hae\n",
      "hagrid\n",
      "haiku\n",
      "hair\n",
      "hairband\n",
      "hairclip\n",
      "hakala\n",
      "hal\n",
      "half\n",
      "hallucin\n",
      "halo\n",
      "ham\n",
      "hamper\n",
      "han\n",
      "hand\n",
      "handbook\n",
      "handicraft\n",
      "handl\n",
      "handpick\n",
      "handwrit\n",
      "handwritten\n",
      "hang\n",
      "hanz\n",
      "hao\n",
      "happen\n",
      "happi\n",
      "har\n",
      "hard\n",
      "harder\n",
      "hardest\n",
      "hardhat\n",
      "hardwar\n",
      "harm\n",
      "harmless\n",
      "harmon\n",
      "harvard\n",
      "harvest\n",
      "hash\n",
      "hashtag\n",
      "hasso\n",
      "hat\n",
      "hate\n",
      "hatebert\n",
      "hatecheck\n",
      "hausa\n",
      "haut\n",
      "haven\n",
      "hay\n",
      "hayakawa\n",
      "hazard\n",
      "hbxc\n",
      "hc\n",
      "hd\n",
      "hdd\n",
      "hdf\n",
      "hdparmar\n",
      "head\n",
      "headach\n",
      "header\n",
      "headlamp\n",
      "headlin\n",
      "headphon\n",
      "headroom\n",
      "headset\n",
      "headwear\n",
      "health\n",
      "healthadvic\n",
      "healthcar\n",
      "healthcaremag\n",
      "healthi\n",
      "hear\n",
      "heard\n",
      "heart\n",
      "heartble\n",
      "hearthston\n",
      "heat\n",
      "heatlhlin\n",
      "heavi\n",
      "heavili\n",
      "hebrew\n",
      "hebrewstageandlyricswithnewlin\n",
      "hedc\n",
      "hedderich\n",
      "hee\n",
      "heegyu\n",
      "heel\n",
      "heewon\n",
      "hefti\n",
      "heiga\n",
      "height\n",
      "heightmap\n",
      "heilman\n",
      "helber\n",
      "helbereurosat\n",
      "held\n",
      "helicopt\n",
      "heliosbrahma\n",
      "hellagur\n",
      "hellaswag\n",
      "hello\n",
      "helmet\n",
      "heloc\n",
      "help\n",
      "helsinki\n",
      "henan\n",
      "henc\n",
      "hendryck\n",
      "heng\n",
      "henri\n",
      "hension\n",
      "hep\n",
      "hercul\n",
      "herebi\n",
      "heritag\n",
      "herm\n",
      "hero\n",
      "heron\n",
      "hertiag\n",
      "heterochromia\n",
      "heterogen\n",
      "heurist\n",
      "hex\n",
      "hexim\n",
      "hey\n",
      "hezar\n",
      "hezarai\n",
      "hf\n",
      "hh\n",
      "hhhh\n",
      "hi\n",
      "hiagm\n",
      "hibiscu\n",
      "hick\n",
      "hidden\n",
      "hidiffus\n",
      "hierarch\n",
      "hierarchi\n",
      "hieroglyph\n",
      "hieu\n",
      "hifitt\n",
      "higg\n",
      "high\n",
      "higher\n",
      "highest\n",
      "highli\n",
      "highlight\n",
      "highlightsum\n",
      "highwir\n",
      "hike\n",
      "hill\n",
      "hillshad\n",
      "himach\n",
      "himakunthala\n",
      "himani\n",
      "hindawi\n",
      "hindencorp\n",
      "hinder\n",
      "hindi\n",
      "hindsight\n",
      "hiner\n",
      "hing\n",
      "hingerl\n",
      "hinglish\n",
      "hint\n",
      "hip\n",
      "hipaa\n",
      "hiphop\n",
      "hippocamp\n",
      "hippocorpu\n",
      "hire\n",
      "hiris\n",
      "hiroto\n",
      "hiru\n",
      "hispan\n",
      "histogram\n",
      "histolog\n",
      "histopatholog\n",
      "histor\n",
      "histori\n",
      "hit\n",
      "hitmonchan\n",
      "hitmonle\n",
      "hitz\n",
      "hiujin\n",
      "hkcancor\n",
      "hkr\n",
      "hlgd\n",
      "hlr\n",
      "hlrdelay\n",
      "hlt\n",
      "hm\n",
      "hmdb\n",
      "hmin\n",
      "hnc\n",
      "hninn\n",
      "hnp\n",
      "ho\n",
      "hoard\n",
      "hoc\n",
      "hockey\n",
      "hoffman\n",
      "hoffmeist\n",
      "hofst\n",
      "hofsted\n",
      "hoge\n",
      "hokkien\n",
      "hold\n",
      "holder\n",
      "holdout\n",
      "hole\n",
      "holger\n",
      "holi\n",
      "holmen\n",
      "holo\n",
      "hologram\n",
      "home\n",
      "homepag\n",
      "homework\n",
      "homogen\n",
      "homograph\n",
      "homonymi\n",
      "homophob\n",
      "honda\n",
      "honest\n",
      "honesti\n",
      "hong\n",
      "honkai\n",
      "honneur\n",
      "hood\n",
      "hop\n",
      "hope\n",
      "hopkin\n",
      "horizon\n",
      "horizont\n",
      "horizontalmirror\n",
      "horn\n",
      "hors\n",
      "horsea\n",
      "horst\n",
      "hoshiguma\n",
      "hospit\n",
      "hospitalroom\n",
      "host\n",
      "hotb\n",
      "hotel\n",
      "hotpotqa\n",
      "hotspot\n",
      "hou\n",
      "hour\n",
      "hourli\n",
      "hous\n",
      "house\n",
      "household\n",
      "houston\n",
      "hovr\n",
      "howcroft\n",
      "howev\n",
      "howpublish\n",
      "howtom\n",
      "hp\n",
      "hq\n",
      "hr\n",
      "hrmoni\n",
      "hs\n",
      "hsd\n",
      "hsi\n",
      "hsinghai\n",
      "hsk\n",
      "hsplit\n",
      "htet\n",
      "html\n",
      "htr\n",
      "http\n",
      "hu\n",
      "hua\n",
      "huamultiscen\n",
      "huanfeng\n",
      "huang\n",
      "huap\n",
      "huatuo\n",
      "huatuom\n",
      "huazhi\n",
      "hub\n",
      "hubbl\n",
      "hudson\n",
      "hudsongqa\n",
      "huerta\n",
      "hueynemud\n",
      "hug\n",
      "huge\n",
      "hugggingfac\n",
      "hugginfac\n",
      "huggingfac\n",
      "huggingfaceh\n",
      "hugo\n",
      "huihuayin\n",
      "huil\n",
      "hulk\n",
      "hulu\n",
      "hum\n",
      "human\n",
      "humanev\n",
      "humanitarian\n",
      "humanoid\n",
      "humor\n",
      "humset\n",
      "hunalign\n",
      "hunan\n",
      "hundr\n",
      "hung\n",
      "hungari\n",
      "hungarian\n",
      "hunsum\n",
      "hunt\n",
      "huo\n",
      "hupd\n",
      "hurc\n",
      "hurt\n",
      "hvg\n",
      "hwa\n",
      "hwang\n",
      "hybrid\n",
      "hybridqa\n",
      "hyderabad\n",
      "hydrat\n",
      "hydrogen\n",
      "hydromyelia\n",
      "hydrophon\n",
      "hyp\n",
      "hyper\n",
      "hyperlink\n",
      "hyperparamet\n",
      "hypnosi\n",
      "hypo\n",
      "hypothes\n",
      "hypothesi\n",
      "hypothyroid\n",
      "hystoclass\n",
      "hz\n",
      "ia\n",
      "iaa\n",
      "iahlt\n",
      "ialcin\n",
      "iapp\n",
      "iasd\n",
      "ibdcolepi\n",
      "iberlef\n",
      "ibeta\n",
      "ibin\n",
      "ibm\n",
      "ibo\n",
      "icail\n",
      "icassp\n",
      "iccv\n",
      "iccvw\n",
      "icdar\n",
      "ice\n",
      "iceland\n",
      "icfoss\n",
      "icliniq\n",
      "iclr\n",
      "icml\n",
      "icon\n",
      "iconclass\n",
      "icra\n",
      "ict\n",
      "icu\n",
      "id\n",
      "idan\n",
      "ide\n",
      "idea\n",
      "ideal\n",
      "ideb\n",
      "ident\n",
      "identif\n",
      "identifi\n",
      "identificador\n",
      "identifikasi\n",
      "identifynam\n",
      "ideolog\n",
      "idiom\n",
      "idiomat\n",
      "idiosyncrat\n",
      "idl\n",
      "idlak\n",
      "idli\n",
      "idn\n",
      "ids\n",
      "idv\n",
      "idx\n",
      "ieee\n",
      "iemocap\n",
      "iepil\n",
      "ifrit\n",
      "igbo\n",
      "iglu\n",
      "ignatiu\n",
      "ignor\n",
      "igor\n",
      "ihi\n",
      "ii\n",
      "iic\n",
      "iict\n",
      "iii\n",
      "iiit\n",
      "iisc\n",
      "iiw\n",
      "ijcnn\n",
      "ijd\n",
      "ikeda\n",
      "il\n",
      "ile\n",
      "ill\n",
      "illeg\n",
      "illicit\n",
      "illinoi\n",
      "illumin\n",
      "illus\n",
      "illusionvqa\n",
      "illustr\n",
      "ilmi\n",
      "ilpd\n",
      "ilpost\n",
      "ilsp\n",
      "ilsvrc\n",
      "im\n",
      "imad\n",
      "imag\n",
      "imageboard\n",
      "imagedataset\n",
      "imagein\n",
      "imageinword\n",
      "imagenet\n",
      "imagenetk\n",
      "imagenett\n",
      "imagenetvc\n",
      "imagenhub\n",
      "imageom\n",
      "imagereview\n",
      "imagerewaddb\n",
      "imagerewarddb\n",
      "imageri\n",
      "imagestructur\n",
      "imagetest\n",
      "imagetext\n",
      "imagew\n",
      "imagewoof\n",
      "imagin\n",
      "imaginari\n",
      "imam\n",
      "imasc\n",
      "imbal\n",
      "imbalanc\n",
      "imcs\n",
      "imda\n",
      "imdb\n",
      "img\n",
      "imgdataset\n",
      "imgimg\n",
      "imglatex\n",
      "imgsi\n",
      "imit\n",
      "imlatex\n",
      "immedi\n",
      "immens\n",
      "immers\n",
      "immun\n",
      "imodel\n",
      "imp\n",
      "impact\n",
      "impair\n",
      "imped\n",
      "imper\n",
      "imperfect\n",
      "implement\n",
      "impli\n",
      "implic\n",
      "implicit\n",
      "import\n",
      "importantli\n",
      "impos\n",
      "imposit\n",
      "impract\n",
      "impress\n",
      "impression\n",
      "improv\n",
      "impuls\n",
      "impulso\n",
      "imu\n",
      "inactiv\n",
      "inadvert\n",
      "inappropri\n",
      "incel\n",
      "incelset\n",
      "incept\n",
      "inch\n",
      "incid\n",
      "incit\n",
      "incl\n",
      "inclin\n",
      "includ\n",
      "inclus\n",
      "incom\n",
      "incompat\n",
      "incomplet\n",
      "inconsist\n",
      "incorpor\n",
      "incorrect\n",
      "incorrectli\n",
      "increas\n",
      "increasingli\n",
      "ind\n",
      "indend\n",
      "independ\n",
      "index\n",
      "indi\n",
      "india\n",
      "indian\n",
      "indiana\n",
      "indic\n",
      "indigen\n",
      "indirect\n",
      "indiscrimin\n",
      "individu\n",
      "indonesia\n",
      "indonesian\n",
      "indonli\n",
      "indoor\n",
      "induc\n",
      "induct\n",
      "industri\n",
      "inf\n",
      "infant\n",
      "infer\n",
      "infil\n",
      "infinit\n",
      "inflamm\n",
      "inflat\n",
      "influenc\n",
      "info\n",
      "infobox\n",
      "infor\n",
      "inform\n",
      "informaci\n",
      "informat\n",
      "infrar\n",
      "infrastructur\n",
      "ingamefilenam\n",
      "ingredi\n",
      "inher\n",
      "inherit\n",
      "initi\n",
      "inject\n",
      "injuri\n",
      "inner\n",
      "innov\n",
      "inovacija\n",
      "inproceed\n",
      "input\n",
      "inquiri\n",
      "inria\n",
      "insect\n",
      "insecur\n",
      "insert\n",
      "insid\n",
      "insight\n",
      "insolit\n",
      "inspair\n",
      "inspect\n",
      "inspir\n",
      "instagram\n",
      "instal\n",
      "instanc\n",
      "instead\n",
      "institut\n",
      "instruct\n",
      "instructgpt\n",
      "instructorxl\n",
      "instrument\n",
      "insuffici\n",
      "insur\n",
      "int\n",
      "intak\n",
      "integr\n",
      "intel\n",
      "intellect\n",
      "intellectu\n",
      "intellig\n",
      "intend\n",
      "intens\n",
      "intensifi\n",
      "intent\n",
      "inter\n",
      "interact\n",
      "intercorp\n",
      "interfac\n",
      "interlingua\n",
      "intermedi\n",
      "intern\n",
      "internet\n",
      "internvideo\n",
      "interplay\n",
      "interpress\n",
      "interpret\n",
      "intersect\n",
      "interset\n",
      "intervent\n",
      "interview\n",
      "intfloat\n",
      "inton\n",
      "intra\n",
      "intric\n",
      "intrigu\n",
      "intrins\n",
      "intro\n",
      "introduc\n",
      "introduct\n",
      "invalid\n",
      "inventor\n",
      "inventori\n",
      "invers\n",
      "investig\n",
      "investor\n",
      "invit\n",
      "invoc\n",
      "invoic\n",
      "involv\n",
      "io\n",
      "iob\n",
      "ionospher\n",
      "iot\n",
      "ipa\n",
      "ipc\n",
      "iphon\n",
      "ipum\n",
      "ir\n",
      "iran\n",
      "ircam\n",
      "irct\n",
      "ird\n",
      "iren\n",
      "iri\n",
      "irish\n",
      "irrelev\n",
      "iryna\n",
      "isaf\n",
      "isic\n",
      "isir\n",
      "island\n",
      "isn\n",
      "isobench\n",
      "isol\n",
      "isolet\n",
      "isra\n",
      "israel\n",
      "issai\n",
      "issn\n",
      "issu\n",
      "istella\n",
      "istina\n",
      "ita\n",
      "itali\n",
      "italian\n",
      "itamediev\n",
      "item\n",
      "iter\n",
      "itg\n",
      "itn\n",
      "iv\n",
      "ivan\n",
      "ivd\n",
      "iwslt\n",
      "ixid\n",
      "izdvaja\n",
      "izdvojeni\n",
      "ja\n",
      "jaccard\n",
      "jack\n",
      "jacob\n",
      "jailbreak\n",
      "jailbreakv\n",
      "jamark\n",
      "jame\n",
      "jan\n",
      "janli\n",
      "janu\n",
      "januari\n",
      "japan\n",
      "japanes\n",
      "japanesegoblin\n",
      "jaquad\n",
      "jar\n",
      "jason\n",
      "jat\n",
      "java\n",
      "javascript\n",
      "jax\n",
      "jay\n",
      "jazz\n",
      "je\n",
      "jean\n",
      "jed\n",
      "jefersson\n",
      "jersey\n",
      "jessica\n",
      "jest\n",
      "jewelri\n",
      "jewik\n",
      "jfleg\n",
      "jglue\n",
      "ji\n",
      "jian\n",
      "jiang\n",
      "jianyi\n",
      "jiaqi\n",
      "jiatong\n",
      "jilan\n",
      "jin\n",
      "jina\n",
      "jinaai\n",
      "jingwen\n",
      "jmk\n",
      "jmmlu\n",
      "jmteb\n",
      "jo\n",
      "job\n",
      "joe\n",
      "joelito\n",
      "john\n",
      "join\n",
      "joint\n",
      "jointli\n",
      "joka\n",
      "joke\n",
      "jona\n",
      "jordan\n",
      "jordanian\n",
      "jordi\n",
      "jose\n",
      "joulin\n",
      "journal\n",
      "journalist\n",
      "journey\n",
      "joy\n",
      "jp\n",
      "jpeg\n",
      "jpegimagefil\n",
      "jpegimageplugin\n",
      "jpg\n",
      "jpn\n",
      "jpsz\n",
      "jrc\n",
      "js\n",
      "jsick\n",
      "json\n",
      "jsonl\n",
      "jsonlin\n",
      "jtin\n",
      "ju\n",
      "judg\n",
      "judgelm\n",
      "judgement\n",
      "judgment\n",
      "judici\n",
      "juicer\n",
      "juli\n",
      "julian\n",
      "julien\n",
      "june\n",
      "just\n",
      "justi\n",
      "justic\n",
      "justif\n",
      "jw\n",
      "jxx\n",
      "kabr\n",
      "kagentbench\n",
      "kaggl\n",
      "kai\n",
      "kaist\n",
      "kal\n",
      "kamath\n",
      "kang\n",
      "kannada\n",
      "kapitanov\n",
      "kar\n",
      "karina\n",
      "karmiq\n",
      "karpathi\n",
      "karpov\n",
      "katana\n",
      "kateryna\n",
      "kathbath\n",
      "kawai\n",
      "kazakh\n",
      "kazakhstan\n",
      "kb\n",
      "kbanken\n",
      "kbq\n",
      "kcbert\n",
      "kd\n",
      "kdconv\n",
      "kddcup\n",
      "keen\n",
      "keiller\n",
      "kenyan\n",
      "kept\n",
      "keremberk\n",
      "key\n",
      "keyi\n",
      "keypoint\n",
      "keystrok\n",
      "keyword\n",
      "kfupm\n",
      "kgqa\n",
      "kh\n",
      "khair\n",
      "khot\n",
      "khz\n",
      "ki\n",
      "kid\n",
      "kidney\n",
      "kiela\n",
      "kilcher\n",
      "kill\n",
      "kilt\n",
      "kim\n",
      "kin\n",
      "kind\n",
      "kindli\n",
      "kinet\n",
      "kinetics\n",
      "king\n",
      "kingdom\n",
      "kinyarwanda\n",
      "kiritrash\n",
      "kise\n",
      "kiswahili\n",
      "kit\n",
      "kitchen\n",
      "kitti\n",
      "kktni\n",
      "kkxa\n",
      "klasifikasi\n",
      "klexikon\n",
      "km\n",
      "kmmlu\n",
      "kn\n",
      "knock\n",
      "know\n",
      "knowledg\n",
      "known\n",
      "ko\n",
      "kobbq\n",
      "kocot\n",
      "kodialogbench\n",
      "koehn\n",
      "koja\n",
      "koje\n",
      "koji\n",
      "kolekcij\n",
      "kollava\n",
      "kollm\n",
      "komet\n",
      "komi\n",
      "kompaktnom\n",
      "konachan\n",
      "kong\n",
      "koopmanrl\n",
      "kopen\n",
      "kor\n",
      "korea\n",
      "korean\n",
      "koreasci\n",
      "kori\n",
      "kormedmcqa\n",
      "kornat\n",
      "korpu\n",
      "kotlin\n",
      "kovalenko\n",
      "koz\n",
      "kp\n",
      "kpwr\n",
      "kr\n",
      "krkr\n",
      "kroo\n",
      "krzysztof\n",
      "ksc\n",
      "kshivendu\n",
      "ksp\n",
      "ksponspeech\n",
      "kss\n",
      "kto\n",
      "kuehn\n",
      "kullan\n",
      "kullm\n",
      "kumar\n",
      "kurdish\n",
      "kutsenko\n",
      "kvanchiani\n",
      "kvgq\n",
      "kw\n",
      "kwiatkowski\n",
      "kyaw\n",
      "la\n",
      "lab\n",
      "label\n",
      "laboratori\n",
      "labs\n",
      "lack\n",
      "lada\n",
      "ladino\n",
      "lahan\n",
      "laion\n",
      "laionb\n",
      "lakera\n",
      "lama\n",
      "lambada\n",
      "lambda\n",
      "lamini\n",
      "lan\n",
      "land\n",
      "landcov\n",
      "landmark\n",
      "landsat\n",
      "landscap\n",
      "lane\n",
      "lang\n",
      "langchain\n",
      "langlai\n",
      "languag\n",
      "languang\n",
      "laparoscopi\n",
      "lappland\n",
      "larg\n",
      "larger\n",
      "largest\n",
      "lastli\n",
      "lat\n",
      "late\n",
      "latent\n",
      "later\n",
      "latest\n",
      "latex\n",
      "latin\n",
      "latitud\n",
      "latvian\n",
      "laugh\n",
      "launch\n",
      "laurent\n",
      "law\n",
      "lay\n",
      "layer\n",
      "layout\n",
      "lc\n",
      "lcqmc\n",
      "lcst\n",
      "ldjnr\n",
      "le\n",
      "lead\n",
      "leader\n",
      "leaderboard\n",
      "leaf\n",
      "leaflet\n",
      "leagu\n",
      "leak\n",
      "leakag\n",
      "lean\n",
      "learn\n",
      "learnabl\n",
      "leather\n",
      "leav\n",
      "lectivat\n",
      "lectur\n",
      "led\n",
      "ledit\n",
      "lee\n",
      "leeb\n",
      "left\n",
      "leg\n",
      "legal\n",
      "legalnero\n",
      "legisl\n",
      "legitim\n",
      "lei\n",
      "lemma\n",
      "len\n",
      "lener\n",
      "length\n",
      "lengthi\n",
      "lenguaj\n",
      "lenslesspicam\n",
      "leopard\n",
      "lepton\n",
      "lerch\n",
      "lesion\n",
      "lesser\n",
      "lesson\n",
      "let\n",
      "letter\n",
      "lettuc\n",
      "levantin\n",
      "level\n",
      "leverag\n",
      "levesqu\n",
      "lewi\n",
      "lex\n",
      "lexabsumm\n",
      "lexfil\n",
      "lexfridmanpodcast\n",
      "lexglu\n",
      "lexic\n",
      "lexicon\n",
      "lf\n",
      "lfid\n",
      "lfqa\n",
      "li\n",
      "liang\n",
      "liar\n",
      "liber\n",
      "librari\n",
      "librilight\n",
      "librispeech\n",
      "libritt\n",
      "librivox\n",
      "librosa\n",
      "licenc\n",
      "licens\n",
      "lidar\n",
      "life\n",
      "lifestyl\n",
      "light\n",
      "lightn\n",
      "lightweight\n",
      "like\n",
      "lila\n",
      "lim\n",
      "lima\n",
      "limit\n",
      "lin\n",
      "line\n",
      "linear\n",
      "liner\n",
      "ling\n",
      "lingua\n",
      "lingual\n",
      "linguist\n",
      "link\n",
      "linkedin\n",
      "linschoten\n",
      "linu\n",
      "linustechtip\n",
      "lion\n",
      "lip\n",
      "lipi\n",
      "lipogram\n",
      "lisc\n",
      "lisenc\n",
      "liskarm\n",
      "list\n",
      "listen\n",
      "lite\n",
      "liter\n",
      "literari\n",
      "literatur\n",
      "lithuanian\n",
      "littl\n",
      "liu\n",
      "lium\n",
      "live\n",
      "liver\n",
      "livonian\n",
      "livr\n",
      "lj\n",
      "ljivo\n",
      "ll\n",
      "llama\n",
      "llava\n",
      "llavar\n",
      "llc\n",
      "llm\n",
      "llmbar\n",
      "lm\n",
      "lmm\n",
      "lmqg\n",
      "lmsi\n",
      "lns\n",
      "lo\n",
      "load\n",
      "loader\n",
      "loan\n",
      "loc\n",
      "local\n",
      "locat\n",
      "loeb\n",
      "log\n",
      "logic\n",
      "logicnlg\n",
      "logiqa\n",
      "logist\n",
      "logo\n",
      "lojban\n",
      "loji\n",
      "lol\n",
      "long\n",
      "longer\n",
      "longform\n",
      "longitud\n",
      "longt\n",
      "look\n",
      "lookup\n",
      "loop\n",
      "lopez\n",
      "lora\n",
      "loralay\n",
      "loro\n",
      "loss\n",
      "lossless\n",
      "lot\n",
      "lott\n",
      "loui\n",
      "love\n",
      "low\n",
      "lower\n",
      "lowest\n",
      "lowkey\n",
      "lr\n",
      "lrec\n",
      "lsoie\n",
      "lsun\n",
      "lt\n",
      "lter\n",
      "lu\n",
      "lucen\n",
      "lucr\n",
      "luganda\n",
      "lui\n",
      "luke\n",
      "lumbar\n",
      "lumo\n",
      "luo\n",
      "luotuo\n",
      "luxuri\n",
      "lv\n",
      "lvi\n",
      "lvlm\n",
      "lwptl\n",
      "lycori\n",
      "lyd\n",
      "lyric\n",
      "ma\n",
      "maa\n",
      "mac\n",
      "macao\n",
      "macavaney\n",
      "machin\n",
      "machop\n",
      "mad\n",
      "madelon\n",
      "madison\n",
      "madlad\n",
      "madrid\n",
      "madurai\n",
      "mafand\n",
      "magallan\n",
      "magazin\n",
      "maghrebi\n",
      "magic\n",
      "magicbrush\n",
      "magnet\n",
      "magnitud\n",
      "mahapurana\n",
      "mail\n",
      "main\n",
      "mainland\n",
      "mainli\n",
      "maintain\n",
      "mainten\n",
      "major\n",
      "make\n",
      "maker\n",
      "makeup\n",
      "makhlyarchuk\n",
      "malay\n",
      "malayalam\n",
      "malaysia\n",
      "malciou\n",
      "male\n",
      "malform\n",
      "malhajar\n",
      "malici\n",
      "mall\n",
      "malta\n",
      "maltes\n",
      "mammal\n",
      "mammographi\n",
      "mammoth\n",
      "man\n",
      "manag\n",
      "mandarin\n",
      "manga\n",
      "manhattan\n",
      "mani\n",
      "manipul\n",
      "maniskil\n",
      "maniskill\n",
      "mannequin\n",
      "manner\n",
      "manot\n",
      "manta\n",
      "manticor\n",
      "manual\n",
      "manuel\n",
      "manufactur\n",
      "manuscript\n",
      "map\n",
      "marathi\n",
      "marathon\n",
      "marbl\n",
      "march\n",
      "marco\n",
      "marcu\n",
      "marek\n",
      "marelli\n",
      "margin\n",
      "mari\n",
      "maria\n",
      "marianmt\n",
      "marin\n",
      "mario\n",
      "maritim\n",
      "mark\n",
      "markdown\n",
      "marker\n",
      "market\n",
      "marketplac\n",
      "markup\n",
      "marneff\n",
      "marrow\n",
      "martin\n",
      "marvel\n",
      "marvin\n",
      "masakhan\n",
      "mascarilla\n",
      "mask\n",
      "masri\n",
      "mass\n",
      "massiv\n",
      "master\n",
      "mat\n",
      "match\n",
      "materi\n",
      "math\n",
      "mathcod\n",
      "mathemat\n",
      "mathvers\n",
      "mathvista\n",
      "matlok\n",
      "matplotlib\n",
      "matric\n",
      "matrix\n",
      "matsynth\n",
      "matter\n",
      "matthew\n",
      "matur\n",
      "mawp\n",
      "max\n",
      "maxim\n",
      "maximum\n",
      "maxm\n",
      "maxmin\n",
      "mayb\n",
      "mayo\n",
      "mayott\n",
      "mazeika\n",
      "mb\n",
      "mbart\n",
      "mbpp\n",
      "mc\n",
      "mcc\n",
      "mcnet\n",
      "mcq\n",
      "mcqa\n",
      "mcrb\n",
      "mcv\n",
      "md\n",
      "mean\n",
      "meaning\n",
      "meant\n",
      "meanwhil\n",
      "measur\n",
      "mechan\n",
      "med\n",
      "medconceptsqa\n",
      "meddocan\n",
      "medi\n",
      "media\n",
      "mediaspeech\n",
      "mediasum\n",
      "mediat\n",
      "medic\n",
      "medicin\n",
      "mediev\n",
      "medinstruct\n",
      "mediqa\n",
      "medium\n",
      "medjool\n",
      "medlexsp\n",
      "medlin\n",
      "medmcqa\n",
      "medqa\n",
      "medrag\n",
      "meet\n",
      "mega\n",
      "mel\n",
      "melanoma\n",
      "melantha\n",
      "mele\n",
      "melissa\n",
      "mellon\n",
      "melodi\n",
      "meltpool\n",
      "member\n",
      "membership\n",
      "membran\n",
      "meme\n",
      "memori\n",
      "men\n",
      "mendeley\n",
      "meningioma\n",
      "menswear\n",
      "mental\n",
      "mention\n",
      "mentor\n",
      "merchant\n",
      "mere\n",
      "merg\n",
      "merval\n",
      "mesi\n",
      "messag\n",
      "messaih\n",
      "messeng\n",
      "meta\n",
      "metacloak\n",
      "metadata\n",
      "metafil\n",
      "metainform\n",
      "metal\n",
      "metalwoz\n",
      "metaphor\n",
      "metashift\n",
      "meteorolog\n",
      "meter\n",
      "method\n",
      "methodolog\n",
      "methyl\n",
      "meticul\n",
      "metoprolol\n",
      "metric\n",
      "metro\n",
      "metropolitan\n",
      "mevak\n",
      "mevakerconctre\n",
      "mexam\n",
      "mexican\n",
      "mexico\n",
      "mflag\n",
      "mgb\n",
      "mhal\n",
      "mhsma\n",
      "mi\n",
      "michael\n",
      "michal\n",
      "micro\n",
      "microphon\n",
      "microscopi\n",
      "microseism\n",
      "microsoft\n",
      "middl\n",
      "midjourney\n",
      "mike\n",
      "mil\n",
      "miladi\n",
      "mile\n",
      "milebench\n",
      "militair\n",
      "militari\n",
      "miller\n",
      "millet\n",
      "million\n",
      "millionth\n",
      "millj\n",
      "milo\n",
      "mimetyp\n",
      "mimic\n",
      "mimick\n",
      "min\n",
      "mina\n",
      "minako\n",
      "minangkabau\n",
      "minari\n",
      "mind\n",
      "minecraft\n",
      "minedream\n",
      "miner\n",
      "mineur\n",
      "ming\n",
      "mingz\n",
      "minh\n",
      "minhash\n",
      "mini\n",
      "minicpm\n",
      "minier\n",
      "minigpt\n",
      "minilm\n",
      "minim\n",
      "minimalist\n",
      "minimum\n",
      "minipil\n",
      "minist\n",
      "ministerio\n",
      "ministri\n",
      "minivan\n",
      "minkin\n",
      "minnad\n",
      "minnadechat\n",
      "minor\n",
      "minqi\n",
      "minueza\n",
      "minut\n",
      "mio\n",
      "mip\n",
      "mipvu\n",
      "mir\n",
      "mira\n",
      "miracl\n",
      "mirage\n",
      "miren\n",
      "mirror\n",
      "mirroshandel\n",
      "misanthrop\n",
      "misc\n",
      "miscellan\n",
      "misconcept\n",
      "misinfo\n",
      "mislabel\n",
      "mislead\n",
      "misma\n",
      "mismatch\n",
      "misogynist\n",
      "miss\n",
      "misser\n",
      "missingkey\n",
      "mission\n",
      "misskey\n",
      "misspel\n",
      "mistak\n",
      "mistral\n",
      "misus\n",
      "mit\n",
      "mitig\n",
      "mitjan\n",
      "mitochondria\n",
      "mitosi\n",
      "mitr\n",
      "mitsua\n",
      "mitsufuji\n",
      "mix\n",
      "mixk\n",
      "mixtral\n",
      "mixtur\n",
      "miyata\n",
      "mizuki\n",
      "mj\n",
      "mjsynth\n",
      "mjzgj\n",
      "mkdir\n",
      "mkh\n",
      "mkqa\n",
      "ml\n",
      "mlama\n",
      "mlb\n",
      "mlcommon\n",
      "mldr\n",
      "mlia\n",
      "mll\n",
      "mllm\n",
      "mlm\n",
      "mlqa\n",
      "mlqe\n",
      "mlst\n",
      "mlsum\n",
      "mm\n",
      "mmbench\n",
      "mmc\n",
      "mmdetect\n",
      "mme\n",
      "mmhal\n",
      "mmlu\n",
      "mmmu\n",
      "mmpose\n",
      "mmsd\n",
      "mmstar\n",
      "mmt\n",
      "mmvp\n",
      "mn\n",
      "mnbvc\n",
      "mnist\n",
      "mnli\n",
      "mnrl\n",
      "mnt\n",
      "mo\n",
      "mobi\n",
      "mobil\n",
      "mocha\n",
      "mock\n",
      "mockup\n",
      "mod\n",
      "modal\n",
      "mode\n",
      "model\n",
      "modela\n",
      "modellem\n",
      "modelo\n",
      "moder\n",
      "modern\n",
      "modic\n",
      "modif\n",
      "modifi\n",
      "modul\n",
      "modular\n",
      "modulo\n",
      "moedict\n",
      "mohamad\n",
      "mohammad\n",
      "mohiniyattam\n",
      "moir\n",
      "mojok\n",
      "mol\n",
      "molar\n",
      "mold\n",
      "moldavian\n",
      "mole\n",
      "molecualr\n",
      "molecul\n",
      "molecular\n",
      "molfromsmil\n",
      "moltosmil\n",
      "moment\n",
      "momentum\n",
      "momo\n",
      "mon\n",
      "mona\n",
      "monan\n",
      "monash\n",
      "monday\n",
      "monet\n",
      "money\n",
      "mongolian\n",
      "monitor\n",
      "monk\n",
      "monkroos\n",
      "monks\n",
      "mono\n",
      "monoelectra\n",
      "monographi\n",
      "monolingu\n",
      "monologu\n",
      "monom\n",
      "monomer\n",
      "monophon\n",
      "monospecif\n",
      "monot\n",
      "monro\n",
      "monster\n",
      "mont\n",
      "montariol\n",
      "montenegrin\n",
      "montenegrinsub\n",
      "montgomeri\n",
      "month\n",
      "monthli\n",
      "moondream\n",
      "moral\n",
      "mordovia\n",
      "morellato\n",
      "moreov\n",
      "morfessor\n",
      "morfeusz\n",
      "morn\n",
      "moroccan\n",
      "moroco\n",
      "morphem\n",
      "morpho\n",
      "morphog\n",
      "morpholog\n",
      "morphosyntact\n",
      "morr\n",
      "mortar\n",
      "mosei\n",
      "moss\n",
      "mossi\n",
      "mostima\n",
      "mostli\n",
      "motif\n",
      "motion\n",
      "motiv\n",
      "motorcycl\n",
      "motorist\n",
      "motorsport\n",
      "moujez\n",
      "mount\n",
      "mountain\n",
      "mous\n",
      "mouss\n",
      "moustafa\n",
      "mouth\n",
      "mova\n",
      "moveit\n",
      "movement\n",
      "movi\n",
      "movielen\n",
      "movietheat\n",
      "mowi\n",
      "moyen\n",
      "mozambican\n",
      "mozharova\n",
      "mozilla\n",
      "mp\n",
      "mpala\n",
      "mpbp\n",
      "mpep\n",
      "mpg\n",
      "mph\n",
      "mpid\n",
      "mpii\n",
      "mpnet\n",
      "mq\n",
      "mqa\n",
      "mqm\n",
      "mr\n",
      "mraahekio\n",
      "mrbeast\n",
      "mrc\n",
      "mri\n",
      "mrpc\n",
      "mrw\n",
      "mrwd\n",
      "mrwi\n",
      "mrz\n",
      "ms\n",
      "msa\n",
      "msap\n",
      "msc\n",
      "mscoco\n",
      "mse\n",
      "mslr\n",
      "msmarco\n",
      "msn\n",
      "msqg\n",
      "msra\n",
      "msrvtt\n",
      "mstz\n",
      "msvd\n",
      "mt\n",
      "mtasksourc\n",
      "mteb\n",
      "mtedx\n",
      "mtet\n",
      "mtl\n",
      "mtsampl\n",
      "mtsd\n",
      "mtvqa\n",
      "mu\n",
      "mudrock\n",
      "muennighoff\n",
      "muffin\n",
      "mug\n",
      "mugeminorum\n",
      "mujh\n",
      "mujoco\n",
      "mukesh\n",
      "muld\n",
      "mulm\n",
      "multext\n",
      "multi\n",
      "multibag\n",
      "multibook\n",
      "multichoic\n",
      "multiclass\n",
      "multicolor\n",
      "multiconer\n",
      "multicultur\n",
      "multidialect\n",
      "multidialog\n",
      "multidimension\n",
      "multidocdi\n",
      "multidocu\n",
      "multieurlex\n",
      "multifacet\n",
      "multifamili\n",
      "multifus\n",
      "multihop\n",
      "multijurisdict\n",
      "multik\n",
      "multilabel\n",
      "multilang\n",
      "multilegalpil\n",
      "multilevel\n",
      "multilin\n",
      "multilingu\n",
      "multilingualclip\n",
      "multimedia\n",
      "multimod\n",
      "multimodel\n",
      "multin\n",
      "multinerd\n",
      "multinli\n",
      "multipart\n",
      "multipl\n",
      "multireqa\n",
      "multiresolut\n",
      "multiscen\n",
      "multispeak\n",
      "multitableqa\n",
      "multitabqa\n",
      "multitask\n",
      "multitop\n",
      "multitud\n",
      "multiun\n",
      "multiword\n",
      "multiwoz\n",
      "multlingu\n",
      "mundo\n",
      "munich\n",
      "municip\n",
      "mupa\n",
      "muppet\n",
      "mur\n",
      "mura\n",
      "muratcan\n",
      "murzakhmetov\n",
      "muscl\n",
      "musculoskelet\n",
      "muse\n",
      "museum\n",
      "mushnub\n",
      "mushroom\n",
      "music\n",
      "musiccap\n",
      "musician\n",
      "musicpil\n",
      "musk\n",
      "muskv\n",
      "mustach\n",
      "mustafa\n",
      "mustapha\n",
      "mutat\n",
      "mutli\n",
      "mutlilingu\n",
      "mutual\n",
      "mutualfriend\n",
      "mutualit\n",
      "muzero\n",
      "mv\n",
      "mvp\n",
      "mvtec\n",
      "mwoz\n",
      "mwsc\n",
      "mx\n",
      "myanmar\n",
      "mydp\n",
      "mykyta\n",
      "myopathi\n",
      "myoquant\n",
      "myrtl\n",
      "mysteri\n",
      "mytwu\n",
      "myung\n",
      "myv\n",
      "na\n",
      "naab\n",
      "naacl\n",
      "naan\n",
      "nabird\n",
      "nacion\n",
      "nacl\n",
      "nadezhda\n",
      "naf\n",
      "nagra\n",
      "nagrani\n",
      "nah\n",
      "nahuatl\n",
      "naijarc\n",
      "nail\n",
      "nailbit\n",
      "naiv\n",
      "nakamura\n",
      "nal\n",
      "nale\n",
      "nam\n",
      "naman\n",
      "namespac\n",
      "namuwiki\n",
      "nan\n",
      "nanj\n",
      "nann\n",
      "nano\n",
      "napoca\n",
      "napoleon\n",
      "napoletano\n",
      "napoligrafia\n",
      "narodowi\n",
      "narr\n",
      "narrat\n",
      "narrativeqa\n",
      "narrow\n",
      "nart\n",
      "nasa\n",
      "nash\n",
      "nashvil\n",
      "natalia\n",
      "nath\n",
      "nation\n",
      "nativ\n",
      "natur\n",
      "naturalquest\n",
      "naval\n",
      "naver\n",
      "navig\n",
      "nb\n",
      "nbfi\n",
      "nc\n",
      "ncbi\n",
      "ncia\n",
      "nd\n",
      "ndan\n",
      "ndl\n",
      "neapolitan\n",
      "near\n",
      "nearl\n",
      "nearli\n",
      "nebula\n",
      "necessari\n",
      "necessarili\n",
      "neck\n",
      "nectec\n",
      "need\n",
      "neg\n",
      "negat\n",
      "neglect\n",
      "negoti\n",
      "neighbor\n",
      "nemitsua\n",
      "nemo\n",
      "nena\n",
      "nenhuma\n",
      "neno\n",
      "neo\n",
      "neochibi\n",
      "neoforman\n",
      "neomorphem\n",
      "neon\n",
      "neoval\n",
      "nepali\n",
      "nephrit\n",
      "nephriti\n",
      "neqa\n",
      "ner\n",
      "nerd\n",
      "nerel\n",
      "nergi\n",
      "nest\n",
      "net\n",
      "neteas\n",
      "netev\n",
      "netflix\n",
      "netflow\n",
      "netherland\n",
      "netid\n",
      "netlifi\n",
      "netop\n",
      "netori\n",
      "netuid\n",
      "network\n",
      "networkx\n",
      "neu\n",
      "neuclir\n",
      "neumann\n",
      "neural\n",
      "neuralshel\n",
      "neuralspac\n",
      "neurip\n",
      "neuro\n",
      "neurodiverg\n",
      "neuroimag\n",
      "neuropil\n",
      "neurosci\n",
      "neurotic\n",
      "neutral\n",
      "new\n",
      "newer\n",
      "newest\n",
      "newli\n",
      "newlin\n",
      "news\n",
      "newsam\n",
      "newser\n",
      "newsfirst\n",
      "newsgroup\n",
      "newslett\n",
      "newsm\n",
      "newspap\n",
      "newsqa\n",
      "newsroom\n",
      "newssapo\n",
      "newswir\n",
      "nexdata\n",
      "nf\n",
      "nfcorpu\n",
      "nft\n",
      "ng\n",
      "ngpea\n",
      "ngram\n",
      "ngt\n",
      "nguyen\n",
      "nhentai\n",
      "ni\n",
      "nian\n",
      "nich\n",
      "nico\n",
      "nid\n",
      "nifti\n",
      "niger\n",
      "nigerian\n",
      "night\n",
      "nightingal\n",
      "nightlight\n",
      "nightmar\n",
      "nih\n",
      "niji\n",
      "nike\n",
      "nikhilchigali\n",
      "nikolay\n",
      "nil\n",
      "ninji\n",
      "nintendo\n",
      "nip\n",
      "nisu\n",
      "niv\n",
      "nixietun\n",
      "nl\n",
      "nlabel\n",
      "nlg\n",
      "nli\n",
      "nlk\n",
      "nllb\n",
      "nlm\n",
      "nlp\n",
      "nlpc\n",
      "nlpso\n",
      "nlu\n",
      "nm\n",
      "nmsqa\n",
      "nmt\n",
      "noaa\n",
      "noah\n",
      "nob\n",
      "nobel\n",
      "noblocklist\n",
      "noclean\n",
      "nocr\n",
      "nodalida\n",
      "node\n",
      "nofollow\n",
      "nogueira\n",
      "nogueiratoward\n",
      "nois\n",
      "noisi\n",
      "noisyn\n",
      "nolang\n",
      "nom\n",
      "nombr\n",
      "nomic\n",
      "nomin\n",
      "non\n",
      "noncommerci\n",
      "nondenud\n",
      "nonetheless\n",
      "nong\n",
      "nonspeech\n",
      "noon\n",
      "nopemb\n",
      "nopgbrk\n",
      "nord\n",
      "nordic\n",
      "nordjylland\n",
      "norec\n",
      "norfolk\n",
      "norm\n",
      "normal\n",
      "normalis\n",
      "normaliz\n",
      "normalizedbodi\n",
      "norn\n",
      "norsk\n",
      "north\n",
      "northeast\n",
      "northeastern\n",
      "northern\n",
      "northwestern\n",
      "northwind\n",
      "norway\n",
      "norwegian\n",
      "norwood\n",
      "nose\n",
      "nota\n",
      "notabl\n",
      "notado\n",
      "notat\n",
      "notch\n",
      "note\n",
      "notebook\n",
      "notechat\n",
      "noteworthi\n",
      "noth\n",
      "notic\n",
      "noticia\n",
      "notion\n",
      "notmnist\n",
      "notr\n",
      "nou\n",
      "nougat\n",
      "noun\n",
      "nour\n",
      "nouveau\n",
      "nouvel\n",
      "nov\n",
      "novel\n",
      "novelai\n",
      "novelsens\n",
      "novelti\n",
      "novemb\n",
      "novinki\n",
      "nowaday\n",
      "nowiki\n",
      "nowledg\n",
      "nox\n",
      "np\n",
      "npc\n",
      "npee\n",
      "npi\n",
      "npig\n",
      "nplus\n",
      "npr\n",
      "npsc\n",
      "nq\n",
      "nqa\n",
      "nr\n",
      "nrk\n",
      "nsc\n",
      "nsd\n",
      "nsdsr\n",
      "nsf\n",
      "nsfw\n",
      "nsme\n",
      "nsql\n",
      "nst\n",
      "nstextsql\n",
      "nsynth\n",
      "ntcir\n",
      "ntemleri\n",
      "ntg\n",
      "ntica\n",
      "ntire\n",
      "ntr\n",
      "ntu\n",
      "ntweet\n",
      "nu\n",
      "nuanc\n",
      "nuclei\n",
      "nucleotid\n",
      "nude\n",
      "nuex\n",
      "null\n",
      "num\n",
      "numa\n",
      "number\n",
      "numberdtyp\n",
      "numer\n",
      "numerai\n",
      "numersens\n",
      "numpi\n",
      "nung\n",
      "nuno\n",
      "nuo\n",
      "nurs\n",
      "nurseri\n",
      "nusantara\n",
      "nusax\n",
      "nuscen\n",
      "nut\n",
      "nutrient\n",
      "nutshel\n",
      "nvidia\n",
      "nwpu\n",
      "nwu\n",
      "nxi\n",
      "nya\n",
      "nyameri\n",
      "nyanko\n",
      "nyannyan\n",
      "nynorsk\n",
      "nyu\n",
      "nza\n",
      "oa\n",
      "oakink\n",
      "oamento\n",
      "oaoqoqkaksk\n",
      "oasst\n",
      "oasum\n",
      "ob\n",
      "obama\n",
      "obelix\n",
      "oberta\n",
      "obfusc\n",
      "obimnijih\n",
      "objavers\n",
      "object\n",
      "objectnet\n",
      "objeto\n",
      "obscen\n",
      "obscura\n",
      "observ\n",
      "observatori\n",
      "obstacl\n",
      "obtain\n",
      "obtatin\n",
      "oc\n",
      "occasion\n",
      "occlus\n",
      "occup\n",
      "occupi\n",
      "occur\n",
      "occurr\n",
      "ocean\n",
      "oceanograph\n",
      "ocer\n",
      "och\n",
      "ochi\n",
      "ocotob\n",
      "ocr\n",
      "oct\n",
      "octob\n",
      "octscen\n",
      "ocw\n",
      "od\n",
      "oda\n",
      "odabranu\n",
      "odaka\n",
      "odba\n",
      "odc\n",
      "oddish\n",
      "odditi\n",
      "odesta\n",
      "odex\n",
      "odgovora\n",
      "odgovori\n",
      "odia\n",
      "odin\n",
      "odissi\n",
      "odomet\n",
      "odor\n",
      "oecd\n",
      "offcombr\n",
      "offend\n",
      "offens\n",
      "offensev\n",
      "offer\n",
      "offic\n",
      "offici\n",
      "officiel\n",
      "offlin\n",
      "og\n",
      "oh\n",
      "ok\n",
      "ol\n",
      "olan\n",
      "old\n",
      "oleksa\n",
      "oliv\n",
      "oliveira\n",
      "olm\n",
      "olu\n",
      "olup\n",
      "olvi\n",
      "olymp\n",
      "omiss\n",
      "omogu\n",
      "onc\n",
      "ongo\n",
      "onima\n",
      "onli\n",
      "onlin\n",
      "onset\n",
      "ontario\n",
      "ontolog\n",
      "ontonot\n",
      "oogiri\n",
      "op\n",
      "opcion\n",
      "open\n",
      "openai\n",
      "openapi\n",
      "openbmb\n",
      "openbookqa\n",
      "opencodeinterpret\n",
      "opencpop\n",
      "openend\n",
      "openherm\n",
      "openhermesprefer\n",
      "openimag\n",
      "openlegaldata\n",
      "openli\n",
      "openllmturkishleaderboard\n",
      "openmathinstruct\n",
      "openml\n",
      "openorca\n",
      "openpos\n",
      "openqa\n",
      "opensea\n",
      "openslr\n",
      "opensubtitl\n",
      "opentom\n",
      "openvivqa\n",
      "openwebtext\n",
      "openworld\n",
      "oper\n",
      "opinion\n",
      "opl\n",
      "opportun\n",
      "oppos\n",
      "opposit\n",
      "opt\n",
      "optdigit\n",
      "optic\n",
      "optim\n",
      "optimis\n",
      "option\n",
      "opu\n",
      "opul\n",
      "opus\n",
      "oracl\n",
      "oral\n",
      "orang\n",
      "orangesum\n",
      "orca\n",
      "ord\n",
      "order\n",
      "ordin\n",
      "oregon\n",
      "org\n",
      "organ\n",
      "organis\n",
      "orgin\n",
      "ori\n",
      "orient\n",
      "origin\n",
      "origun\n",
      "oriya\n",
      "ornament\n",
      "orpo\n",
      "orthograph\n",
      "os\n",
      "oscar\n",
      "osteochondrosi\n",
      "osteophyt\n",
      "ostvarivanj\n",
      "oswaldo\n",
      "ot\n",
      "otherwis\n",
      "otra\n",
      "otsl\n",
      "ounass\n",
      "outcom\n",
      "outdoor\n",
      "outlet\n",
      "outlier\n",
      "outlin\n",
      "outperform\n",
      "output\n",
      "outsid\n",
      "ouzjz\n",
      "ovaj\n",
      "oveja\n",
      "overal\n",
      "overarch\n",
      "overcom\n",
      "overflow\n",
      "overlap\n",
      "overtak\n",
      "overview\n",
      "ovog\n",
      "ovu\n",
      "owe\n",
      "owl\n",
      "owner\n",
      "ownership\n",
      "owski\n",
      "oxford\n",
      "oz\n",
      "ozon\n",
      "pa\n",
      "pacakg\n",
      "pace\n",
      "pacif\n",
      "packag\n",
      "packet\n",
      "pad\n",
      "page\n",
      "pageblock\n",
      "pagina\n",
      "pagragraph\n",
      "paid\n",
      "pain\n",
      "paint\n",
      "pair\n",
      "pairrm\n",
      "pairwis\n",
      "paldea\n",
      "palestin\n",
      "palla\n",
      "pallet\n",
      "palm\n",
      "palmer\n",
      "pan\n",
      "panayotov\n",
      "panda\n",
      "pandem\n",
      "pandit\n",
      "panel\n",
      "panoram\n",
      "panorama\n",
      "pant\n",
      "panta\n",
      "paper\n",
      "paperswithcod\n",
      "paq\n",
      "par\n",
      "para\n",
      "paracrawl\n",
      "parad\n",
      "paradigm\n",
      "paragraph\n",
      "parallel\n",
      "paramet\n",
      "paraphras\n",
      "paraphraseminingevalu\n",
      "paraphraserc\n",
      "parasect\n",
      "parasit\n",
      "parcc\n",
      "parent\n",
      "pari\n",
      "pariti\n",
      "park\n",
      "parlamentopt\n",
      "parliament\n",
      "parliamentari\n",
      "parmisano\n",
      "parquet\n",
      "pars\n",
      "parse\n",
      "parser\n",
      "parsynth\n",
      "parsynthocr\n",
      "parti\n",
      "partial\n",
      "particip\n",
      "particl\n",
      "particular\n",
      "particularli\n",
      "partit\n",
      "partli\n",
      "partner\n",
      "partnership\n",
      "pascal\n",
      "pass\n",
      "passag\n",
      "passiv\n",
      "passport\n",
      "password\n",
      "past\n",
      "patat\n",
      "patch\n",
      "patent\n",
      "patfig\n",
      "path\n",
      "patholog\n",
      "pathvqa\n",
      "pathway\n",
      "patient\n",
      "patrick\n",
      "pattern\n",
      "patternnet\n",
      "paul\n",
      "paus\n",
      "pav\n",
      "pave\n",
      "paw\n",
      "pawn\n",
      "payload\n",
      "payment\n",
      "pbr\n",
      "pc\n",
      "pca\n",
      "pcap\n",
      "pcb\n",
      "pcm\n",
      "pd\n",
      "pdf\n",
      "pdfa\n",
      "peanut\n",
      "pedestrian\n",
      "pedro\n",
      "peer\n",
      "peewe\n",
      "peft\n",
      "pegasu\n",
      "peixo\n",
      "pen\n",
      "penal\n",
      "penanc\n",
      "penetr\n",
      "peng\n",
      "penguin\n",
      "penn\n",
      "pension\n",
      "pentaton\n",
      "peopl\n",
      "peopledairy\n",
      "perceiv\n",
      "percentag\n",
      "percept\n",
      "perez\n",
      "perfect\n",
      "perform\n",
      "performansi\n",
      "performd\n",
      "perfum\n",
      "period\n",
      "perk\n",
      "permiss\n",
      "permit\n",
      "pero\n",
      "perplex\n",
      "persian\n",
      "persist\n",
      "person\n",
      "persona\n",
      "personsegsmal\n",
      "perspect\n",
      "persuad\n",
      "pertain\n",
      "perturb\n",
      "peso\n",
      "pest\n",
      "pet\n",
      "peter\n",
      "petfind\n",
      "petit\n",
      "petra\n",
      "petrov\n",
      "pexel\n",
      "pfeiffer\n",
      "pfpnft\n",
      "phage\n",
      "phantom\n",
      "pharmacolog\n",
      "pharmacon\n",
      "phase\n",
      "phd\n",
      "phenomena\n",
      "phi\n",
      "philharmon\n",
      "philip\n",
      "philosophi\n",
      "phish\n",
      "phiyodr\n",
      "phone\n",
      "phonem\n",
      "phonet\n",
      "phonetician\n",
      "phonetis\n",
      "photo\n",
      "photograph\n",
      "photographi\n",
      "photoid\n",
      "photorealist\n",
      "photoscan\n",
      "phototest\n",
      "phrase\n",
      "physic\n",
      "physiolog\n",
      "piaf\n",
      "piana\n",
      "piano\n",
      "pic\n",
      "pick\n",
      "picklebotk\n",
      "pictur\n",
      "pidgin\n",
      "pie\n",
      "piec\n",
      "pierc\n",
      "pierr\n",
      "pig\n",
      "pigment\n",
      "pii\n",
      "pil\n",
      "pile\n",
      "pill\n",
      "pillar\n",
      "pilot\n",
      "pima\n",
      "ping\n",
      "pink\n",
      "pinyin\n",
      "pioneer\n",
      "pip\n",
      "pipe\n",
      "pipelin\n",
      "piqa\n",
      "pisicina\n",
      "pitch\n",
      "pitcher\n",
      "pittsburgh\n",
      "pivot\n",
      "pixel\n",
      "pixiv\n",
      "pku\n",
      "pl\n",
      "place\n",
      "plain\n",
      "plan\n",
      "plane\n",
      "plant\n",
      "plantat\n",
      "plantl\n",
      "plastic\n",
      "plate\n",
      "platform\n",
      "platinum\n",
      "platpyu\n",
      "plattner\n",
      "platypu\n",
      "plausibl\n",
      "play\n",
      "player\n",
      "playground\n",
      "playlist\n",
      "pleas\n",
      "plenari\n",
      "plethora\n",
      "plo\n",
      "plod\n",
      "plot\n",
      "plotcod\n",
      "plotqa\n",
      "plp\n",
      "plt\n",
      "plu\n",
      "pluck\n",
      "plugin\n",
      "pluma\n",
      "plural\n",
      "pm\n",
      "pmc\n",
      "pmid\n",
      "pneumonia\n",
      "png\n",
      "po\n",
      "podataka\n",
      "podcast\n",
      "poem\n",
      "poet\n",
      "poetri\n",
      "point\n",
      "pointi\n",
      "poison\n",
      "poj\n",
      "pok\n",
      "pokedex\n",
      "pokemon\n",
      "poker\n",
      "pol\n",
      "poland\n",
      "polar\n",
      "polev\n",
      "polici\n",
      "policymak\n",
      "polish\n",
      "poliskammar\n",
      "polit\n",
      "politi\n",
      "politician\n",
      "politifact\n",
      "pollut\n",
      "polyglot\n",
      "polygon\n",
      "polymorph\n",
      "polynewsparallel\n",
      "pomo\n",
      "pon\n",
      "ponti\n",
      "ponytail\n",
      "pool\n",
      "pop\n",
      "popul\n",
      "populac\n",
      "popular\n",
      "por\n",
      "port\n",
      "portal\n",
      "portamento\n",
      "porter\n",
      "portion\n",
      "portrait\n",
      "portray\n",
      "portug\n",
      "portugu\n",
      "portugues\n",
      "porygon\n",
      "pose\n",
      "posit\n",
      "possibl\n",
      "post\n",
      "postglaci\n",
      "potato\n",
      "potenti\n",
      "pothol\n",
      "pour\n",
      "pourmand\n",
      "povey\n",
      "power\n",
      "pozemka\n",
      "pp\n",
      "ppav\n",
      "pr\n",
      "prabin\n",
      "prachathai\n",
      "practic\n",
      "practition\n",
      "prada\n",
      "pradesh\n",
      "pragmat\n",
      "pramanix\n",
      "pre\n",
      "prebuilt\n",
      "preced\n",
      "precis\n",
      "precomput\n",
      "predecessor\n",
      "predic\n",
      "predict\n",
      "predomin\n",
      "predominantli\n",
      "predstavlja\n",
      "prefer\n",
      "prefix\n",
      "premier\n",
      "premis\n",
      "premium\n",
      "prepar\n",
      "preprint\n",
      "preprocess\n",
      "presenc\n",
      "present\n",
      "preserv\n",
      "presid\n",
      "press\n",
      "presser\n",
      "prestig\n",
      "prestigi\n",
      "presum\n",
      "pretrain\n",
      "pretti\n",
      "preval\n",
      "prevent\n",
      "preview\n",
      "previou\n",
      "previous\n",
      "pribli\n",
      "price\n",
      "primari\n",
      "primarili\n",
      "primaryclass\n",
      "prime\n",
      "primer\n",
      "primerdata\n",
      "primit\n",
      "princ\n",
      "princeton\n",
      "principl\n",
      "print\n",
      "printout\n",
      "prior\n",
      "prioriti\n",
      "privaci\n",
      "privat\n",
      "privi\n",
      "prize\n",
      "pro\n",
      "probabilist\n",
      "probabl\n",
      "probe\n",
      "problem\n",
      "problema\n",
      "problemat\n",
      "proc\n",
      "proce\n",
      "procedur\n",
      "proceed\n",
      "process\n",
      "procur\n",
      "produc\n",
      "product\n",
      "profan\n",
      "profess\n",
      "profession\n",
      "professor\n",
      "profici\n",
      "profil\n",
      "profit\n",
      "profound\n",
      "program\n",
      "programm\n",
      "progress\n",
      "project\n",
      "projector\n",
      "projekt\n",
      "promin\n",
      "promis\n",
      "promot\n",
      "prompt\n",
      "pronoun\n",
      "pronounc\n",
      "pronunci\n",
      "propel\n",
      "proper\n",
      "properli\n",
      "properti\n",
      "proport\n",
      "propos\n",
      "propri\n",
      "proprietari\n",
      "propublica\n",
      "prosocialdialog\n",
      "prosod\n",
      "prosodi\n",
      "protect\n",
      "protein\n",
      "protocol\n",
      "prototyp\n",
      "protrus\n",
      "prove\n",
      "proven\n",
      "provenc\n",
      "provid\n",
      "provinc\n",
      "proyect\n",
      "proyecto\n",
      "proza\n",
      "prune\n",
      "ps\n",
      "psd\n",
      "pseudo\n",
      "pseudolabel\n",
      "psf\n",
      "psycholinguist\n",
      "psycholog\n",
      "pszemraj\n",
      "pt\n",
      "ptb\n",
      "pteas\n",
      "pth\n",
      "ptilopsi\n",
      "ptrn\n",
      "ptywi\n",
      "pubhealth\n",
      "publaynet\n",
      "public\n",
      "publicli\n",
      "publiqu\n",
      "publish\n",
      "pubm\n",
      "pubmedcaus\n",
      "pubmedqa\n",
      "pubtabl\n",
      "pubtabnet\n",
      "puesta\n",
      "puisi\n",
      "pull\n",
      "pum\n",
      "pump\n",
      "punctuat\n",
      "punjabi\n",
      "pupil\n",
      "purchas\n",
      "pure\n",
      "pureforest\n",
      "purpl\n",
      "purpos\n",
      "push\n",
      "pushshift\n",
      "puta\n",
      "puzzl\n",
      "px\n",
      "py\n",
      "pynich\n",
      "pypi\n",
      "pyplot\n",
      "pyterri\n",
      "pythainlp\n",
      "python\n",
      "pytorch\n",
      "qa\n",
      "qald\n",
      "qasc\n",
      "qatar\n",
      "qatari\n",
      "qcri\n",
      "qdobr\n",
      "qed\n",
      "qg\n",
      "qin\n",
      "qlnqi\n",
      "qnli\n",
      "qq\n",
      "qqp\n",
      "qrel\n",
      "qtsumm\n",
      "qu\n",
      "quac\n",
      "quad\n",
      "qualifi\n",
      "qualit\n",
      "qualiti\n",
      "quantifi\n",
      "quantit\n",
      "quantiti\n",
      "quantiz\n",
      "quarantin\n",
      "quartz\n",
      "que\n",
      "quechua\n",
      "queri\n",
      "query\n",
      "question\n",
      "quick\n",
      "quickli\n",
      "quiet\n",
      "quit\n",
      "quiz\n",
      "quora\n",
      "quot\n",
      "quran\n",
      "qwen\n",
      "qxv\n",
      "rabbit\n",
      "rac\n",
      "raccoon\n",
      "race\n",
      "racecar\n",
      "rad\n",
      "radar\n",
      "radio\n",
      "radiolog\n",
      "radu\n",
      "rae\n",
      "rag\n",
      "raheja\n",
      "rail\n",
      "railroad\n",
      "rais\n",
      "rajasthan\n",
      "rajasthani\n",
      "rajpurkar\n",
      "rakuten\n",
      "ral\n",
      "ram\n",
      "rana\n",
      "random\n",
      "randomli\n",
      "rang\n",
      "range\n",
      "rangeindex\n",
      "rank\n",
      "rapid\n",
      "rapidli\n",
      "rar\n",
      "rare\n",
      "raster\n",
      "rasterio\n",
      "rat\n",
      "rate\n",
      "rater\n",
      "ratio\n",
      "ration\n",
      "rational\n",
      "ravdess\n",
      "ravnursson\n",
      "raw\n",
      "ray\n",
      "rbmt\n",
      "rc\n",
      "rcn\n",
      "rct\n",
      "rd\n",
      "rdecom\n",
      "rdf\n",
      "rdkit\n",
      "reach\n",
      "reaction\n",
      "read\n",
      "readabl\n",
      "reader\n",
      "readi\n",
      "readili\n",
      "readm\n",
      "readmiss\n",
      "readmit\n",
      "real\n",
      "realbooru\n",
      "realifak\n",
      "realis\n",
      "realism\n",
      "realist\n",
      "realiti\n",
      "realiz\n",
      "realli\n",
      "realm\n",
      "realnewslik\n",
      "realworldqa\n",
      "reannot\n",
      "rearrang\n",
      "reason\n",
      "rebel\n",
      "recal\n",
      "recast\n",
      "receipt\n",
      "receiv\n",
      "recent\n",
      "recherch\n",
      "recid\n",
      "recidiv\n",
      "recidivid\n",
      "reciev\n",
      "recip\n",
      "recit\n",
      "recod\n",
      "recogn\n",
      "recognis\n",
      "recognit\n",
      "recolect\n",
      "recommend\n",
      "recon\n",
      "reconstruct\n",
      "record\n",
      "recreat\n",
      "recruit\n",
      "rectifi\n",
      "recurr\n",
      "recycl\n",
      "red\n",
      "redcap\n",
      "reddi\n",
      "reddit\n",
      "redefin\n",
      "redial\n",
      "redistribut\n",
      "redpajama\n",
      "reduc\n",
      "reed\n",
      "ref\n",
      "refer\n",
      "refere\n",
      "referenc\n",
      "refexp\n",
      "refin\n",
      "refinedweb\n",
      "reflect\n",
      "reflex\n",
      "reformat\n",
      "refug\n",
      "refus\n",
      "refut\n",
      "reg\n",
      "regard\n",
      "regardless\n",
      "regex\n",
      "regga\n",
      "region\n",
      "regist\n",
      "regress\n",
      "regul\n",
      "regular\n",
      "regularli\n",
      "regulatori\n",
      "reinforc\n",
      "reject\n",
      "rel\n",
      "relat\n",
      "related\n",
      "relationextract\n",
      "relationship\n",
      "releas\n",
      "relev\n",
      "reli\n",
      "reliabl\n",
      "relief\n",
      "religi\n",
      "religion\n",
      "remain\n",
      "remark\n",
      "remast\n",
      "remedi\n",
      "rememb\n",
      "remilio\n",
      "remot\n",
      "remov\n",
      "renaiss\n",
      "renam\n",
      "render\n",
      "renown\n",
      "renum\n",
      "repeat\n",
      "repeatedli\n",
      "repetit\n",
      "rephras\n",
      "replac\n",
      "replay\n",
      "repli\n",
      "replic\n",
      "replica\n",
      "repo\n",
      "report\n",
      "repositori\n",
      "repres\n",
      "represent\n",
      "reproduc\n",
      "reproduct\n",
      "repubblica\n",
      "republ\n",
      "reput\n",
      "request\n",
      "requir\n",
      "rerank\n",
      "resampl\n",
      "resd\n",
      "research\n",
      "resel\n",
      "resembl\n",
      "reserv\n",
      "residu\n",
      "resiz\n",
      "resolut\n",
      "resolv\n",
      "reson\n",
      "resourc\n",
      "respect\n",
      "respond\n",
      "respons\n",
      "rest\n",
      "restaur\n",
      "restor\n",
      "restrict\n",
      "restructur\n",
      "result\n",
      "retail\n",
      "retain\n",
      "retrait\n",
      "retriev\n",
      "retrievalgenr\n",
      "return\n",
      "reupload\n",
      "reus\n",
      "reusabl\n",
      "rev\n",
      "reveal\n",
      "revenu\n",
      "review\n",
      "revis\n",
      "revisit\n",
      "revizij\n",
      "revolution\n",
      "revolv\n",
      "reward\n",
      "rewrit\n",
      "rf\n",
      "rffa\n",
      "rgb\n",
      "rgba\n",
      "rhetor\n",
      "rheumatolog\n",
      "rhizoctonia\n",
      "rhythm\n",
      "rial\n",
      "ribbon\n",
      "rich\n",
      "riddl\n",
      "ride\n",
      "rieur\n",
      "riffus\n",
      "right\n",
      "rigid\n",
      "rigor\n",
      "ring\n",
      "rio\n",
      "ripe\n",
      "risc\n",
      "riscbac\n",
      "rise\n",
      "risk\n",
      "ritter\n",
      "rival\n",
      "river\n",
      "rk\n",
      "rkiy\n",
      "rl\n",
      "rlaif\n",
      "rlhf\n",
      "rm\n",
      "rn\n",
      "ro\n",
      "road\n",
      "roadway\n",
      "robert\n",
      "roberta\n",
      "robin\n",
      "roboflow\n",
      "robomast\n",
      "robot\n",
      "robust\n",
      "robustli\n",
      "rock\n",
      "rococo\n",
      "rodrigo\n",
      "roland\n",
      "role\n",
      "roleplay\n",
      "roman\n",
      "romania\n",
      "romanian\n",
      "romanis\n",
      "ronithf\n",
      "room\n",
      "root\n",
      "rope\n",
      "rosa\n",
      "rose\n",
      "rosmonti\n",
      "ross\n",
      "rot\n",
      "rotat\n",
      "roth\n",
      "roug\n",
      "rough\n",
      "roughli\n",
      "round\n",
      "rout\n",
      "row\n",
      "rp\n",
      "rqq\n",
      "rr\n",
      "rsna\n",
      "rssi\n",
      "rsuf\n",
      "rt\n",
      "ru\n",
      "rudevic\n",
      "rudimentari\n",
      "rue\n",
      "rule\n",
      "rumour\n",
      "rumt\n",
      "run\n",
      "runn\n",
      "runner\n",
      "rural\n",
      "rurebu\n",
      "russia\n",
      "russian\n",
      "rusynpannonianpur\n",
      "ruter\n",
      "ruwi\n",
      "rvc\n",
      "rvl\n",
      "ryan\n",
      "ryerson\n",
      "sa\n",
      "saad\n",
      "sabharw\n",
      "sacrif\n",
      "sad\n",
      "saf\n",
      "safe\n",
      "safeti\n",
      "saga\n",
      "sahil\n",
      "said\n",
      "saileach\n",
      "saint\n",
      "sake\n",
      "sakura\n",
      "sale\n",
      "salesforc\n",
      "salient\n",
      "salud\n",
      "sam\n",
      "sampl\n",
      "samr\n",
      "samromur\n",
      "samsum\n",
      "san\n",
      "sang\n",
      "sangraha\n",
      "sanidad\n",
      "saniti\n",
      "sankaku\n",
      "sankshipt\n",
      "sanna\n",
      "sanskrit\n",
      "sant\n",
      "santa\n",
      "santo\n",
      "santorini\n",
      "sanzhar\n",
      "saok\n",
      "sapien\n",
      "sar\n",
      "sarcasm\n",
      "sarcast\n",
      "sarfish\n",
      "sargishunanyan\n",
      "sarhon\n",
      "saria\n",
      "sartasipk\n",
      "sat\n",
      "satellit\n",
      "satin\n",
      "satisfact\n",
      "satisfactori\n",
      "satisfi\n",
      "satoru\n",
      "sattriya\n",
      "saudi\n",
      "savag\n",
      "savanna\n",
      "savant\n",
      "save\n",
      "saveri\n",
      "saveryquest\n",
      "savvi\n",
      "saw\n",
      "saxon\n",
      "say\n",
      "sayoko\n",
      "sbb\n",
      "sber\n",
      "sberbank\n",
      "sberdevic\n",
      "sberquad\n",
      "sbert\n",
      "sbintuit\n",
      "sbu\n",
      "sc\n",
      "scaffold\n",
      "scaheff\n",
      "scalabl\n",
      "scalar\n",
      "scale\n",
      "scalp\n",
      "scam\n",
      "scammer\n",
      "scan\n",
      "scandireddit\n",
      "scandiredditfilt\n",
      "scandiwiki\n",
      "scanner\n",
      "scape\n",
      "scar\n",
      "scarc\n",
      "scarciti\n",
      "scarfac\n",
      "scat\n",
      "scatter\n",
      "scattershot\n",
      "scaveng\n",
      "scb\n",
      "sccale\n",
      "scenario\n",
      "scenc\n",
      "scene\n",
      "sceneparse\n",
      "sceneri\n",
      "scenesens\n",
      "scenic\n",
      "schaeffer\n",
      "schel\n",
      "schem\n",
      "schema\n",
      "scheme\n",
      "schibst\n",
      "schizophren\n",
      "schmid\n",
      "schmorl\n",
      "schoenick\n",
      "scholar\n",
      "scholarli\n",
      "school\n",
      "schuster\n",
      "schwabach\n",
      "schwarz\n",
      "schwenk\n",
      "sci\n",
      "sciarg\n",
      "scico\n",
      "scidoc\n",
      "scidtb\n",
      "scielo\n",
      "scienc\n",
      "sciencedb\n",
      "sciencedirect\n",
      "sciencei\n",
      "scienceqa\n",
      "scientif\n",
      "scientist\n",
      "scifact\n",
      "scikit\n",
      "sciq\n",
      "sciqa\n",
      "scitldr\n",
      "sclerosi\n",
      "scmscx\n",
      "scnclab\n",
      "scoliosi\n",
      "scope\n",
      "score\n",
      "scotland\n",
      "scott\n",
      "scottish\n",
      "scourc\n",
      "scpt\n",
      "scrabblegan\n",
      "scrap\n",
      "scrape\n",
      "scraper\n",
      "scrapper\n",
      "scratch\n",
      "scream\n",
      "screen\n",
      "screenshot\n",
      "screenspot\n",
      "screenton\n",
      "script\n",
      "scription\n",
      "scroll\n",
      "scrub\n",
      "scryfal\n",
      "sd\n",
      "sdh\n",
      "sdk\n",
      "sdkf\n",
      "sdoh\n",
      "sdu\n",
      "sdx\n",
      "sdxl\n",
      "se\n",
      "sea\n",
      "seadra\n",
      "seak\n",
      "seal\n",
      "seamless\n",
      "seamlessli\n",
      "search\n",
      "searchqa\n",
      "season\n",
      "seat\n",
      "sebai\n",
      "sebastian\n",
      "sec\n",
      "second\n",
      "secondair\n",
      "secondari\n",
      "secqa\n",
      "section\n",
      "sector\n",
      "secular\n",
      "secur\n",
      "sedimentari\n",
      "seed\n",
      "seek\n",
      "seen\n",
      "segbroeck\n",
      "segment\n",
      "segmentation\n",
      "segmonto\n",
      "segnet\n",
      "segundo\n",
      "seguro\n",
      "seifuku\n",
      "seismic\n",
      "seld\n",
      "select\n",
      "selekciju\n",
      "selenium\n",
      "self\n",
      "selfi\n",
      "selfless\n",
      "selfrc\n",
      "sell\n",
      "seller\n",
      "sem\n",
      "semant\n",
      "semenov\n",
      "semeru\n",
      "semev\n",
      "semeval\n",
      "semi\n",
      "semisold\n",
      "semo\n",
      "sempars\n",
      "semrel\n",
      "send\n",
      "sendid\n",
      "senior\n",
      "sennheis\n",
      "sens\n",
      "sensem\n",
      "sensenc\n",
      "sensit\n",
      "sensor\n",
      "sensori\n",
      "sent\n",
      "sentenc\n",
      "sentence\n",
      "sentencehood\n",
      "sentencetransform\n",
      "sentim\n",
      "sentiment\n",
      "sentinel\n",
      "sentitaglish\n",
      "seo\n",
      "seongyun\n",
      "sep\n",
      "separ\n",
      "sepedi\n",
      "seper\n",
      "sephard\n",
      "sept\n",
      "septemb\n",
      "sepuluh\n",
      "seqseq\n",
      "sequenc\n",
      "sequenti\n",
      "ser\n",
      "serbian\n",
      "sergeant\n",
      "sergey\n",
      "sergeyviev\n",
      "seri\n",
      "serial\n",
      "seric\n",
      "seriou\n",
      "serp\n",
      "serr\n",
      "serra\n",
      "sertkan\n",
      "serv\n",
      "servant\n",
      "server\n",
      "servic\n",
      "seshadri\n",
      "session\n",
      "set\n",
      "seti\n",
      "setiawan\n",
      "setosa\n",
      "setswana\n",
      "setup\n",
      "seungjun\n",
      "sevanskelighed\n",
      "seven\n",
      "seventeen\n",
      "seventh\n",
      "seventi\n",
      "sever\n",
      "sex\n",
      "sexist\n",
      "sexual\n",
      "sey\n",
      "sf\n",
      "sft\n",
      "sfw\n",
      "sgd\n",
      "sgdd\n",
      "sgml\n",
      "sh\n",
      "sha\n",
      "shabdkosh\n",
      "shad\n",
      "shade\n",
      "shadow\n",
      "shadr\n",
      "shahnameh\n",
      "shahnegar\n",
      "shaina\n",
      "shakirov\n",
      "shall\n",
      "shallow\n",
      "shalumov\n",
      "shalumovhero\n",
      "shalumovmevak\n",
      "shamar\n",
      "shanghai\n",
      "shanghua\n",
      "shanghuayin\n",
      "shanxi\n",
      "shao\n",
      "shaohua\n",
      "shaoteng\n",
      "shap\n",
      "shape\n",
      "sharath\n",
      "sharc\n",
      "sharcmodifi\n",
      "shard\n",
      "share\n",
      "shareabl\n",
      "sharealik\n",
      "sharegpt\n",
      "sharegptkk\n",
      "sharegptv\n",
      "sharif\n",
      "shark\n",
      "sharma\n",
      "sharp\n",
      "shaw\n",
      "shawn\n",
      "shawt\n",
      "shay\n",
      "shed\n",
      "sheep\n",
      "sheepdog\n",
      "sheer\n",
      "sheet\n",
      "sheila\n",
      "shein\n",
      "shelf\n",
      "shell\n",
      "shellder\n",
      "shelter\n",
      "shemo\n",
      "shen\n",
      "shengyang\n",
      "shi\n",
      "shield\n",
      "shift\n",
      "shih\n",
      "shilova\n",
      "shimmer\n",
      "shinbo\n",
      "shine\n",
      "shinji\n",
      "ship\n",
      "shipibo\n",
      "shirayuki\n",
      "shiroko\n",
      "shironaam\n",
      "shirt\n",
      "shising\n",
      "shiv\n",
      "shivam\n",
      "shoe\n",
      "shona\n",
      "shoot\n",
      "shop\n",
      "shoplift\n",
      "shopper\n",
      "shore\n",
      "shorelin\n",
      "short\n",
      "shortcom\n",
      "shorten\n",
      "shorter\n",
      "shortest\n",
      "shot\n",
      "shotstori\n",
      "shoukanlab\n",
      "shoulder\n",
      "shouldn\n",
      "showcas\n",
      "shown\n",
      "shreya\n",
      "shri\n",
      "shrimad\n",
      "shripad\n",
      "shruti\n",
      "shrutilipi\n",
      "shuailong\n",
      "shucheng\n",
      "shuffl\n",
      "shuhang\n",
      "shukla\n",
      "shuklafloco\n",
      "shukotoku\n",
      "shumpei\n",
      "shut\n",
      "shuttl\n",
      "si\n",
      "siak\n",
      "siavava\n",
      "sib\n",
      "siberian\n",
      "sic\n",
      "sica\n",
      "sichuan\n",
      "sick\n",
      "sickr\n",
      "sidd\n",
      "siddharth\n",
      "sidelin\n",
      "sidelock\n",
      "sideroca\n",
      "sidewalk\n",
      "sieg\n",
      "siev\n",
      "siftm\n",
      "sight\n",
      "sign\n",
      "signal\n",
      "signatur\n",
      "signific\n",
      "significantli\n",
      "siji\n",
      "sika\n",
      "silatu\n",
      "silenc\n",
      "silencio\n",
      "sileo\n",
      "sileod\n",
      "sileotasksourc\n",
      "silicon\n",
      "sill\n",
      "silli\n",
      "silva\n",
      "silvana\n",
      "silver\n",
      "silverash\n",
      "sim\n",
      "simcs\n",
      "similar\n",
      "similaridad\n",
      "similarli\n",
      "simliarti\n",
      "simo\n",
      "simpel\n",
      "simpitiki\n",
      "simpl\n",
      "simpleai\n",
      "simplepil\n",
      "simplequest\n",
      "simpler\n",
      "simplewiki\n",
      "simpli\n",
      "simplif\n",
      "simplifi\n",
      "simpson\n",
      "simsamu\n",
      "simul\n",
      "simulacra\n",
      "simulacraunsupervis\n",
      "simular\n",
      "sin\n",
      "sinc\n",
      "sinclair\n",
      "sincnet\n",
      "sindonew\n",
      "sing\n",
      "singapor\n",
      "singer\n",
      "singh\n",
      "singl\n",
      "singleton\n",
      "singlish\n",
      "singular\n",
      "sinha\n",
      "sinhagener\n",
      "sinhala\n",
      "sinji\n",
      "sint\n",
      "sinu\n",
      "sio\n",
      "sipiran\n",
      "siqa\n",
      "siren\n",
      "siri\n",
      "sister\n",
      "sit\n",
      "site\n",
      "siteleri\n",
      "sitelerinden\n",
      "sitesinin\n",
      "situ\n",
      "situat\n",
      "siva\n",
      "size\n",
      "sizeabl\n",
      "sizikova\n",
      "sk\n",
      "skadi\n",
      "skateboard\n",
      "sketch\n",
      "skew\n",
      "skginstruct\n",
      "ski\n",
      "skill\n",
      "skillgo\n",
      "skin\n",
      "skip\n",
      "skipgram\n",
      "skirealist\n",
      "skirt\n",
      "skjeldrum\n",
      "skladu\n",
      "skolegpt\n",
      "skull\n",
      "skupa\n",
      "skupu\n",
      "sky\n",
      "skyfir\n",
      "skypil\n",
      "skyscen\n",
      "slake\n",
      "slang\n",
      "slant\n",
      "slate\n",
      "slay\n",
      "slc\n",
      "sleep\n",
      "slfk\n",
      "sli\n",
      "slice\n",
      "slick\n",
      "slide\n",
      "slight\n",
      "slightli\n",
      "slimopenorca\n",
      "slimorca\n",
      "slimpajama\n",
      "slither\n",
      "slm\n",
      "sloie\n",
      "slone\n",
      "slope\n",
      "slot\n",
      "slovak\n",
      "slovakia\n",
      "sloven\n",
      "slovenian\n",
      "slow\n",
      "slowbro\n",
      "slowli\n",
      "slowlori\n",
      "slpl\n",
      "slr\n",
      "slt\n",
      "slu\n",
      "slur\n",
      "sm\n",
      "small\n",
      "smaller\n",
      "smalllin\n",
      "smart\n",
      "smartdata\n",
      "smartphon\n",
      "smc\n",
      "smell\n",
      "smet\n",
      "smg\n",
      "smile\n",
      "smith\n",
      "smithsonian\n",
      "smiyata\n",
      "smock\n",
      "smoke\n",
      "smol\n",
      "smooth\n",
      "smt\n",
      "sn\n",
      "sna\n",
      "snack\n",
      "snake\n",
      "snap\n",
      "snappi\n",
      "snapshot\n",
      "sneez\n",
      "sniafas\n",
      "sning\n",
      "sninger\n",
      "snip\n",
      "snippet\n",
      "snl\n",
      "snli\n",
      "snoopi\n",
      "snorkel\n",
      "snow\n",
      "soc\n",
      "soccer\n",
      "socher\n",
      "sochx\n",
      "social\n",
      "socialcod\n",
      "socialiqa\n",
      "societ\n",
      "societi\n",
      "socio\n",
      "sociolinguist\n",
      "sociolog\n",
      "sock\n",
      "soda\n",
      "sofc\n",
      "soft\n",
      "softcat\n",
      "softwar\n",
      "sofwath\n",
      "soil\n",
      "sokdr\n",
      "soket\n",
      "solar\n",
      "sold\n",
      "sole\n",
      "solenix\n",
      "solid\n",
      "solista\n",
      "solo\n",
      "solomona\n",
      "solubl\n",
      "solut\n",
      "solv\n",
      "solvabl\n",
      "solver\n",
      "som\n",
      "someon\n",
      "someth\n",
      "sometim\n",
      "somewhat\n",
      "somewher\n",
      "somo\n",
      "son\n",
      "sonar\n",
      "song\n",
      "songyang\n",
      "soni\n",
      "soon\n",
      "sophia\n",
      "sophist\n",
      "sora\n",
      "soravit\n",
      "sorbonn\n",
      "sorc\n",
      "soricut\n",
      "soroa\n",
      "soroush\n",
      "sort\n",
      "sosialurin\n",
      "sostenibilidad\n",
      "sota\n",
      "sotho\n",
      "soul\n",
      "soumya\n",
      "sound\n",
      "soundbit\n",
      "soundfil\n",
      "sourc\n",
      "sourcedata\n",
      "sourcelang\n",
      "sourcod\n",
      "south\n",
      "southeast\n",
      "southeastern\n",
      "southern\n",
      "souza\n",
      "sova\n",
      "soviet\n",
      "sovit\n",
      "soybean\n",
      "soynlp\n",
      "sp\n",
      "spa\n",
      "spacc\n",
      "spaccc\n",
      "space\n",
      "spacek\n",
      "spaci\n",
      "spade\n",
      "spaeti\n",
      "spagheti\n",
      "spaghetti\n",
      "spain\n",
      "spall\n",
      "spam\n",
      "spambas\n",
      "span\n",
      "spanish\n",
      "sparkl\n",
      "sparql\n",
      "sparrow\n",
      "spars\n",
      "spatial\n",
      "spatio\n",
      "spatiotempor\n",
      "speak\n",
      "speaker\n",
      "spear\n",
      "spearhead\n",
      "spec\n",
      "speci\n",
      "special\n",
      "specialis\n",
      "specialti\n",
      "specif\n",
      "specifi\n",
      "spect\n",
      "specter\n",
      "spectf\n",
      "spectogram\n",
      "spectra\n",
      "spectral\n",
      "spectro\n",
      "spectrogram\n",
      "spectrum\n",
      "speech\n",
      "speechbrain\n",
      "speechcommand\n",
      "speechocean\n",
      "speed\n",
      "speeddat\n",
      "spell\n",
      "spellcheck\n",
      "spellgram\n",
      "spend\n",
      "spent\n",
      "sperm\n",
      "spermatozoa\n",
      "spgispeech\n",
      "sphenoid\n",
      "sphere\n",
      "spheric\n",
      "spi\n",
      "spice\n",
      "spider\n",
      "spike\n",
      "spin\n",
      "spinal\n",
      "spindl\n",
      "spine\n",
      "spinetta\n",
      "spiral\n",
      "spirit\n",
      "spiritu\n",
      "spk\n",
      "spkrec\n",
      "spl\n",
      "splat\n",
      "spleen\n",
      "splice\n",
      "split\n",
      "spoiler\n",
      "spoke\n",
      "spoken\n",
      "spondyl\n",
      "spondyloarthrosi\n",
      "spondylolisthesi\n",
      "spondylosi\n",
      "spongi\n",
      "sponsor\n",
      "spontan\n",
      "spoof\n",
      "sport\n",
      "sportsett\n",
      "sportssum\n",
      "spot\n",
      "spotifi\n",
      "spr\n",
      "spraakbanken\n",
      "sprach\n",
      "spread\n",
      "spreadsheet\n",
      "spring\n",
      "springer\n",
      "sprint\n",
      "spritesheet\n",
      "spur\n",
      "spuriou\n",
      "spx\n",
      "sq\n",
      "sqa\n",
      "sql\n",
      "sqlite\n",
      "squad\n",
      "squadlik\n",
      "squadqg\n",
      "squadshift\n",
      "squaliti\n",
      "squall\n",
      "squar\n",
      "squat\n",
      "squeezenet\n",
      "squidigi\n",
      "squidl\n",
      "squirrel\n",
      "sr\n",
      "sra\n",
      "src\n",
      "sri\n",
      "srijhwan\n",
      "sriniva\n",
      "srir\n",
      "srivastava\n",
      "srivastavabeyond\n",
      "srl\n",
      "sroie\n",
      "srsd\n",
      "srtm\n",
      "sruviv\n",
      "ss\n",
      "sse\n",
      "ssh\n",
      "ssip\n",
      "ssjk\n",
      "ssl\n",
      "sss\n",
      "sst\n",
      "st\n",
      "stabil\n",
      "stabl\n",
      "stablesr\n",
      "staccato\n",
      "stack\n",
      "stackcub\n",
      "stackexchang\n",
      "stackexchange\n",
      "stackmix\n",
      "stackoverflow\n",
      "stackoverflowvqa\n",
      "staff\n",
      "stage\n",
      "stagger\n",
      "stain\n",
      "stairscas\n",
      "stairstep\n",
      "stamatato\n",
      "stamp\n",
      "stand\n",
      "standalon\n",
      "standard\n",
      "standardima\n",
      "standford\n",
      "standout\n",
      "stanford\n",
      "stanojev\n",
      "stanza\n",
      "stapl\n",
      "star\n",
      "starc\n",
      "starcod\n",
      "starcraft\n",
      "staredit\n",
      "starmi\n",
      "starrail\n",
      "starss\n",
      "start\n",
      "starter\n",
      "startpric\n",
      "startup\n",
      "starvat\n",
      "staryu\n",
      "stat\n",
      "stata\n",
      "statcast\n",
      "state\n",
      "statement\n",
      "static\n",
      "statin\n",
      "station\n",
      "statist\n",
      "statlib\n",
      "statmt\n",
      "statu\n",
      "statut\n",
      "statutori\n",
      "stavang\n",
      "stavro\n",
      "stay\n",
      "std\n",
      "steadili\n",
      "steam\n",
      "steedman\n",
      "steel\n",
      "steen\n",
      "steer\n",
      "stefan\n",
      "steinhardt\n",
      "steinmetz\n",
      "steinway\n",
      "steitz\n",
      "stem\n",
      "stemmer\n",
      "step\n",
      "stereo\n",
      "stereochemistri\n",
      "stereotyp\n",
      "steven\n",
      "stevhliu\n",
      "sthsthv\n",
      "sticker\n",
      "stickier\n",
      "stihi\n",
      "stil\n",
      "stimul\n",
      "stimuli\n",
      "sto\n",
      "stock\n",
      "stockholm\n",
      "stockmark\n",
      "stodden\n",
      "stomach\n",
      "stomata\n",
      "stool\n",
      "stop\n",
      "stopword\n",
      "stor\n",
      "storag\n",
      "store\n",
      "stori\n",
      "storiescan\n",
      "storieslanguag\n",
      "stormfront\n",
      "stormlib\n",
      "storytel\n",
      "str\n",
      "straighforward\n",
      "straight\n",
      "straightforward\n",
      "strateg\n",
      "strategi\n",
      "stratifi\n",
      "strawberri\n",
      "streak\n",
      "stream\n",
      "streamabl\n",
      "streamlin\n",
      "street\n",
      "streetview\n",
      "streetviewx\n",
      "strem\n",
      "strength\n",
      "strengthen\n",
      "stress\n",
      "stressor\n",
      "stretch\n",
      "strick\n",
      "strickvl\n",
      "strict\n",
      "stricter\n",
      "strictli\n",
      "stride\n",
      "strike\n",
      "strimel\n",
      "string\n",
      "stringent\n",
      "strint\n",
      "strip\n",
      "stripe\n",
      "strive\n",
      "strong\n",
      "strongli\n",
      "structlm\n",
      "structur\n",
      "strukturen\n",
      "strukturer\n",
      "sts\n",
      "stsb\n",
      "stsbenchmark\n",
      "stt\n",
      "student\n",
      "studi\n",
      "studio\n",
      "studiomus\n",
      "stuff\n",
      "style\n",
      "stylegan\n",
      "stylegaussian\n",
      "stylish\n",
      "styliz\n",
      "su\n",
      "suara\n",
      "sub\n",
      "subcategori\n",
      "subcollect\n",
      "subcorpu\n",
      "subdataset\n",
      "subdirectori\n",
      "subdivid\n",
      "subdivis\n",
      "subdomain\n",
      "subesco\n",
      "subforum\n",
      "subheadlin\n",
      "subject\n",
      "subjqa\n",
      "submiss\n",
      "submit\n",
      "subnetwork\n",
      "subordin\n",
      "subpart\n",
      "subreddit\n",
      "subsampl\n",
      "subscrib\n",
      "subscript\n",
      "subsequ\n",
      "subset\n",
      "substanc\n",
      "substanti\n",
      "substitut\n",
      "substr\n",
      "subtask\n",
      "subtitl\n",
      "subtl\n",
      "subtop\n",
      "subtract\n",
      "subway\n",
      "subzero\n",
      "succeed\n",
      "success\n",
      "successor\n",
      "succin\n",
      "sudarsanam\n",
      "suffer\n",
      "suffici\n",
      "suffix\n",
      "suggest\n",
      "suguru\n",
      "suhbrajit\n",
      "suicid\n",
      "suim\n",
      "suit\n",
      "suitabl\n",
      "sujet\n",
      "sulpha\n",
      "sult\n",
      "sultan\n",
      "sum\n",
      "sumeur\n",
      "sumita\n",
      "summ\n",
      "summar\n",
      "summari\n",
      "summaris\n",
      "summer\n",
      "sun\n",
      "sundanes\n",
      "sunday\n",
      "sundh\n",
      "sung\n",
      "sunglass\n",
      "sunlight\n",
      "sunnanraster\n",
      "sup\n",
      "super\n",
      "superalloy\n",
      "superb\n",
      "superclass\n",
      "supercomput\n",
      "superfici\n",
      "superglu\n",
      "superhero\n",
      "superhot\n",
      "superior\n",
      "supermat\n",
      "supernova\n",
      "superpixel\n",
      "supersed\n",
      "supertyp\n",
      "supervis\n",
      "supervisada\n",
      "superwiki\n",
      "supplement\n",
      "suppli\n",
      "support\n",
      "suppos\n",
      "suprem\n",
      "supremacist\n",
      "supremecourtofisrael\n",
      "supremo\n",
      "sur\n",
      "surabaya\n",
      "suraj\n",
      "sure\n",
      "surfac\n",
      "surg\n",
      "surgeri\n",
      "surgic\n",
      "surnam\n",
      "surpris\n",
      "surprisingli\n",
      "surround\n",
      "surtr\n",
      "survey\n",
      "surviv\n",
      "survivorslib\n",
      "susann\n",
      "suspect\n",
      "sussurro\n",
      "sust\n",
      "sustain\n",
      "suzuki\n",
      "suzuran\n",
      "sv\n",
      "svea\n",
      "svg\n",
      "sw\n",
      "swab\n",
      "swag\n",
      "swahili\n",
      "swan\n",
      "swaroop\n",
      "swathanthra\n",
      "swaziland\n",
      "swe\n",
      "swearword\n",
      "sweatshirt\n",
      "sweden\n",
      "swedish\n",
      "sweet\n",
      "swim\n",
      "swin\n",
      "swinv\n",
      "swire\n",
      "swiss\n",
      "switch\n",
      "switzerland\n",
      "sword\n",
      "sxdht\n",
      "sybil\n",
      "sycoph\n",
      "sydt\n",
      "syllabl\n",
      "sym\n",
      "symbol\n",
      "symmetr\n",
      "symphoni\n",
      "symposium\n",
      "symptom\n",
      "synchron\n",
      "synergi\n",
      "synergist\n",
      "synonym\n",
      "synops\n",
      "synopsi\n",
      "synshandicap\n",
      "syntact\n",
      "syntax\n",
      "syntezi\n",
      "synth\n",
      "synthes\n",
      "synthesi\n",
      "synthet\n",
      "synthtabnet\n",
      "syntra\n",
      "syntran\n",
      "syria\n",
      "syriel\n",
      "syst\n",
      "systemat\n",
      "systemprompt\n",
      "szpektor\n",
      "szymon\n",
      "ta\n",
      "tab\n",
      "tabl\n",
      "tablellm\n",
      "tableqa\n",
      "tablet\n",
      "tabletop\n",
      "tablevqa\n",
      "tablewar\n",
      "taborda\n",
      "tabular\n",
      "tac\n",
      "tackl\n",
      "taco\n",
      "tacotron\n",
      "tactic\n",
      "tadk\n",
      "tafsir\n",
      "tag\n",
      "tagalog\n",
      "tagger\n",
      "taghizadeh\n",
      "taglish\n",
      "tagset\n",
      "tahrirchi\n",
      "taid\n",
      "taiga\n",
      "tail\n",
      "tailor\n",
      "tair\n",
      "taiwan\n",
      "taiwanes\n",
      "tajik\n",
      "takano\n",
      "takeaway\n",
      "taken\n",
      "takumi\n",
      "taledata\n",
      "talent\n",
      "tali\n",
      "taliz\n",
      "talk\n",
      "talkbank\n",
      "talkrl\n",
      "taln\n",
      "taman\n",
      "tamazight\n",
      "tambi\n",
      "tamil\n",
      "tamir\n",
      "tamper\n",
      "tan\n",
      "tanberg\n",
      "tang\n",
      "tangela\n",
      "tango\n",
      "tanh\n",
      "tanishq\n",
      "tanmoy\n",
      "tanta\n",
      "tanya\n",
      "tanzil\n",
      "tao\n",
      "tap\n",
      "tapilot\n",
      "tar\n",
      "taraf\n",
      "tarawa\n",
      "tarea\n",
      "tarfil\n",
      "target\n",
      "targetlang\n",
      "tartakovski\n",
      "tarteel\n",
      "tasarlanm\n",
      "task\n",
      "taskmast\n",
      "tasksourc\n",
      "tasktyp\n",
      "tasmania\n",
      "tassel\n",
      "tast\n",
      "tat\n",
      "tata\n",
      "tation\n",
      "tatist\n",
      "tatoeba\n",
      "tau\n",
      "tawar\n",
      "tax\n",
      "taxa\n",
      "taxonom\n",
      "taxonomi\n",
      "taxvb\n",
      "tb\n",
      "tba\n",
      "tbaseparaphras\n",
      "tbc\n",
      "tbd\n",
      "tbx\n",
      "tc\n",
      "tca\n",
      "tcg\n",
      "tcidu\n",
      "tct\n",
      "td\n",
      "tdd\n",
      "tdtunlp\n",
      "te\n",
      "teach\n",
      "teacher\n",
      "team\n",
      "teammat\n",
      "tear\n",
      "teaser\n",
      "teborg\n",
      "tech\n",
      "technic\n",
      "techniqu\n",
      "technolog\n",
      "techreport\n",
      "tecnol\n",
      "tecnolog\n",
      "tecnologia\n",
      "ted\n",
      "tedbench\n",
      "tedlium\n",
      "tedx\n",
      "tee\n",
      "teeth\n",
      "teg\n",
      "tehran\n",
      "tekgen\n",
      "teknium\n",
      "teknolog\n",
      "tekst\n",
      "tekstdata\n",
      "tekster\n",
      "tele\n",
      "telebista\n",
      "telecommun\n",
      "telegram\n",
      "telemetri\n",
      "telephon\n",
      "telescop\n",
      "televs\n",
      "tell\n",
      "tellmewhi\n",
      "telugu\n",
      "temperari\n",
      "temperatur\n",
      "templat\n",
      "tempo\n",
      "tempofunk\n",
      "tempor\n",
      "tench\n",
      "tend\n",
      "tendr\n",
      "tener\n",
      "teng\n",
      "tenho\n",
      "tenn\n",
      "tennesse\n",
      "tenpo\n",
      "tens\n",
      "tensor\n",
      "tensorflow\n",
      "tensortensor\n",
      "tep\n",
      "ter\n",
      "terabyt\n",
      "terashima\n",
      "term\n",
      "termin\n",
      "terminolog\n",
      "terrain\n",
      "terraria\n",
      "terri\n",
      "terrier\n",
      "territorial\n",
      "terror\n",
      "tessa\n",
      "test\n",
      "testament\n",
      "testimoni\n",
      "testset\n",
      "testttt\n",
      "tetiana\n",
      "tetim\n",
      "tetramod\n",
      "tetsuo\n",
      "texa\n",
      "text\n",
      "textbook\n",
      "textbookqa\n",
      "textbox\n",
      "textcap\n",
      "textcyph\n",
      "textfacegan\n",
      "textgptv\n",
      "textil\n",
      "textimag\n",
      "textit\n",
      "textless\n",
      "texto\n",
      "textocr\n",
      "textsparql\n",
      "textsql\n",
      "texttext\n",
      "textual\n",
      "textur\n",
      "textura\n",
      "textvqa\n",
      "teyvat\n",
      "tfd\n",
      "tgif\n",
      "tgnb\n",
      "tgz\n",
      "th\n",
      "tha\n",
      "thai\n",
      "thaigov\n",
      "thailand\n",
      "thainer\n",
      "thaipb\n",
      "thaiqa\n",
      "thairath\n",
      "thaisum\n",
      "thalenberg\n",
      "thambawita\n",
      "thambawitavisem\n",
      "thank\n",
      "thapliy\n",
      "thapliyalcrossmodal\n",
      "thead\n",
      "theater\n",
      "theatr\n",
      "thegreatrambl\n",
      "themat\n",
      "theme\n",
      "themselv\n",
      "theochem\n",
      "theorem\n",
      "theoremqa\n",
      "theori\n",
      "theoriz\n",
      "therapi\n",
      "therebi\n",
      "therefor\n",
      "theresa\n",
      "thermal\n",
      "thermostat\n",
      "thesi\n",
      "thi\n",
      "thiago\n",
      "thienviet\n",
      "thing\n",
      "think\n",
      "thirteen\n",
      "thirti\n",
      "thorac\n",
      "thorn\n",
      "thorough\n",
      "thoroughli\n",
      "thought\n",
      "thousand\n",
      "thread\n",
      "threat\n",
      "threshold\n",
      "thrill\n",
      "thrive\n",
      "throat\n",
      "throw\n",
      "thrush\n",
      "thse\n",
      "thu\n",
      "thumb\n",
      "thumbnail\n",
      "thv\n",
      "ti\n",
      "tian\n",
      "tianl\n",
      "tianyu\n",
      "tib\n",
      "tibetan\n",
      "tibidabo\n",
      "tic\n",
      "tica\n",
      "ticker\n",
      "ticket\n",
      "ticketnum\n",
      "tictacto\n",
      "tide\n",
      "tidend\n",
      "tie\n",
      "tiedemann\n",
      "tien\n",
      "tier\n",
      "tierney\n",
      "tif\n",
      "tiff\n",
      "tifinagh\n",
      "tiger\n",
      "tigrinya\n",
      "tii\n",
      "tiktoken\n",
      "til\n",
      "tild\n",
      "tile\n",
      "tileset\n",
      "tilg\n",
      "tillman\n",
      "tilt\n",
      "tim\n",
      "timber\n",
      "timbr\n",
      "time\n",
      "timecod\n",
      "timeless\n",
      "timelin\n",
      "timepiec\n",
      "timer\n",
      "timeseri\n",
      "timestamp\n",
      "timo\n",
      "timofeeva\n",
      "timoft\n",
      "tinca\n",
      "ting\n",
      "tinh\n",
      "tini\n",
      "tinkoff\n",
      "tinni\n",
      "tint\n",
      "tinymistr\n",
      "tinyorca\n",
      "tinystori\n",
      "tinytruthfulqa\n",
      "tion\n",
      "tip\n",
      "tiqu\n",
      "tirasaroj\n",
      "tire\n",
      "tissu\n",
      "titan\n",
      "titl\n",
      "titml\n",
      "titulo\n",
      "tjong\n",
      "tk\n",
      "tl\n",
      "tlc\n",
      "tldr\n",
      "tm\n",
      "tmh\n",
      "tmmlu\n",
      "tmp\n",
      "tmr\n",
      "tmx\n",
      "tne\n",
      "tner\n",
      "tngcv\n",
      "tnhc\n",
      "tnjgpmtz\n",
      "toagpt\n",
      "toba\n",
      "tobia\n",
      "toda\n",
      "today\n",
      "todisco\n",
      "todo\n",
      "toe\n",
      "tofu\n",
      "togeth\n",
      "togethercomput\n",
      "toh\n",
      "tohru\n",
      "toilet\n",
      "token\n",
      "tokenis\n",
      "tokenizarlo\n",
      "tokens\n",
      "toki\n",
      "tokipona\n",
      "tokyo\n",
      "tollefj\n",
      "toloka\n",
      "tom\n",
      "toman\n",
      "tomasg\n",
      "tomato\n",
      "tomaz\n",
      "tomi\n",
      "tomimi\n",
      "tomo\n",
      "tomographi\n",
      "tone\n",
      "tong\n",
      "tonic\n",
      "took\n",
      "tool\n",
      "toolcal\n",
      "toolkit\n",
      "toothpick\n",
      "topic\n",
      "topicsum\n",
      "topiocqa\n",
      "topluluk\n",
      "topograph\n",
      "topographi\n",
      "topolog\n",
      "topperc\n",
      "topr\n",
      "toprol\n",
      "toqu\n",
      "torch\n",
      "tori\n",
      "tormo\n",
      "tornado\n",
      "toronto\n",
      "toropov\n",
      "total\n",
      "totto\n",
      "touch\n",
      "touche\n",
      "touhouwiki\n",
      "tour\n",
      "tourism\n",
      "tourist\n",
      "tournament\n",
      "toutanova\n",
      "towel\n",
      "tower\n",
      "towerinstruct\n",
      "town\n",
      "toxic\n",
      "toxicchat\n",
      "toxigen\n",
      "toxocen\n",
      "toxoplasma\n",
      "toy\n",
      "tp\n",
      "tr\n",
      "trabina\n",
      "trace\n",
      "traceabl\n",
      "track\n",
      "tracker\n",
      "tractabl\n",
      "traction\n",
      "trad\n",
      "trade\n",
      "trademark\n",
      "tradit\n",
      "tradu\n",
      "traduit\n",
      "traffic\n",
      "traiga\n",
      "trail\n",
      "trailblaz\n",
      "trailer\n",
      "train\n",
      "trainer\n",
      "trainfifi\n",
      "trainig\n",
      "trainingdata\n",
      "trait\n",
      "trajectori\n",
      "tram\n",
      "tramtrain\n",
      "tran\n",
      "tranger\n",
      "trankit\n",
      "transact\n",
      "transactpro\n",
      "transcrib\n",
      "transcrieb\n",
      "transcript\n",
      "transfer\n",
      "transform\n",
      "transformationen\n",
      "transfus\n",
      "transgend\n",
      "transgener\n",
      "transient\n",
      "transit\n",
      "transkription\n",
      "translat\n",
      "transliter\n",
      "transmit\n",
      "transport\n",
      "transscript\n",
      "traor\n",
      "trap\n",
      "trash\n",
      "trasncript\n",
      "trauma\n",
      "trav\n",
      "travail\n",
      "travel\n",
      "travelplann\n",
      "travers\n",
      "trawsgrifiadau\n",
      "trdition\n",
      "tre\n",
      "treasur\n",
      "treat\n",
      "treatment\n",
      "trec\n",
      "tree\n",
      "treebank\n",
      "treehk\n",
      "treeoflif\n",
      "tremend\n",
      "tremolo\n",
      "trend\n",
      "treningu\n",
      "trento\n",
      "trg\n",
      "tri\n",
      "trial\n",
      "triangulum\n",
      "tribal\n",
      "tribe\n",
      "tribun\n",
      "tribunnew\n",
      "trick\n",
      "trigger\n",
      "trilingu\n",
      "trill\n",
      "trillion\n",
      "trim\n",
      "trine\n",
      "trinket\n",
      "trip\n",
      "tripadvisor\n",
      "tripclick\n",
      "tripl\n",
      "triplet\n",
      "trismegistu\n",
      "tristan\n",
      "trivia\n",
      "triviaqa\n",
      "triviaqqa\n",
      "trl\n",
      "trmal\n",
      "trocr\n",
      "troubleshoot\n",
      "trpakov\n",
      "truck\n",
      "true\n",
      "truecas\n",
      "truli\n",
      "truncat\n",
      "truncatedsvd\n",
      "trust\n",
      "trustworthi\n",
      "truth\n",
      "truthfulqa\n",
      "truy\n",
      "trykt\n",
      "ts\n",
      "tser\n",
      "tsf\n",
      "tshitoyan\n",
      "tsi\n",
      "tsinghua\n",
      "tsit\n",
      "tsn\n",
      "tst\n",
      "tsubame\n",
      "tsuboyama\n",
      "tsv\n",
      "tt\n",
      "ttc\n",
      "tten\n",
      "tter\n",
      "ttet\n",
      "ttl\n",
      "ttp\n",
      "tu\n",
      "tudiant\n",
      "tug\n",
      "tulu\n",
      "tumblr\n",
      "tumor\n",
      "tune\n",
      "tunear\n",
      "tunga\n",
      "tunisia\n",
      "tuo\n",
      "tuoma\n",
      "tupi\n",
      "tupl\n",
      "tur\n",
      "turbo\n",
      "ture\n",
      "turk\n",
      "turkcorpu\n",
      "turker\n",
      "turkey\n",
      "turkish\n",
      "turkishneuralvoic\n",
      "turku\n",
      "turma\n",
      "turn\n",
      "turulmu\n",
      "tuset\n",
      "tushar\n",
      "tut\n",
      "tutoiement\n",
      "tutori\n",
      "tutu\n",
      "tutupan\n",
      "tuxemon\n",
      "tv\n",
      "tw\n",
      "tweak\n",
      "tweebank\n",
      "tweet\n",
      "tweeter\n",
      "tweetner\n",
      "twelv\n",
      "twenti\n",
      "twi\n",
      "twice\n",
      "twin\n",
      "twintail\n",
      "twitch\n",
      "twitter\n",
      "twnertc\n",
      "twofold\n",
      "twonorm\n",
      "twp\n",
      "txd\n",
      "txt\n",
      "tydi\n",
      "tyer\n",
      "tympan\n",
      "type\n",
      "typeddict\n",
      "typeset\n",
      "typic\n",
      "typo\n",
      "typolog\n",
      "tyrkk\n",
      "tzu\n",
      "ua\n",
      "uae\n",
      "ub\n",
      "uba\n",
      "ubcc\n",
      "ubuntu\n",
      "uc\n",
      "ucd\n",
      "ucf\n",
      "uci\n",
      "ucla\n",
      "ucr\n",
      "ucsi\n",
      "ud\n",
      "udgivet\n",
      "udn\n",
      "udvalgt\n",
      "ue\n",
      "uea\n",
      "uec\n",
      "uedcnescynn\n",
      "uedin\n",
      "uemon\n",
      "uet\n",
      "ueti\n",
      "uf\n",
      "ufg\n",
      "ufsac\n",
      "ufsc\n",
      "ug\n",
      "ugk\n",
      "uhura\n",
      "ui\n",
      "uibert\n",
      "uid\n",
      "uit\n",
      "uiuc\n",
      "uk\n",
      "ukhushn\n",
      "ukiyo\n",
      "ukrain\n",
      "ukrainian\n",
      "ukranian\n",
      "ul\n",
      "ulca\n",
      "ulpgl\n",
      "ultim\n",
      "ultra\n",
      "ultrachat\n",
      "ultracm\n",
      "ultrafeedback\n",
      "ultrarm\n",
      "ultrasafeti\n",
      "ulwv\n",
      "ulyssesbr\n",
      "ulyssesn\n",
      "um\n",
      "uma\n",
      "umap\n",
      "umd\n",
      "uml\n",
      "umt\n",
      "una\n",
      "unabl\n",
      "unaccept\n",
      "unam\n",
      "unambigu\n",
      "unannot\n",
      "unanswer\n",
      "unarch\n",
      "unattend\n",
      "unavail\n",
      "unb\n",
      "unbalanc\n",
      "uncas\n",
      "uncensor\n",
      "uncertain\n",
      "uncertainti\n",
      "unclean\n",
      "unclear\n",
      "uncompil\n",
      "uncompress\n",
      "uncondit\n",
      "unconstrain\n",
      "uncorrel\n",
      "uncov\n",
      "und\n",
      "undeni\n",
      "undergo\n",
      "undergon\n",
      "undergradu\n",
      "underli\n",
      "underpin\n",
      "underrepres\n",
      "underscor\n",
      "underspecifi\n",
      "understand\n",
      "understood\n",
      "undertak\n",
      "undertaken\n",
      "undertook\n",
      "underw\n",
      "underwat\n",
      "underway\n",
      "undesir\n",
      "unearth\n",
      "uneccessari\n",
      "unequ\n",
      "uner\n",
      "uneth\n",
      "unfair\n",
      "unfaith\n",
      "unfilt\n",
      "unfinish\n",
      "unfortun\n",
      "uni\n",
      "uniarch\n",
      "unicod\n",
      "unif\n",
      "unifi\n",
      "uniform\n",
      "uniformli\n",
      "uniir\n",
      "unimm\n",
      "unimod\n",
      "union\n",
      "uniprot\n",
      "uniqu\n",
      "uniref\n",
      "unit\n",
      "univers\n",
      "universidad\n",
      "universit\n",
      "universitat\n",
      "universiteit\n",
      "unix\n",
      "unk\n",
      "unknown\n",
      "unlabel\n",
      "unlearn\n",
      "unlik\n",
      "unlock\n",
      "unmask\n",
      "unmatch\n",
      "unmix\n",
      "unnam\n",
      "unnatur\n",
      "unnecessari\n",
      "uno\n",
      "unoffici\n",
      "unord\n",
      "unp\n",
      "unpack\n",
      "unpair\n",
      "unparallel\n",
      "unport\n",
      "unpreced\n",
      "unpredict\n",
      "unprocess\n",
      "unprompt\n",
      "unproven\n",
      "unpublish\n",
      "unravel\n",
      "unreal\n",
      "unrecogn\n",
      "unrel\n",
      "unreli\n",
      "unrestrain\n",
      "unsaf\n",
      "unscript\n",
      "unseen\n",
      "unshuffl\n",
      "unsilenc\n",
      "unsloth\n",
      "unsolicit\n",
      "unsolv\n",
      "unsort\n",
      "unsplash\n",
      "unstructur\n",
      "unsual\n",
      "unsuccess\n",
      "unsuit\n",
      "unsup\n",
      "unsupervis\n",
      "unsw\n",
      "unsynchron\n",
      "untrunc\n",
      "unusu\n",
      "unwant\n",
      "unwieldi\n",
      "unwrap\n",
      "unzip\n",
      "uom\n",
      "upcom\n",
      "upd\n",
      "updat\n",
      "updateticketnum\n",
      "upgrad\n",
      "upgrow\n",
      "uphold\n",
      "upload\n",
      "uplug\n",
      "upo\n",
      "upper\n",
      "upright\n",
      "upscal\n",
      "upsurg\n",
      "upv\n",
      "upvot\n",
      "upward\n",
      "upwork\n",
      "ur\n",
      "ural\n",
      "urban\n",
      "urbana\n",
      "urbanism\n",
      "urbansyn\n",
      "urdu\n",
      "urg\n",
      "urgent\n",
      "uri\n",
      "urib\n",
      "url\n",
      "urllink\n",
      "urmi\n",
      "urn\n",
      "usa\n",
      "usabl\n",
      "usag\n",
      "usando\n",
      "usar\n",
      "usb\n",
      "uscensu\n",
      "usclassact\n",
      "use\n",
      "user\n",
      "usg\n",
      "ushiku\n",
      "ushl\n",
      "usingt\n",
      "uso\n",
      "uspto\n",
      "usr\n",
      "usual\n",
      "uta\n",
      "utag\n",
      "utc\n",
      "utf\n",
      "util\n",
      "utilis\n",
      "utilit\n",
      "utilizaci\n",
      "utiyama\n",
      "utlizars\n",
      "utmo\n",
      "utt\n",
      "utter\n",
      "utvr\n",
      "uuid\n",
      "uvd\n",
      "uvylj\n",
      "uwb\n",
      "uwet\n",
      "uyemf\n",
      "uyghur\n",
      "uz\n",
      "uzbek\n",
      "uzbook\n",
      "uzcrawl\n",
      "uzenzel\n",
      "uzuki\n",
      "va\n",
      "vacanc\n",
      "vaccin\n",
      "vacuol\n",
      "vacuum\n",
      "vad\n",
      "vae\n",
      "vai\n",
      "vaishali\n",
      "vaishnavi\n",
      "vaiv\n",
      "vajira\n",
      "vajirayana\n",
      "val\n",
      "valencian\n",
      "valentin\n",
      "valeri\n",
      "valeria\n",
      "valerie\n",
      "valid\n",
      "validatid\n",
      "vall\n",
      "vallabha\n",
      "valmiki\n",
      "valor\n",
      "valu\n",
      "valuabl\n",
      "valueev\n",
      "valv\n",
      "vamo\n",
      "van\n",
      "vanessaschenkel\n",
      "vare\n",
      "vari\n",
      "variabl\n",
      "varianc\n",
      "variant\n",
      "variat\n",
      "varieti\n",
      "vario\n",
      "variou\n",
      "varioyu\n",
      "varta\n",
      "vasant\n",
      "vasilii\n",
      "vassil\n",
      "vast\n",
      "vat\n",
      "vaughan\n",
      "vazquez\n",
      "vblagoj\n",
      "vcf\n",
      "vdesign\n",
      "vdet\n",
      "ve\n",
      "vector\n",
      "vectordb\n",
      "vegann\n",
      "veget\n",
      "vegetarian\n",
      "vehicl\n",
      "vel\n",
      "veloc\n",
      "velvet\n",
      "venafi\n",
      "vendor\n",
      "veneta\n",
      "venezuela\n",
      "venkatapathi\n",
      "venonat\n",
      "ventur\n",
      "venu\n",
      "ver\n",
      "verac\n",
      "verb\n",
      "verbal\n",
      "verbalis\n",
      "verdict\n",
      "verena\n",
      "veri\n",
      "verif\n",
      "verifi\n",
      "vermeil\n",
      "vers\n",
      "versa\n",
      "versatil\n",
      "versicolor\n",
      "version\n",
      "versu\n",
      "vertebr\n",
      "vertebra\n",
      "vertic\n",
      "verziju\n",
      "vessl\n",
      "vest\n",
      "vestman\n",
      "vet\n",
      "veteran\n",
      "veyseh\n",
      "vfj\n",
      "vflan\n",
      "vg\n",
      "vgg\n",
      "vggface\n",
      "vggsound\n",
      "vh\n",
      "vhr\n",
      "vi\n",
      "vibrant\n",
      "vibrato\n",
      "vice\n",
      "vicgal\n",
      "vicomtech\n",
      "victim\n",
      "victoria\n",
      "victr\n",
      "vicuna\n",
      "vid\n",
      "video\n",
      "videochat\n",
      "videochatgpt\n",
      "videoclip\n",
      "videoconfer\n",
      "videogam\n",
      "videoid\n",
      "videoma\n",
      "vidgen\n",
      "vidprom\n",
      "vieira\n",
      "vien\n",
      "vienen\n",
      "vietai\n",
      "vietbiblevox\n",
      "vietnam\n",
      "vietnames\n",
      "view\n",
      "viewcount\n",
      "viewer\n",
      "viggo\n",
      "vigna\n",
      "vihatet\n",
      "viic\n",
      "vikash\n",
      "vikipedi\n",
      "viktorialand\n",
      "vilasum\n",
      "vilaweb\n",
      "vileplum\n",
      "vill\n",
      "villain\n",
      "vinai\n",
      "vincent\n",
      "vine\n",
      "vineeth\n",
      "vineyard\n",
      "vinta\n",
      "vio\n",
      "violat\n",
      "violenc\n",
      "violent\n",
      "vip\n",
      "vipul\n",
      "viquad\n",
      "virgin\n",
      "virginia\n",
      "virginica\n",
      "virtanen\n",
      "virtual\n",
      "virtuoso\n",
      "visa\n",
      "visem\n",
      "vishal\n",
      "vishrav\n",
      "visibl\n",
      "vision\n",
      "visionand\n",
      "visionui\n",
      "visit\n",
      "visitor\n",
      "visokih\n",
      "visor\n",
      "vista\n",
      "visual\n",
      "visualgenom\n",
      "visualis\n",
      "visualroberta\n",
      "visualwebbench\n",
      "visuomotor\n",
      "vit\n",
      "vital\n",
      "vitali\n",
      "vitaliy\n",
      "vitamin\n",
      "viticultur\n",
      "vitigeoss\n",
      "viusal\n",
      "vivanew\n",
      "vivechan\n",
      "vivian\n",
      "vivo\n",
      "vivrc\n",
      "vivym\n",
      "vizwiz\n",
      "vl\n",
      "vllm\n",
      "vlm\n",
      "vlsp\n",
      "vm\n",
      "vn\n",
      "vnuhcm\n",
      "voa\n",
      "voc\n",
      "vocab\n",
      "vocabulari\n",
      "vocal\n",
      "vocalist\n",
      "vocod\n",
      "vogelstein\n",
      "voic\n",
      "voicebox\n",
      "voicemail\n",
      "voiceprint\n",
      "void\n",
      "voiri\n",
      "volatil\n",
      "voltag\n",
      "volum\n",
      "volumetr\n",
      "volumn\n",
      "volunt\n",
      "von\n",
      "vote\n",
      "voter\n",
      "vouvoiement\n",
      "vox\n",
      "voxceleb\n",
      "voxcelebspoof\n",
      "voxdiy\n",
      "voxel\n",
      "voxlab\n",
      "voz\n",
      "vp\n",
      "vq\n",
      "vqa\n",
      "vqaonlin\n",
      "vqav\n",
      "vquanda\n",
      "vript\n",
      "vroid\n",
      "vs\n",
      "vsmg\n",
      "vsr\n",
      "vt\n",
      "vtt\n",
      "vu\n",
      "vuitton\n",
      "vuk\n",
      "vulcan\n",
      "vulgar\n",
      "vulgat\n",
      "vuli\n",
      "vulner\n",
      "vumichien\n",
      "vv\n",
      "wa\n",
      "waai\n",
      "wacki\n",
      "waifu\n",
      "waist\n",
      "wait\n",
      "waitingroom\n",
      "wajdm\n",
      "wakeword\n",
      "wale\n",
      "walk\n",
      "walker\n",
      "wall\n",
      "wallet\n",
      "wallfollow\n",
      "walmsley\n",
      "wanchuang\n",
      "wang\n",
      "wangbo\n",
      "wangchanglm\n",
      "wangcovost\n",
      "wangexploit\n",
      "wangglu\n",
      "wangscen\n",
      "wangsuperglu\n",
      "wanli\n",
      "wannaphong\n",
      "wanng\n",
      "want\n",
      "wanyu\n",
      "war\n",
      "ward\n",
      "wardenpad\n",
      "warehous\n",
      "warfarin\n",
      "warm\n",
      "warmli\n",
      "warn\n",
      "warranti\n",
      "warstadt\n",
      "warstadtneur\n",
      "wartha\n",
      "waseem\n",
      "washington\n",
      "washroom\n",
      "wasn\n",
      "wast\n",
      "watanab\n",
      "watch\n",
      "water\n",
      "waterbodi\n",
      "watermark\n",
      "watkin\n",
      "wav\n",
      "wave\n",
      "waveform\n",
      "waveformnoisev\n",
      "wavenet\n",
      "waveprop\n",
      "wavvec\n",
      "wawjdm\n",
      "waxholm\n",
      "way\n",
      "wayuunaiki\n",
      "wb\n",
      "wbc\n",
      "wbt\n",
      "wcep\n",
      "wdc\n",
      "weak\n",
      "weakli\n",
      "wealth\n",
      "wealthi\n",
      "weapon\n",
      "wear\n",
      "weasel\n",
      "weather\n",
      "weathergov\n",
      "web\n",
      "webapp\n",
      "webarch\n",
      "webbnyhet\n",
      "webcam\n",
      "webdataset\n",
      "webi\n",
      "webinstruct\n",
      "webist\n",
      "weblinx\n",
      "webm\n",
      "webmast\n",
      "webmd\n",
      "webnlg\n",
      "webot\n",
      "webp\n",
      "webpag\n",
      "webrtc\n",
      "webrtcvad\n",
      "websit\n",
      "websrc\n",
      "webtext\n",
      "webui\n",
      "webvid\n",
      "webz\n",
      "weed\n",
      "weedi\n",
      "weedl\n",
      "week\n",
      "weekli\n",
      "weepinbel\n",
      "wei\n",
      "weibo\n",
      "weichbroth\n",
      "weidi\n",
      "weight\n",
      "weiran\n",
      "weixun\n",
      "weka\n",
      "welcom\n",
      "wellformed\n",
      "welsh\n",
      "wen\n",
      "wenbo\n",
      "wenbopan\n",
      "wenhu\n",
      "wenku\n",
      "went\n",
      "wenwen\n",
      "wenzek\n",
      "wer\n",
      "west\n",
      "westergaard\n",
      "western\n",
      "westh\n",
      "weston\n",
      "weyd\n",
      "wg\n",
      "wget\n",
      "wgisd\n",
      "wh\n",
      "whale\n",
      "whatev\n",
      "wheel\n",
      "wheelchair\n",
      "whera\n",
      "wherea\n",
      "whi\n",
      "whiskey\n",
      "whislash\n",
      "whisper\n",
      "whisperain\n",
      "whisperspeech\n",
      "whistl\n",
      "white\n",
      "whitebg\n",
      "whiteboard\n",
      "whitehead\n",
      "whiten\n",
      "whitespac\n",
      "wholli\n",
      "whosampl\n",
      "whu\n",
      "wi\n",
      "wia\n",
      "widdd\n",
      "wide\n",
      "wider\n",
      "widespread\n",
      "widli\n",
      "widlii\n",
      "width\n",
      "wiesp\n",
      "wifi\n",
      "wig\n",
      "wigan\n",
      "wiki\n",
      "wikiann\n",
      "wikiansw\n",
      "wikiart\n",
      "wikiasp\n",
      "wikiauto\n",
      "wikib\n",
      "wikibio\n",
      "wikibook\n",
      "wikicorpu\n",
      "wikidata\n",
      "wikidoc\n",
      "wikidocpatientinform\n",
      "wikidt\n",
      "wikihow\n",
      "wikilingua\n",
      "wikimatrix\n",
      "wikimedia\n",
      "wikimovi\n",
      "wikin\n",
      "wikineur\n",
      "wikinew\n",
      "wikipedia\n",
      "wikipeida\n",
      "wikiqa\n",
      "wikisourc\n",
      "wikisplit\n",
      "wikisql\n",
      "wikisum\n",
      "wikit\n",
      "wikitablequest\n",
      "wikitablet\n",
      "wikitext\n",
      "wikititl\n",
      "wilber\n",
      "wild\n",
      "wildbench\n",
      "wildchat\n",
      "wildfir\n",
      "wildlif\n",
      "wiley\n",
      "william\n",
      "win\n",
      "window\n",
      "wine\n",
      "wing\n",
      "winner\n",
      "wino\n",
      "winobia\n",
      "winograd\n",
      "winogrand\n",
      "winter\n",
      "wip\n",
      "wire\n",
      "wisc\n",
      "wisconsin\n",
      "wisdom\n",
      "wisdombar\n",
      "wise\n",
      "wisesight\n",
      "wish\n",
      "wit\n",
      "witchessocialstream\n",
      "witczak\n",
      "withhold\n",
      "wixarika\n",
      "wizard\n",
      "wizardlm\n",
      "wizztow\n",
      "wlasl\n",
      "wle\n",
      "wlot\n",
      "wmm\n",
      "wmt\n",
      "wnawcza\n",
      "wngt\n",
      "wnut\n",
      "wo\n",
      "wojtasik\n",
      "wol\n",
      "wolberg\n",
      "wolf\n",
      "wolff\n",
      "wolof\n",
      "woman\n",
      "women\n",
      "won\n",
      "wonder\n",
      "wong\n",
      "woo\n",
      "wood\n",
      "woodland\n",
      "woodscap\n",
      "woori\n",
      "word\n",
      "wordphonem\n",
      "wordplay\n",
      "wordvec\n",
      "work\n",
      "worker\n",
      "workflow\n",
      "workplac\n",
      "workshop\n",
      "workspac\n",
      "workstat\n",
      "world\n",
      "worldwid\n",
      "worn\n",
      "wors\n",
      "worth\n",
      "worthwhil\n",
      "wortschatz\n",
      "wow\n",
      "woz\n",
      "wpr\n",
      "wr\n",
      "wrap\n",
      "wraper\n",
      "wrapper\n",
      "wreck\n",
      "wright\n",
      "write\n",
      "writer\n",
      "written\n",
      "wrong\n",
      "wrote\n",
      "ws\n",
      "wsd\n",
      "wsdmcup\n",
      "wtih\n",
      "wtq\n",
      "wu\n",
      "wudao\n",
      "wudaocorpora\n",
      "wukong\n",
      "wukongm\n",
      "wvj\n",
      "ww\n",
      "www\n",
      "wycliff\n",
      "xaee\n",
      "xai\n",
      "xavier\n",
      "xb\n",
      "xbc\n",
      "xbmu\n",
      "xbooru\n",
      "xbow\n",
      "xbuk\n",
      "xcopa\n",
      "xcup\n",
      "xd\n",
      "xejw\n",
      "xf\n",
      "xfeeba\n",
      "xg\n",
      "xglue\n",
      "xgqa\n",
      "xho\n",
      "xhosa\n",
      "xi\n",
      "xia\n",
      "xiaaid\n",
      "xiahua\n",
      "xiahuayin\n",
      "xiangtao\n",
      "xianm\n",
      "xiao\n",
      "xiaogang\n",
      "xiaonan\n",
      "xiaoou\n",
      "xiaoqiang\n",
      "xiaoyu\n",
      "xie\n",
      "xin\n",
      "xincan\n",
      "xincheng\n",
      "xing\n",
      "xingyu\n",
      "xinrun\n",
      "xinyi\n",
      "xitsonga\n",
      "xiu\n",
      "xkcd\n",
      "xl\n",
      "xliff\n",
      "xlm\n",
      "xlsum\n",
      "xlvx\n",
      "xm\n",
      "xmax\n",
      "xmediasum\n",
      "xmin\n",
      "xml\n",
      "xnli\n",
      "xor\n",
      "xp\n",
      "xpo\n",
      "xquad\n",
      "xr\n",
      "xray\n",
      "xscienc\n",
      "xss\n",
      "xsum\n",
      "xt\n",
      "xtreme\n",
      "xu\n",
      "xudong\n",
      "xue\n",
      "xuelong\n",
      "xuewen\n",
      "xuexiqiangguo\n",
      "xuretriev\n",
      "xvect\n",
      "xvector\n",
      "xview\n",
      "xvnli\n",
      "xwiki\n",
      "xx\n",
      "xxx\n",
      "xz\n",
      "ya\n",
      "yaakov\n",
      "yaameen\n",
      "yadav\n",
      "yahma\n",
      "yahoo\n",
      "yale\n",
      "yalt\n",
      "yaltai\n",
      "yamagishi\n",
      "yamaha\n",
      "yaml\n",
      "yan\n",
      "yand\n",
      "yandere\n",
      "yandex\n",
      "yang\n",
      "yann\n",
      "yannic\n",
      "yaound\n",
      "yaozhi\n",
      "yapakta\n",
      "yarom\n",
      "yatim\n",
      "yato\n",
      "yay\n",
      "yaz\n",
      "ye\n",
      "year\n",
      "yeast\n",
      "yellow\n",
      "yen\n",
      "yequan\n",
      "yer\n",
      "yerevann\n",
      "yeti\n",
      "yf\n",
      "yfccm\n",
      "yhavinga\n",
      "yi\n",
      "yichan\n",
      "yield\n",
      "yifei\n",
      "yifeng\n",
      "yike\n",
      "yime\n",
      "yin\n",
      "ying\n",
      "yixin\n",
      "yixinliuc\n",
      "ylz\n",
      "ymax\n",
      "ymin\n",
      "yn\n",
      "yo\n",
      "yogesh\n",
      "yolo\n",
      "yolochess\n",
      "yolov\n",
      "yolox\n",
      "yonathan\n",
      "yonggang\n",
      "yor\n",
      "york\n",
      "yorker\n",
      "yoruba\n",
      "yorubatwi\n",
      "yoruno\n",
      "yorunohitsuji\n",
      "yoshihiko\n",
      "yoshimoto\n",
      "youcook\n",
      "young\n",
      "youngchang\n",
      "youtub\n",
      "youtubeload\n",
      "youvers\n",
      "yrj\n",
      "yttb\n",
      "yu\n",
      "yuan\n",
      "yuanhan\n",
      "yuchen\n",
      "yue\n",
      "yuelin\n",
      "yueqian\n",
      "yuhang\n",
      "yuhui\n",
      "yuji\n",
      "yukai\n",
      "yuki\n",
      "yuliang\n",
      "yun\n",
      "yune\n",
      "yuningm\n",
      "yupeng\n",
      "yuri\n",
      "yusuk\n",
      "yutao\n",
      "yuuka\n",
      "yuxiang\n",
      "yuxuan\n",
      "yuxun\n",
      "yuyang\n",
      "zaanind\n",
      "zae\n",
      "zaid\n",
      "zapdo\n",
      "zden\n",
      "zealand\n",
      "zebra\n",
      "zeerak\n",
      "zellikl\n",
      "zeman\n",
      "zen\n",
      "zenodo\n",
      "zenseact\n",
      "zephyr\n",
      "zerind\n",
      "zero\n",
      "zerochan\n",
      "zeroshot\n",
      "zeroth\n",
      "zest\n",
      "zetavg\n",
      "zeti\n",
      "zffswyrinhjxt\n",
      "zh\n",
      "zhang\n",
      "zhangmexam\n",
      "zhao\n",
      "zhaodirichlet\n",
      "zhaofeatur\n",
      "zhaoqtsumm\n",
      "zhconv\n",
      "zhenfeng\n",
      "zheng\n",
      "zhengp\n",
      "zhicheng\n",
      "zhihu\n",
      "zhiyi\n",
      "zho\n",
      "zhong\n",
      "zhou\n",
      "zhoupatternnet\n",
      "zhtw\n",
      "zhu\n",
      "zhuang\n",
      "zhuoer\n",
      "zhwiki\n",
      "zihao\n",
      "zikir\n",
      "zilio\n",
      "zillow\n",
      "zima\n",
      "zip\n",
      "zipcod\n",
      "zipfian\n",
      "ziqiang\n",
      "ziwei\n",
      "ziyuan\n",
      "zm\n",
      "zod\n",
      "zofia\n",
      "zombi\n",
      "zone\n",
      "zoo\n",
      "zoom\n",
      "zou\n",
      "zs\n",
      "zst\n",
      "zucchini\n",
      "zul\n",
      "zulu\n",
      "zwitterion\n"
     ]
    }
   ],
   "source": [
    "for i in cv.get_feature_names_out():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation based particular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(dataset):\n",
    "    model_index = df2[df2[\"id\"]==dataset].index[0]\n",
    "    distances = similarity[model_index]\n",
    "    recommends = sorted(list(enumerate(distances)) , reverse=True , key=lambda x:x[1])[1:6]\n",
    "    for i in recommends:\n",
    "        print(df2.iloc[i[0]][1])\n",
    "        print(df2.iloc[i[0]][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openbmb/RLAIF-V-Dataset\n",
      "Lin-Chen/ShareGPT4V\n",
      "liuhaotian/LLaVA-Instruct-150K\n",
      "MMMU/MMMU\n",
      "openbmb/RLHF-V-Dataset\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(df['id'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mizinovmv/LLaVA-Instruct-150K-RU\n",
      "llava visual instruct k dataset detail dataset type llava visual instruct k is a set of gpt gener multimod instruct follow data it is construct for visual instruct tune and for build larg multimod toward gpt  vision languag capabl dataset date llava visual instruct k wa collect in april  by prompt gpt   api paper or resourc see the full descript on the dataset page\n",
      "LLaVA-VL/llava-plus-data\n",
      "llava plu instruct dataset detail dataset type llava plu v k is a set of gpt gener multimod tool augment instruct follow data it is construct for tool use to build larg multimod agent with gpt  plu vision languag capabl dataset date llava plu v k wa collect in sep  by prompt chatgpt gpt   api paper or resourc for more inform licens see the full descript on the dataset page\n",
      "mucai/ViP-LLaVA-Instruct\n",
      "vip llava instruct dataset detail dataset type vip llava instruct is compos of a mixtur of llava   instruct data and the region level visual prompt data it is construct for visual instruct tune and for build larg multimod toward gpt  level region understand capabl specif we use  m data for stage  finetun and use k data for the option stage  finetun dataset date vip llava instruct wa see the full descript on the dataset page\n",
      "damerajee/Hindi-LLaVA-CC3M-Pretrain-595K\n",
      "llava visual instruct ccm k pretrain dataset detail dataset type llava visual instruct ccm pretrain k is a subset of cc m dataset filter with a more balanc concept coverag distribut caption are also associ with blip synthet caption for refer it is construct for the pretrain stage for featur align in visual instruct tune we aim to build larg multimod toward gpt  vision languag capabl dataset see the full descript on the dataset page\n",
      "pig4431/TextGPT4V\n",
      "textgptv k dataset detail dataset type textgptv k is a set of gptv gener instruct data to enchanc the textual capabl of vlm construct with prompt gpt  vision preview dataset date textgptv k wa collect in nov  by prompt gpt  vision preview api paper or resourc for more inform licens attribut noncommerci   intern it should abid by the see the full descript on the dataset page\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14019/1353031619.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(df2.iloc[i[0]][1])\n",
      "/tmp/ipykernel_14019/1353031619.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(df2.iloc[i[0]][5])\n"
     ]
    }
   ],
   "source": [
    "recommend('liuhaotian/LLaVA-Instruct-150K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation based on user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for dataset name dataset summari thi dataset card aim to be a base templat for new dataset it ha been gener use thi raw templat support task and leaderboard more inform need languag more inform need dataset structur data instanc more inform need data field more inform need data split more inform see the full descript on the dataset page\n",
      "test\n",
      "what is thi thi is a clean version of amazon product dataset  from kaggl whi use via hug face api is easier kaggl api is annoy becaus their authent is have credenti in a folder clean becaus   column are empti\n",
      "sagi the scientif and gener inform data set the inform store in the dataset is inform from openai gpt   turbo googl palm and anthrop claud  the inform may not be entir factual\n",
      "for spider tableqa usag import panda as pd from dataset import load dataset spider tableqa load dataset vaishali spider tableqa for sampl in spider tableqa train question sampl question sql queri sampl queri input tabl name sampl tabl name input tabl pd read json tabl orient split for tabl in sampl tabl answer pd read json sampl answer orient split flatten input output see the full descript on the dataset page\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(df2['text'][i+2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['tags'] = df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_model(user_input):\n",
    "    \n",
    "    user_vector = cv.transform([user_input]).toarray()\n",
    "    similarity_with_user = cosine_similarity(vectors ,user_vector)\n",
    "    recommended_indices = sorted(range(len(similarity_with_user)) ,key=lambda i: similarity_with_user[i] ,reverse=True)[:5]\n",
    "    for index in recommended_indices:\n",
    "        print(df2.iloc[index]['id'])\n",
    "        print(df2.iloc[index]['text'])\n",
    "        print(df2.iloc[index]['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yuweiyin/FinBench\n",
      "finbench dataset\n",
      "['multiple-choice', 'question-answering', 'zero-shot-classification', 'text2text-generation', 'table-question-answering', 'text-generation', 'text-classification', 'tabular-classification']\n",
      "gauss314/arg-equity\n",
      "download the option iv sp dataset thi document will guid you through the step to download the merval equiti dataset from hug face dataset to start you ll need to instal hug face s dataset librari if you haven t done so alreadi you can do thi use the follow pip command pip instal dataset here s the python code to load the merval equiti dataset from hug face dataset and convert it into a panda datafram from dataset import load dataset see the full descript on the dataset page\n",
      "['question-answering', 'text2text-generation', 'text-generation']\n",
      "gauss314/opciones\n",
      "download thi option dataset thi document will guid you through the step to download the merval option dataset from hug face dataset to start you ll need to instal hug face s dataset librari if you haven t done so alreadi you can do thi use the follow pip command pip instal dataset here s the python code to load the merval equiti dataset from hug face dataset and convert it into a panda datafram from dataset import load dataset import see the full descript on the dataset page\n",
      "['question-answering', 'text-retrieval', 'text2text-generation', 'other', 'translation']\n",
      "rdpahalavan/UNSW-NB15\n",
      "we have develop a python packag as a wrapper around hug face hub and hug face dataset librari to access thi dataset easili nid dataset the nid dataset packag provid function to download and util special curat and extract dataset from the origin unsw nb and cic ids dataset these dataset which initi were onli flow dataset have been enhanc to includ packet level inform from the raw pcap file the dataset contain both see the full descript on the dataset page\n",
      "['multiple-choice', 'question-answering', 'zero-shot-classification', 'text2text-generation', 'table-question-answering', 'text-generation', 'text-classification', 'tabular-classification']\n",
      "rdpahalavan/CIC-IDS2017\n",
      "we have develop a python packag as a wrapper around hug face hub and hug face dataset librari to access thi dataset easili nid dataset the nid dataset packag provid function to download and util special curat and extract dataset from the origin unsw nb and cic ids dataset these dataset which initi were onli flow dataset have been enhanc to includ packet level inform from the raw pcap file the dataset contain both see the full descript on the dataset page\n",
      "['multiple-choice', 'question-answering', 'zero-shot-classification', 'text2text-generation', 'table-question-answering', 'text-generation', 'text-classification', 'tabular-classification']\n"
     ]
    }
   ],
   "source": [
    "user_input = 'face dataset'\n",
    "recommend_model(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/dataset/req_df.pickle' ,'wb') as file:\n",
    "    pickle.dump(df2 ,file)\n",
    "with open('../data/dataset/vectors.pickle' ,'wb') as file:\n",
    "    pickle.dump(vectors ,file)\n",
    "with open('../data/dataset/count_vectorizer.pickle' ,'wb') as file:\n",
    "    pickle.dump(cv ,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
